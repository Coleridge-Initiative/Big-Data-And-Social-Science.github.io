<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 7 Machine Learning | Big Data and Social Science</title>
  <meta name="description" content="Chapter 7 Machine Learning | Big Data and Social Science" />
  <meta name="generator" content="bookdown 0.13 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 7 Machine Learning | Big Data and Social Science" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="Coleridge-Initiative/big-data-and-social-science" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 7 Machine Learning | Big Data and Social Science" />
  
  
  

<meta name="author" content="Ian Foster, Rayid Ghani, Ron S. Jarmin, Frauke Kreuter and Julia Lane" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="chap-viz.html"/>
<link rel="next" href="chap-text.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-157005492-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-157005492-1');
</script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Big Data and Social Science</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface to the 2nd edition</a></li>
<li class="chapter" data-level="1" data-path="chap-intro.html"><a href="chap-intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="chap-intro.html"><a href="chap-intro.html#sec:1-1"><i class="fa fa-check"></i><b>1.1</b> Why this book?</a></li>
<li class="chapter" data-level="1.2" data-path="chap-intro.html"><a href="chap-intro.html#sec:1-2"><i class="fa fa-check"></i><b>1.2</b> Defining big data and its value</a></li>
<li class="chapter" data-level="1.3" data-path="chap-intro.html"><a href="chap-intro.html#sec:1.3"><i class="fa fa-check"></i><b>1.3</b> The importance of inference</a></li>
<li class="chapter" data-level="1.4" data-path="chap-intro.html"><a href="chap-intro.html#sec:1-4"><i class="fa fa-check"></i><b>1.4</b> The importance of understanding how data are generated</a></li>
<li class="chapter" data-level="1.5" data-path="chap-intro.html"><a href="chap-intro.html#sec:1-5"><i class="fa fa-check"></i><b>1.5</b> New tools for new data</a></li>
<li class="chapter" data-level="1.6" data-path="chap-intro.html"><a href="chap-intro.html#sec:1-6"><i class="fa fa-check"></i><b>1.6</b> The book’s “use case”</a></li>
<li class="chapter" data-level="1.7" data-path="chap-intro.html"><a href="chap-intro.html#the-structure-of-the-book"><i class="fa fa-check"></i><b>1.7</b> The structure of the book</a><ul>
<li class="chapter" data-level="1.7.1" data-path="chap-intro.html"><a href="chap-intro.html#part-i-capture-and-curation"><i class="fa fa-check"></i><b>1.7.1</b> Part I: Capture and curation</a></li>
<li class="chapter" data-level="1.7.2" data-path="chap-intro.html"><a href="chap-intro.html#part-ii-modeling-and-analysis"><i class="fa fa-check"></i><b>1.7.2</b> Part II: Modeling and analysis</a></li>
<li class="chapter" data-level="1.7.3" data-path="chap-intro.html"><a href="chap-intro.html#part-iii-inference-and-ethics"><i class="fa fa-check"></i><b>1.7.3</b> Part III: Inference and ethics</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="chap-intro.html"><a href="chap-intro.html#sec:intro:resources"><i class="fa fa-check"></i><b>1.8</b> Resources</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="chap-web.html"><a href="chap-web.html"><i class="fa fa-check"></i><b>2</b> Working with Web Data and APIs</a><ul>
<li class="chapter" data-level="2.1" data-path="chap-web.html"><a href="chap-web.html#introduction"><i class="fa fa-check"></i><b>2.1</b> Introduction</a></li>
<li class="chapter" data-level="2.2" data-path="chap-web.html"><a href="chap-web.html#sec:4-1"><i class="fa fa-check"></i><b>2.2</b> Scraping information from the web</a><ul>
<li class="chapter" data-level="2.2.1" data-path="chap-web.html"><a href="chap-web.html#sec:4-1.1"><i class="fa fa-check"></i><b>2.2.1</b> Obtaining data from websites</a></li>
<li class="chapter" data-level="2.2.2" data-path="chap-web.html"><a href="chap-web.html#sec:4-1.2"><i class="fa fa-check"></i><b>2.2.2</b> Limits of scraping</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="chap-web.html"><a href="chap-web.html#sec:4-3"><i class="fa fa-check"></i><b>2.3</b> Application Programming Interfaces (APIs)</a><ul>
<li class="chapter" data-level="2.3.1" data-path="chap-web.html"><a href="chap-web.html#sec:4-3.1"><i class="fa fa-check"></i><b>2.3.1</b> Relevant APIs and resources</a></li>
<li class="chapter" data-level="2.3.2" data-path="chap-web.html"><a href="chap-web.html#sec:4-3.2"><i class="fa fa-check"></i><b>2.3.2</b> RESTful APIs, returned data, and Python wrappers</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="chap-web.html"><a href="chap-web.html#sec:4-4"><i class="fa fa-check"></i><b>2.4</b> Using an API</a></li>
<li class="chapter" data-level="2.5" data-path="chap-web.html"><a href="chap-web.html#sec:4-4.1"><i class="fa fa-check"></i><b>2.5</b> Another example: Using the ORCID API via a wrapper</a></li>
<li class="chapter" data-level="2.6" data-path="chap-web.html"><a href="chap-web.html#sec:4-6"><i class="fa fa-check"></i><b>2.6</b> Integrating data from multiple sources</a></li>
<li class="chapter" data-level="2.7" data-path="chap-web.html"><a href="chap-web.html#sec:4-9"><i class="fa fa-check"></i><b>2.7</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="chap-link.html"><a href="chap-link.html"><i class="fa fa-check"></i><b>3</b> Record Linkage</a><ul>
<li class="chapter" data-level="3.1" data-path="chap-link.html"><a href="chap-link.html#motivation"><i class="fa fa-check"></i><b>3.1</b> Motivation</a></li>
<li class="chapter" data-level="3.2" data-path="chap-link.html"><a href="chap-link.html#sec:recordlinkage"><i class="fa fa-check"></i><b>3.2</b> Introduction to record linkage</a></li>
<li class="chapter" data-level="3.3" data-path="chap-link.html"><a href="chap-link.html#preprocessing-data-for-record-linkage"><i class="fa fa-check"></i><b>3.3</b> Preprocessing data for record linkage</a></li>
<li class="chapter" data-level="3.4" data-path="chap-link.html"><a href="chap-link.html#S:indexing"><i class="fa fa-check"></i><b>3.4</b> Indexing and blocking</a></li>
<li class="chapter" data-level="3.5" data-path="chap-link.html"><a href="chap-link.html#matching"><i class="fa fa-check"></i><b>3.5</b> Matching</a><ul>
<li class="chapter" data-level="3.5.1" data-path="chap-link.html"><a href="chap-link.html#rule-based-approaches"><i class="fa fa-check"></i><b>3.5.1</b> Rule-based approaches</a></li>
<li class="chapter" data-level="3.5.2" data-path="chap-link.html"><a href="chap-link.html#probabilistic-record-linkage"><i class="fa fa-check"></i><b>3.5.2</b> Probabilistic record linkage</a></li>
<li class="chapter" data-level="3.5.3" data-path="chap-link.html"><a href="chap-link.html#machine-learning-approaches-to-record-linkage"><i class="fa fa-check"></i><b>3.5.3</b> Machine learning approaches to record linkage</a></li>
<li class="chapter" data-level="3.5.4" data-path="chap-link.html"><a href="chap-link.html#disambiguating-networks"><i class="fa fa-check"></i><b>3.5.4</b> Disambiguating networks</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="chap-link.html"><a href="chap-link.html#classification"><i class="fa fa-check"></i><b>3.6</b> Classification</a><ul>
<li class="chapter" data-level="3.6.1" data-path="chap-link.html"><a href="chap-link.html#S:thresholds"><i class="fa fa-check"></i><b>3.6.1</b> Thresholds</a></li>
<li class="chapter" data-level="3.6.2" data-path="chap-link.html"><a href="chap-link.html#one-to-one-links"><i class="fa fa-check"></i><b>3.6.2</b> One-to-one links</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="chap-link.html"><a href="chap-link.html#record-linkage-and-data-protection"><i class="fa fa-check"></i><b>3.7</b> Record linkage and data protection</a></li>
<li class="chapter" data-level="3.8" data-path="chap-link.html"><a href="chap-link.html#summary"><i class="fa fa-check"></i><b>3.8</b> Summary</a></li>
<li class="chapter" data-level="3.9" data-path="chap-link.html"><a href="chap-link.html#resources"><i class="fa fa-check"></i><b>3.9</b> Resources</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="chap-db.html"><a href="chap-db.html"><i class="fa fa-check"></i><b>4</b> Databases</a><ul>
<li class="chapter" data-level="4.1" data-path="chap-db.html"><a href="chap-db.html#sec:db:intro"><i class="fa fa-check"></i><b>4.1</b> Introduction</a></li>
<li class="chapter" data-level="4.2" data-path="chap-db.html"><a href="chap-db.html#sec:db:when"><i class="fa fa-check"></i><b>4.2</b> DBMS: When and why</a></li>
<li class="chapter" data-level="4.3" data-path="chap-db.html"><a href="chap-db.html#relational-dbmss"><i class="fa fa-check"></i><b>4.3</b> Relational DBMSs</a><ul>
<li class="chapter" data-level="4.3.1" data-path="chap-db.html"><a href="chap-db.html#structured-query-language-sql"><i class="fa fa-check"></i><b>4.3.1</b> Structured Query Language (SQL)</a></li>
<li class="chapter" data-level="4.3.2" data-path="chap-db.html"><a href="chap-db.html#sec:db:sql"><i class="fa fa-check"></i><b>4.3.2</b> Manipulating and querying data</a></li>
<li class="chapter" data-level="4.3.3" data-path="chap-db.html"><a href="chap-db.html#sec:db:schema"><i class="fa fa-check"></i><b>4.3.3</b> Schema design and definition</a></li>
<li class="chapter" data-level="4.3.4" data-path="chap-db.html"><a href="chap-db.html#loading-data"><i class="fa fa-check"></i><b>4.3.4</b> Loading data</a></li>
<li class="chapter" data-level="4.3.5" data-path="chap-db.html"><a href="chap-db.html#transactions-and-crash-recovery"><i class="fa fa-check"></i><b>4.3.5</b> Transactions and crash recovery</a></li>
<li class="chapter" data-level="4.3.6" data-path="chap-db.html"><a href="chap-db.html#sec:db:index"><i class="fa fa-check"></i><b>4.3.6</b> Database optimizations</a></li>
<li class="chapter" data-level="4.3.7" data-path="chap-db.html"><a href="chap-db.html#caveats-and-challenges"><i class="fa fa-check"></i><b>4.3.7</b> Caveats and challenges</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="chap-db.html"><a href="chap-db.html#linking-dbmss-and-other-tools"><i class="fa fa-check"></i><b>4.4</b> Linking DBMSs and other tools</a></li>
<li class="chapter" data-level="4.5" data-path="chap-db.html"><a href="chap-db.html#sec:db:nosql"><i class="fa fa-check"></i><b>4.5</b> NoSQL databases</a><ul>
<li class="chapter" data-level="4.5.1" data-path="chap-db.html"><a href="chap-db.html#challenges-of-scale-the-cap-theorem"><i class="fa fa-check"></i><b>4.5.1</b> Challenges of scale: The CAP theorem</a></li>
<li class="chapter" data-level="4.5.2" data-path="chap-db.html"><a href="chap-db.html#nosql-and-keyvalue-stores"><i class="fa fa-check"></i><b>4.5.2</b> NoSQL and key–value stores</a></li>
<li class="chapter" data-level="4.5.3" data-path="chap-db.html"><a href="chap-db.html#other-nosql-databases"><i class="fa fa-check"></i><b>4.5.3</b> Other NoSQL databases</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="chap-db.html"><a href="chap-db.html#sec:db:spatial"><i class="fa fa-check"></i><b>4.6</b> Spatial databases</a></li>
<li class="chapter" data-level="4.7" data-path="chap-db.html"><a href="chap-db.html#which-database-to-use"><i class="fa fa-check"></i><b>4.7</b> Which database to use?</a><ul>
<li class="chapter" data-level="4.7.1" data-path="chap-db.html"><a href="chap-db.html#relational-dbmss-1"><i class="fa fa-check"></i><b>4.7.1</b> Relational DBMSs</a></li>
<li class="chapter" data-level="4.7.2" data-path="chap-db.html"><a href="chap-db.html#nosql-dbmss"><i class="fa fa-check"></i><b>4.7.2</b> NoSQL DBMSs</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="chap-db.html"><a href="chap-db.html#summary-1"><i class="fa fa-check"></i><b>4.8</b> Summary</a></li>
<li class="chapter" data-level="4.9" data-path="chap-db.html"><a href="chap-db.html#resources-1"><i class="fa fa-check"></i><b>4.9</b> Resources</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="chap-parallel.html"><a href="chap-parallel.html"><i class="fa fa-check"></i><b>5</b> Scaling up through Parallel and Distributed Computing</a><ul>
<li class="chapter" data-level="5.1" data-path="chap-parallel.html"><a href="chap-parallel.html#introduction-1"><i class="fa fa-check"></i><b>5.1</b> Introduction</a></li>
<li class="chapter" data-level="5.2" data-path="chap-parallel.html"><a href="chap-parallel.html#sec:intro"><i class="fa fa-check"></i><b>5.2</b> MapReduce</a></li>
<li class="chapter" data-level="5.3" data-path="chap-parallel.html"><a href="chap-parallel.html#apache-hadoop-mapreduce"><i class="fa fa-check"></i><b>5.3</b> Apache Hadoop MapReduce</a><ul>
<li class="chapter" data-level="5.3.1" data-path="chap-parallel.html"><a href="chap-parallel.html#the-hadoop-distributed-file-system"><i class="fa fa-check"></i><b>5.3.1</b> The Hadoop Distributed File System</a></li>
<li class="chapter" data-level="5.3.2" data-path="chap-parallel.html"><a href="chap-parallel.html#hadoop-setup-bringing-compute-to-the-data"><i class="fa fa-check"></i><b>5.3.2</b> Hadoop Setup: Bringing compute to the data</a></li>
<li class="chapter" data-level="5.3.3" data-path="chap-parallel.html"><a href="chap-parallel.html#hardware-provisioning"><i class="fa fa-check"></i><b>5.3.3</b> Hardware provisioning</a></li>
<li class="chapter" data-level="5.3.4" data-path="chap-parallel.html"><a href="chap-parallel.html#programming-in-hadoop"><i class="fa fa-check"></i><b>5.3.4</b> Programming in Hadoop</a></li>
<li class="chapter" data-level="5.3.5" data-path="chap-parallel.html"><a href="chap-parallel.html#programming-language-support"><i class="fa fa-check"></i><b>5.3.5</b> Programming language support</a></li>
<li class="chapter" data-level="5.3.6" data-path="chap-parallel.html"><a href="chap-parallel.html#benefits-and-limitations-of-hadoop"><i class="fa fa-check"></i><b>5.3.6</b> Benefits and Limitations of Hadoop</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="chap-parallel.html"><a href="chap-parallel.html#other-mapreduce-implementations"><i class="fa fa-check"></i><b>5.4</b> Other MapReduce Implementations</a></li>
<li class="chapter" data-level="5.5" data-path="chap-parallel.html"><a href="chap-parallel.html#apache-spark"><i class="fa fa-check"></i><b>5.5</b> Apache Spark</a></li>
<li class="chapter" data-level="5.6" data-path="chap-parallel.html"><a href="chap-parallel.html#summary-2"><i class="fa fa-check"></i><b>5.6</b> Summary</a></li>
<li class="chapter" data-level="5.7" data-path="chap-parallel.html"><a href="chap-parallel.html#resources-2"><i class="fa fa-check"></i><b>5.7</b> Resources</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="chap-viz.html"><a href="chap-viz.html"><i class="fa fa-check"></i><b>6</b> Information Visualization</a><ul>
<li class="chapter" data-level="6.1" data-path="chap-viz.html"><a href="chap-viz.html#sec:viz-1"><i class="fa fa-check"></i><b>6.1</b> Introduction</a></li>
<li class="chapter" data-level="6.2" data-path="chap-viz.html"><a href="chap-viz.html#sec:viz-2"><i class="fa fa-check"></i><b>6.2</b> Developing effective visualizations</a></li>
<li class="chapter" data-level="6.3" data-path="chap-viz.html"><a href="chap-viz.html#sec:viz-3"><i class="fa fa-check"></i><b>6.3</b> A data-by-tasks taxonomy</a><ul>
<li class="chapter" data-level="6.3.1" data-path="chap-viz.html"><a href="chap-viz.html#sec:viz-2.1"><i class="fa fa-check"></i><b>6.3.1</b> Multivariate data</a></li>
<li class="chapter" data-level="6.3.2" data-path="chap-viz.html"><a href="chap-viz.html#sec:viz-2.2"><i class="fa fa-check"></i><b>6.3.2</b> Spatial data</a></li>
<li class="chapter" data-level="6.3.3" data-path="chap-viz.html"><a href="chap-viz.html#sec:viz-2.4"><i class="fa fa-check"></i><b>6.3.3</b> Temporal data</a></li>
<li class="chapter" data-level="6.3.4" data-path="chap-viz.html"><a href="chap-viz.html#sec:viz-2.5"><i class="fa fa-check"></i><b>6.3.4</b> Hierarchical data</a></li>
<li class="chapter" data-level="6.3.5" data-path="chap-viz.html"><a href="chap-viz.html#sec:viz-2.6"><i class="fa fa-check"></i><b>6.3.5</b> Network data</a></li>
<li class="chapter" data-level="6.3.6" data-path="chap-viz.html"><a href="chap-viz.html#sec:viz-2.7"><i class="fa fa-check"></i><b>6.3.6</b> Text data</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="chap-viz.html"><a href="chap-viz.html#sec:viz-4"><i class="fa fa-check"></i><b>6.4</b> Challenges</a><ul>
<li class="chapter" data-level="6.4.1" data-path="chap-viz.html"><a href="chap-viz.html#sec:viz-4.1"><i class="fa fa-check"></i><b>6.4.1</b> Scalability</a></li>
<li class="chapter" data-level="6.4.2" data-path="chap-viz.html"><a href="chap-viz.html#sec:viz-4.2"><i class="fa fa-check"></i><b>6.4.2</b> Evaluation</a></li>
<li class="chapter" data-level="6.4.3" data-path="chap-viz.html"><a href="chap-viz.html#sec:viz-4.3"><i class="fa fa-check"></i><b>6.4.3</b> Visual impairment</a></li>
<li class="chapter" data-level="6.4.4" data-path="chap-viz.html"><a href="chap-viz.html#sec:viz-4.4"><i class="fa fa-check"></i><b>6.4.4</b> Visual literacy</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="chap-viz.html"><a href="chap-viz.html#sec:viz-5"><i class="fa fa-check"></i><b>6.5</b> Summary</a></li>
<li class="chapter" data-level="6.6" data-path="chap-viz.html"><a href="chap-viz.html#sec:viz-6"><i class="fa fa-check"></i><b>6.6</b> Resources</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="chap-ml.html"><a href="chap-ml.html"><i class="fa fa-check"></i><b>7</b> Machine Learning</a><ul>
<li class="chapter" data-level="7.1" data-path="chap-ml.html"><a href="chap-ml.html#introduction-2"><i class="fa fa-check"></i><b>7.1</b> Introduction</a></li>
<li class="chapter" data-level="7.2" data-path="chap-ml.html"><a href="chap-ml.html#what-is-machine-learning"><i class="fa fa-check"></i><b>7.2</b> What is machine learning?</a></li>
<li class="chapter" data-level="7.3" data-path="chap-ml.html"><a href="chap-ml.html#types-of-analysis"><i class="fa fa-check"></i><b>7.3</b> Types of analysis</a></li>
<li class="chapter" data-level="7.4" data-path="chap-ml.html"><a href="chap-ml.html#the-machine-learning-process"><i class="fa fa-check"></i><b>7.4</b> The Machine Learning process</a></li>
<li class="chapter" data-level="7.5" data-path="chap-ml.html"><a href="chap-ml.html#problem-formulation-mapping-a-problem-to-machine-learning-methods"><i class="fa fa-check"></i><b>7.5</b> Problem formulation: Mapping a problem to machine learning methods</a><ul>
<li class="chapter" data-level="7.5.1" data-path="chap-ml.html"><a href="chap-ml.html#features"><i class="fa fa-check"></i><b>7.5.1</b> Features</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="chap-ml.html"><a href="chap-ml.html#methods"><i class="fa fa-check"></i><b>7.6</b> Methods</a><ul>
<li class="chapter" data-level="7.6.1" data-path="chap-ml.html"><a href="chap-ml.html#unsupervised-learning-methods"><i class="fa fa-check"></i><b>7.6.1</b> Unsupervised learning methods</a></li>
<li class="chapter" data-level="7.6.2" data-path="chap-ml.html"><a href="chap-ml.html#sec:MLchapter:super"><i class="fa fa-check"></i><b>7.6.2</b> Supervised learning</a></li>
<li class="chapter" data-level="7.6.3" data-path="chap-ml.html"><a href="chap-ml.html#binary-vs-multiclass-classification-problems"><i class="fa fa-check"></i><b>7.6.3</b> Binary vs Multiclass classification problems</a></li>
<li class="chapter" data-level="7.6.4" data-path="chap-ml.html"><a href="chap-ml.html#skewed-or-imbalanced-classification-problems"><i class="fa fa-check"></i><b>7.6.4</b> Skewed or imbalanced classification problems</a></li>
<li class="chapter" data-level="7.6.5" data-path="chap-ml.html"><a href="chap-ml.html#model-interpretability"><i class="fa fa-check"></i><b>7.6.5</b> Model interpretability</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="chap-ml.html"><a href="chap-ml.html#evaluation"><i class="fa fa-check"></i><b>7.7</b> Evaluation</a><ul>
<li class="chapter" data-level="7.7.1" data-path="chap-ml.html"><a href="chap-ml.html#methodology"><i class="fa fa-check"></i><b>7.7.1</b> Methodology</a></li>
<li class="chapter" data-level="7.7.2" data-path="chap-ml.html"><a href="chap-ml.html#metrics"><i class="fa fa-check"></i><b>7.7.2</b> Metrics</a></li>
</ul></li>
<li class="chapter" data-level="7.8" data-path="chap-ml.html"><a href="chap-ml.html#practical-tips"><i class="fa fa-check"></i><b>7.8</b> Practical tips</a><ul>
<li class="chapter" data-level="7.8.1" data-path="chap-ml.html"><a href="chap-ml.html#avoiding-leakage"><i class="fa fa-check"></i><b>7.8.1</b> Avoiding Leakage</a></li>
<li class="chapter" data-level="7.8.2" data-path="chap-ml.html"><a href="chap-ml.html#machine-learning-pipeline"><i class="fa fa-check"></i><b>7.8.2</b> Machine learning pipeline</a></li>
</ul></li>
<li class="chapter" data-level="7.9" data-path="chap-ml.html"><a href="chap-ml.html#how-can-social-scientists-benefit-from-machine-learning"><i class="fa fa-check"></i><b>7.9</b> How can social scientists benefit from machine learning?</a></li>
<li class="chapter" data-level="7.10" data-path="chap-ml.html"><a href="chap-ml.html#advanced-topics"><i class="fa fa-check"></i><b>7.10</b> Advanced topics</a></li>
<li class="chapter" data-level="7.11" data-path="chap-ml.html"><a href="chap-ml.html#summary-3"><i class="fa fa-check"></i><b>7.11</b> Summary</a></li>
<li class="chapter" data-level="7.12" data-path="chap-ml.html"><a href="chap-ml.html#ml:res"><i class="fa fa-check"></i><b>7.12</b> Resources</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="chap-text.html"><a href="chap-text.html"><i class="fa fa-check"></i><b>8</b> Text Analysis</a><ul>
<li class="chapter" data-level="8.1" data-path="chap-text.html"><a href="chap-text.html#understanding-human-generated-text"><i class="fa fa-check"></i><b>8.1</b> Understanding human generated text</a></li>
<li class="chapter" data-level="8.2" data-path="chap-text.html"><a href="chap-text.html#how-is-text-data-different-than-structured-data"><i class="fa fa-check"></i><b>8.2</b> How is text data different than “structured” data?</a></li>
<li class="chapter" data-level="8.3" data-path="chap-text.html"><a href="chap-text.html#what-can-we-do-with-text-data"><i class="fa fa-check"></i><b>8.3</b> What can we do with text data?</a></li>
<li class="chapter" data-level="8.4" data-path="chap-text.html"><a href="chap-text.html#how-to-analyze-text"><i class="fa fa-check"></i><b>8.4</b> How to analyze text</a><ul>
<li class="chapter" data-level="8.4.1" data-path="chap-text.html"><a href="chap-text.html#initial-processing"><i class="fa fa-check"></i><b>8.4.1</b> Initial Processing</a></li>
<li class="chapter" data-level="8.4.2" data-path="chap-text.html"><a href="chap-text.html#linguistic-analysis"><i class="fa fa-check"></i><b>8.4.2</b> Linguistic Analysis</a></li>
<li class="chapter" data-level="8.4.3" data-path="chap-text.html"><a href="chap-text.html#turning-text-data-into-a-matrix-how-much-is-a-word-worth"><i class="fa fa-check"></i><b>8.4.3</b> Turning text data into a matrix: How much is a word worth?</a></li>
<li class="chapter" data-level="8.4.4" data-path="chap-text.html"><a href="chap-text.html#analysis"><i class="fa fa-check"></i><b>8.4.4</b> Analysis</a></li>
<li class="chapter" data-level="8.4.5" data-path="chap-text.html"><a href="chap-text.html#sec:lda"><i class="fa fa-check"></i><b>8.4.5</b> Topic modeling</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="chap-text.html"><a href="chap-text.html#word-embeddings-and-deep-learning"><i class="fa fa-check"></i><b>8.5</b> Word Embeddings and Deep Learning</a></li>
<li class="chapter" data-level="8.6" data-path="chap-text.html"><a href="chap-text.html#text-analysis-tools"><i class="fa fa-check"></i><b>8.6</b> Text analysis tools</a></li>
<li class="chapter" data-level="8.7" data-path="chap-text.html"><a href="chap-text.html#summary-4"><i class="fa fa-check"></i><b>8.7</b> Summary</a></li>
<li class="chapter" data-level="8.8" data-path="chap-text.html"><a href="chap-text.html#resources-3"><i class="fa fa-check"></i><b>8.8</b> Resources</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="chap-networks.html"><a href="chap-networks.html"><i class="fa fa-check"></i><b>9</b> Networks: The Basics</a><ul>
<li class="chapter" data-level="9.1" data-path="chap-networks.html"><a href="chap-networks.html#introduction-3"><i class="fa fa-check"></i><b>9.1</b> Introduction</a></li>
<li class="chapter" data-level="9.2" data-path="chap-networks.html"><a href="chap-networks.html#what-are-networks"><i class="fa fa-check"></i><b>9.2</b> What are networks?</a></li>
<li class="chapter" data-level="9.3" data-path="chap-networks.html"><a href="chap-networks.html#structure-for-this-chapter"><i class="fa fa-check"></i><b>9.3</b> Structure for this chapter</a></li>
<li class="chapter" data-level="9.4" data-path="chap-networks.html"><a href="chap-networks.html#turning-data-into-a-network"><i class="fa fa-check"></i><b>9.4</b> Turning Data into a Network</a><ul>
<li class="chapter" data-level="9.4.1" data-path="chap-networks.html"><a href="chap-networks.html#types-of-networks"><i class="fa fa-check"></i><b>9.4.1</b> Types of Networks</a></li>
<li class="chapter" data-level="9.4.2" data-path="chap-networks.html"><a href="chap-networks.html#inducing-one-mode-networks-from-two-mode-data"><i class="fa fa-check"></i><b>9.4.2</b> Inducing one-mode networks from two-mode data</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="chap-networks.html"><a href="chap-networks.html#network-measures"><i class="fa fa-check"></i><b>9.5</b> Network measures</a><ul>
<li class="chapter" data-level="9.5.1" data-path="chap-networks.html"><a href="chap-networks.html#reachability"><i class="fa fa-check"></i><b>9.5.1</b> Reachability</a></li>
<li class="chapter" data-level="9.5.2" data-path="chap-networks.html"><a href="chap-networks.html#whole-network-measures"><i class="fa fa-check"></i><b>9.5.2</b> Whole-network measures</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="chap-networks.html"><a href="chap-networks.html#case-study-comparing-collaboration-networks"><i class="fa fa-check"></i><b>9.6</b> Case Study: Comparing collaboration networks</a></li>
<li class="chapter" data-level="9.7" data-path="chap-networks.html"><a href="chap-networks.html#summary-5"><i class="fa fa-check"></i><b>9.7</b> Summary</a></li>
<li class="chapter" data-level="9.8" data-path="chap-networks.html"><a href="chap-networks.html#resources-4"><i class="fa fa-check"></i><b>9.8</b> Resources</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="chap-errors.html"><a href="chap-errors.html"><i class="fa fa-check"></i><b>10</b> Data Quality and Inference Errors</a><ul>
<li class="chapter" data-level="10.1" data-path="chap-errors.html"><a href="chap-errors.html#sec:10-1"><i class="fa fa-check"></i><b>10.1</b> Introduction</a></li>
<li class="chapter" data-level="10.2" data-path="chap-errors.html"><a href="chap-errors.html#sec:10-2"><i class="fa fa-check"></i><b>10.2</b> The total error paradigm</a><ul>
<li class="chapter" data-level="10.2.1" data-path="chap-errors.html"><a href="chap-errors.html#sec:10-2.1"><i class="fa fa-check"></i><b>10.2.1</b> The traditional model</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="chap-errors.html"><a href="chap-errors.html#sec:10-3"><i class="fa fa-check"></i><b>10.3</b> Example: Google Flu Trends</a></li>
<li class="chapter" data-level="10.4" data-path="chap-errors.html"><a href="chap-errors.html#sec:10-4"><i class="fa fa-check"></i><b>10.4</b> Errors in data analysis</a><ul>
<li class="chapter" data-level="10.4.1" data-path="chap-errors.html"><a href="chap-errors.html#sec:10-4.2"><i class="fa fa-check"></i><b>10.4.1</b> Analysis errors resulting from inaccurate data</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="chap-errors.html"><a href="chap-errors.html#sec:10-5"><i class="fa fa-check"></i><b>10.5</b> Detecting and Compensating for Data Errors</a><ul>
<li class="chapter" data-level="10.5.1" data-path="chap-errors.html"><a href="chap-errors.html#tableplots"><i class="fa fa-check"></i><b>10.5.1</b> TablePlots</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="chap-errors.html"><a href="chap-errors.html#sec:10-6"><i class="fa fa-check"></i><b>10.6</b> Summary</a></li>
<li class="chapter" data-level="10.7" data-path="chap-errors.html"><a href="chap-errors.html#resources-5"><i class="fa fa-check"></i><b>10.7</b> Resources</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="chap-bias.html"><a href="chap-bias.html"><i class="fa fa-check"></i><b>11</b> Bias and Fairness</a><ul>
<li class="chapter" data-level="11.1" data-path="chap-bias.html"><a href="chap-bias.html#introduction-4"><i class="fa fa-check"></i><b>11.1</b> Introduction</a></li>
<li class="chapter" data-level="11.2" data-path="chap-bias.html"><a href="chap-bias.html#sec:biassources"><i class="fa fa-check"></i><b>11.2</b> Sources of Bias</a><ul>
<li class="chapter" data-level="11.2.1" data-path="chap-bias.html"><a href="chap-bias.html#sample-bias"><i class="fa fa-check"></i><b>11.2.1</b> Sample Bias</a></li>
<li class="chapter" data-level="11.2.2" data-path="chap-bias.html"><a href="chap-bias.html#label-outcome-bias"><i class="fa fa-check"></i><b>11.2.2</b> Label (Outcome) Bias</a></li>
<li class="chapter" data-level="11.2.3" data-path="chap-bias.html"><a href="chap-bias.html#sec:mlbiasexamples"><i class="fa fa-check"></i><b>11.2.3</b> Machine Learning Pipeline Bias</a></li>
<li class="chapter" data-level="11.2.4" data-path="chap-bias.html"><a href="chap-bias.html#application-bias"><i class="fa fa-check"></i><b>11.2.4</b> Application Bias</a></li>
<li class="chapter" data-level="11.2.5" data-path="chap-bias.html"><a href="chap-bias.html#considering-bias-when-deploying-your-model"><i class="fa fa-check"></i><b>11.2.5</b> Considering Bias When Deploying Your Model</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="chap-bias.html"><a href="chap-bias.html#dealing-with-bias"><i class="fa fa-check"></i><b>11.3</b> Dealing with Bias</a><ul>
<li class="chapter" data-level="11.3.1" data-path="chap-bias.html"><a href="chap-bias.html#sec:metrics"><i class="fa fa-check"></i><b>11.3.1</b> Define Bias</a></li>
<li class="chapter" data-level="11.3.2" data-path="chap-bias.html"><a href="chap-bias.html#definitions"><i class="fa fa-check"></i><b>11.3.2</b> Definitions</a></li>
<li class="chapter" data-level="11.3.3" data-path="chap-bias.html"><a href="chap-bias.html#choosing-bias-metrics"><i class="fa fa-check"></i><b>11.3.3</b> Choosing Bias Metrics</a></li>
<li class="chapter" data-level="11.3.4" data-path="chap-bias.html"><a href="chap-bias.html#sec:punitiveexample"><i class="fa fa-check"></i><b>11.3.4</b> Punitive Example</a></li>
<li class="chapter" data-level="11.3.5" data-path="chap-bias.html"><a href="chap-bias.html#sec:assistiveexample"><i class="fa fa-check"></i><b>11.3.5</b> Assistive Example</a></li>
<li class="chapter" data-level="11.3.6" data-path="chap-bias.html"><a href="chap-bias.html#sec:constrainedassistive"><i class="fa fa-check"></i><b>11.3.6</b> Special Case: Resource-Constrained Programs</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="chap-bias.html"><a href="chap-bias.html#sec:applications"><i class="fa fa-check"></i><b>11.4</b> Mitigating Bias</a><ul>
<li class="chapter" data-level="11.4.1" data-path="chap-bias.html"><a href="chap-bias.html#auditing-model-results"><i class="fa fa-check"></i><b>11.4.1</b> Auditing Model Results</a></li>
<li class="chapter" data-level="11.4.2" data-path="chap-bias.html"><a href="chap-bias.html#model-selection"><i class="fa fa-check"></i><b>11.4.2</b> Model Selection</a></li>
<li class="chapter" data-level="11.4.3" data-path="chap-bias.html"><a href="chap-bias.html#other-options-for-mitigating-bias"><i class="fa fa-check"></i><b>11.4.3</b> Other Options for Mitigating Bias</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="chap-bias.html"><a href="chap-bias.html#further-considerations"><i class="fa fa-check"></i><b>11.5</b> Further Considerations</a><ul>
<li class="chapter" data-level="11.5.1" data-path="chap-bias.html"><a href="chap-bias.html#compared-to-what"><i class="fa fa-check"></i><b>11.5.1</b> Compared to What?</a></li>
<li class="chapter" data-level="11.5.2" data-path="chap-bias.html"><a href="chap-bias.html#costs-to-both-errors"><i class="fa fa-check"></i><b>11.5.2</b> Costs to Both Errors</a></li>
<li class="chapter" data-level="11.5.3" data-path="chap-bias.html"><a href="chap-bias.html#what-is-the-relevant-population"><i class="fa fa-check"></i><b>11.5.3</b> What is the Relevant Population?</a></li>
<li class="chapter" data-level="11.5.4" data-path="chap-bias.html"><a href="chap-bias.html#continuous-outcomes"><i class="fa fa-check"></i><b>11.5.4</b> Continuous Outcomes</a></li>
<li class="chapter" data-level="11.5.5" data-path="chap-bias.html"><a href="chap-bias.html#considerations-for-ongoing-measurement"><i class="fa fa-check"></i><b>11.5.5</b> Considerations for Ongoing Measurement</a></li>
<li class="chapter" data-level="11.5.6" data-path="chap-bias.html"><a href="chap-bias.html#equity-in-practice"><i class="fa fa-check"></i><b>11.5.6</b> Equity in Practice</a></li>
<li class="chapter" data-level="11.5.7" data-path="chap-bias.html"><a href="chap-bias.html#other-names-you-might-see"><i class="fa fa-check"></i><b>11.5.7</b> Other Names You Might See</a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="chap-bias.html"><a href="chap-bias.html#case-studies"><i class="fa fa-check"></i><b>11.6</b> Case Studies</a><ul>
<li class="chapter" data-level="11.6.1" data-path="chap-bias.html"><a href="chap-bias.html#sec:compascase"><i class="fa fa-check"></i><b>11.6.1</b> Recidivism Predictions with COMPAS</a></li>
<li class="chapter" data-level="11.6.2" data-path="chap-bias.html"><a href="chap-bias.html#facial-recognition"><i class="fa fa-check"></i><b>11.6.2</b> Facial Recognition</a></li>
<li class="chapter" data-level="11.6.3" data-path="chap-bias.html"><a href="chap-bias.html#facebook-advertisement-targeting"><i class="fa fa-check"></i><b>11.6.3</b> Facebook Advertisement Targeting</a></li>
</ul></li>
<li class="chapter" data-level="11.7" data-path="chap-bias.html"><a href="chap-bias.html#aequitas---a-toolkit-for-auditing-bias-and-fairness-in-machine-learning-models"><i class="fa fa-check"></i><b>11.7</b> Aequitas - A Toolkit for Auditing Bias and Fairness in Machine Learning Models</a><ul>
<li class="chapter" data-level="11.7.1" data-path="chap-bias.html"><a href="chap-bias.html#getting-started-with-aequitas"><i class="fa fa-check"></i><b>11.7.1</b> Getting Started with Aequitas</a></li>
<li class="chapter" data-level="11.7.2" data-path="chap-bias.html"><a href="chap-bias.html#requirements"><i class="fa fa-check"></i><b>11.7.2</b> Requirements</a></li>
<li class="chapter" data-level="11.7.3" data-path="chap-bias.html"><a href="chap-bias.html#data-preparation"><i class="fa fa-check"></i><b>11.7.3</b> Data Preparation</a></li>
<li class="chapter" data-level="11.7.4" data-path="chap-bias.html"><a href="chap-bias.html#working-with-bias-metrics"><i class="fa fa-check"></i><b>11.7.4</b> Working with Bias Metrics</a></li>
<li class="chapter" data-level="11.7.5" data-path="chap-bias.html"><a href="chap-bias.html#measuring-disparities"><i class="fa fa-check"></i><b>11.7.5</b> Measuring Disparities</a></li>
<li class="chapter" data-level="11.7.6" data-path="chap-bias.html"><a href="chap-bias.html#assessing-model-fairness"><i class="fa fa-check"></i><b>11.7.6</b> Assessing Model Fairness</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="chap-privacy.html"><a href="chap-privacy.html"><i class="fa fa-check"></i><b>12</b> Privacy and Confidentiality</a><ul>
<li class="chapter" data-level="12.1" data-path="chap-privacy.html"><a href="chap-privacy.html#introduction-5"><i class="fa fa-check"></i><b>12.1</b> Introduction</a></li>
<li class="chapter" data-level="12.2" data-path="chap-privacy.html"><a href="chap-privacy.html#why-is-access-important"><i class="fa fa-check"></i><b>12.2</b> Why is access important?</a></li>
<li class="chapter" data-level="12.3" data-path="chap-privacy.html"><a href="chap-privacy.html#providing-access"><i class="fa fa-check"></i><b>12.3</b> Providing access</a></li>
<li class="chapter" data-level="12.4" data-path="chap-privacy.html"><a href="chap-privacy.html#non-tabular-data"><i class="fa fa-check"></i><b>12.4</b> Non-Tabular data</a></li>
<li class="chapter" data-level="12.5" data-path="chap-privacy.html"><a href="chap-privacy.html#the-new-challenges"><i class="fa fa-check"></i><b>12.5</b> The new challenges</a></li>
<li class="chapter" data-level="12.6" data-path="chap-privacy.html"><a href="chap-privacy.html#legal-and-ethical-framework"><i class="fa fa-check"></i><b>12.6</b> Legal and ethical framework</a></li>
<li class="chapter" data-level="12.7" data-path="chap-privacy.html"><a href="chap-privacy.html#summary-6"><i class="fa fa-check"></i><b>12.7</b> Summary</a></li>
<li class="chapter" data-level="12.8" data-path="chap-privacy.html"><a href="chap-privacy.html#resources-6"><i class="fa fa-check"></i><b>12.8</b> Resources</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="chap-workbooks.html"><a href="chap-workbooks.html"><i class="fa fa-check"></i><b>13</b> Workbooks</a><ul>
<li class="chapter" data-level="13.1" data-path="chap-workbooks.html"><a href="chap-workbooks.html#introduction-6"><i class="fa fa-check"></i><b>13.1</b> Introduction</a></li>
<li class="chapter" data-level="13.2" data-path="chap-workbooks.html"><a href="chap-workbooks.html#notebooks"><i class="fa fa-check"></i><b>13.2</b> Notebooks</a><ul>
<li class="chapter" data-level="13.2.1" data-path="chap-workbooks.html"><a href="chap-workbooks.html#databases"><i class="fa fa-check"></i><b>13.2.1</b> Databases</a></li>
<li class="chapter" data-level="13.2.2" data-path="chap-workbooks.html"><a href="chap-workbooks.html#dataset-exploration-and-visualization"><i class="fa fa-check"></i><b>13.2.2</b> Dataset Exploration and Visualization</a></li>
<li class="chapter" data-level="13.2.3" data-path="chap-workbooks.html"><a href="chap-workbooks.html#apis"><i class="fa fa-check"></i><b>13.2.3</b> APIs</a></li>
<li class="chapter" data-level="13.2.4" data-path="chap-workbooks.html"><a href="chap-workbooks.html#record-linkage"><i class="fa fa-check"></i><b>13.2.4</b> Record Linkage</a></li>
<li class="chapter" data-level="13.2.5" data-path="chap-workbooks.html"><a href="chap-workbooks.html#text-analysis"><i class="fa fa-check"></i><b>13.2.5</b> Text Analysis</a></li>
<li class="chapter" data-level="13.2.6" data-path="chap-workbooks.html"><a href="chap-workbooks.html#networks"><i class="fa fa-check"></i><b>13.2.6</b> Networks</a></li>
<li class="chapter" data-level="13.2.7" data-path="chap-workbooks.html"><a href="chap-workbooks.html#machine-learning-creating-labels"><i class="fa fa-check"></i><b>13.2.7</b> Machine Learning – Creating Labels</a></li>
<li class="chapter" data-level="13.2.8" data-path="chap-workbooks.html"><a href="chap-workbooks.html#machine-learning-creating-features"><i class="fa fa-check"></i><b>13.2.8</b> Machine Learning – Creating Features</a></li>
<li class="chapter" data-level="13.2.9" data-path="chap-workbooks.html"><a href="chap-workbooks.html#machine-learning-model-training-and-evaluation"><i class="fa fa-check"></i><b>13.2.9</b> Machine Learning – Model Training and Evaluation</a></li>
<li class="chapter" data-level="13.2.10" data-path="chap-workbooks.html"><a href="chap-workbooks.html#bias-and-fairness"><i class="fa fa-check"></i><b>13.2.10</b> Bias and Fairness</a></li>
<li class="chapter" data-level="13.2.11" data-path="chap-workbooks.html"><a href="chap-workbooks.html#errors-and-inference"><i class="fa fa-check"></i><b>13.2.11</b> Errors and Inference</a></li>
<li class="chapter" data-level="13.2.12" data-path="chap-workbooks.html"><a href="chap-workbooks.html#additional-workbooks"><i class="fa fa-check"></i><b>13.2.12</b> Additional Workbooks</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="chap-workbooks.html"><a href="chap-workbooks.html#resources-7"><i class="fa fa-check"></i><b>13.3</b> Resources</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Big Data and Social Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="chap:ml" class="section level1">
<h1><span class="header-section-number">Chapter 7</span> Machine Learning</h1>
<p><strong>Rayid Ghani and Malte Schierholz</strong></p>
<p>This chapter introduces you to the use of machine learning in tackling social science and public policy problems. We cover the end-to-end machine learning process and focus on clustering and classification methods. After reading this chapter, you should have an overview of the components of a machine learning pipeline and methods, and know how to use those in solving social science problems. We have written this chapter to give an intuitive explanation for the methods and to provide a framework and practical tips on how to use them in practice.</p>
<div id="introduction-2" class="section level2">
<h2><span class="header-section-number">7.1</span> Introduction</h2>
<p>You have probably heard of “machine learning” but are not sure exactly what it is, how it differs from traditional statistics, and what you, as social scientists, can do with it. In this chapter, we will demystify machine learning, draw connections to what you already know from statistics and data analysis, and go deeper into some of the novel concepts and methods that have been developed in this field. Although the field originates from computer science, it has been influenced quite heavily by math and statistics in the past 15-20 years. As you will see, many of the concepts you will learn are not entirely new, but are simply called something else. For example, you already are familiar with logistic regression (a classification method that falls under the supervised learning framework in machine learning) and cluster analysis (a form of unsupervised learning). You will also learn about new methods that are more exclusively used in machine learning, such as random forests, support vector machines, and neural networks. We will keep formalisms to a minimum and focus on getting the intuition across, as well as providing practical tips. Our hope is this chapter will make you comfortable and familiar with machine learning vocabulary, concepts, and processes, and allows you to further explore and use these methods and tools in your own research and practice.</p>
</div>
<div id="what-is-machine-learning" class="section level2">
<h2><span class="header-section-number">7.2</span> What is machine learning?</h2>
<p>When humans improve their skills with experience, they are said to learn. Is it also possible to program computers to do the same? Arthur Samuel, who coined the term <em>machine learning</em> in 1959 <span class="citation">(Samuel <a href="#ref-samuel1959some">1959</a>)</span>, was a pioneer in this area, programming a computer to play checkers. The computer played against itself and human opponents, improving its performance with every game. Eventually, after sufficient <em>training</em> (and experience), the computer became a better player than the human programmer. Today, machine learning has grown significantly beyond learning to play checkers. Machine learning systems have learned to drive (and park) autonomous cars, are embedded inside robots, can recommend books, products, and movies we are (sometimes) interested in, identify drugs, proteins, and genes that should be investigated further to cure diseases, detect cancer and other pathologies in x-rays and other types of medical imaging, help us understand how the human brain learns language, help identify which voters are persuadable in elections, detect which students are likely to need extra support to graduate high school on time, and help solve many more problems. Over the past 20 years, machine learning has become an interdisciplinary field spanning computer science, artificial intelligence, databases, and statistics. At its core, machine learning seeks to design computer systems that improve over time with more experience. In one of the earlier books on machine learning, Tom Mitchell gives a more operational definition, stating that: “A computer program is said to learn from experience <span class="math inline">\(E\)</span> with respect to some class of tasks <span class="math inline">\(T\)</span> and performance measure <span class="math inline">\(P\)</span>, if its performance at tasks in <span class="math inline">\(T\)</span>, as measured by <span class="math inline">\(P\)</span>, improves with experience <span class="math inline">\(E\)</span>” <span class="citation">(Mitchell <a href="#ref-mitchell1997machine">1997</a>)</span>. We like this definition because it is task-focused and allows us to think of machine learning as a tool used inside a larger system to improve outcomes that we care about.</p>
<div class="F00">
<p>
<strong>Box 7.1: Commercial machine learning examples</strong>
</p>
<ul>
<li>
<p>
<strong>Speech recognition</strong>: Speech recognition software uses machine learning algorithms that are built on large amounts of initial training data. Machine learning allows these systems to be tuned and adapt to individual variations in speaking as well as across different domains.
</p>
</li>
<li>
<p>
<strong>Autonomous cars</strong>: The ongoing development of self-driving cars applies techniques from machine learning. An onboard computer continuously analyzes the incoming video and sensor streams in order to monitor the surroundings. Incoming data are matched with annotated images to recognize objects like pedestrians, traffic lights, and potholes. In order to assess the different objects, huge training data sets are required where similar objects already have been identified. This allows the autonomous car to decide on which actions to take next.
</p>
</li>
<li>
<p>
<strong>Fraud detection</strong>: Many public and private organizations face the problem of fraud and abuse. Machine learning systems are widely used to take historical cases of fraud and flag fraudulent transactions as they take place. These systems have the benefit of being adaptive, and improving with more data over time.
</p>
</li>
<li>
<p>
<strong>Personalized ads</strong>: Many online stores have personalized recommendations promoting possible products of interest. Based on individual shopping history and what other similar users bought in the past, the website predicts products a user may like and tailors recommendations. Netflix and Amazon are two examples of companies whose recommendation software predicts how a customer would rate a certain movie or product and then suggests items with the highest predicted ratings. Of course there are some caveats here, since they then adjust the recommendations to maximize profits.
</p>
</li>
<li>
<p>
<strong>Face recognition</strong>: Surveillance systems, social networking platforms, and imaging software all use face detection and face recognition to first detect faces in images (or video) and then tag them with individuals for various tasks. These systems are trained by giving examples of faces to a machine learning system which then learns to detect new faces, and tag known individuals. The bias and fairness chapter will highlight some concerns with these types of systems.
</p>
</li>
</ul>
</div>
<!--
% Box 7.2 and section 7.7. overlap
-->
<div class="F00">
<p>
<strong>Box 7.2: Social Science machine learning examples</strong>
</p>
<p>
Potash et al <span class="citation"><span class="citation">(<a href="#ref-Potash2015">2015</a>)</span></span> worked with the Chicago Department of Public Health and used random forests (a machine learning classification method) to predict which children are at risk of lead poisoning. This early warning system was then used to prioritize lead hazard inspections to detect and remediate lead hazards before they had an adverse effect on the child.
</p>
<p>
Carton et al <span class="citation"><span class="citation">(<a href="#ref-Carton2016">2016</a>)</span></span> used a collection of machine learning methods to identify police officers at risk of adverse behavior, such as unjustified use of force or unjustified shootings or sustained complaints, to prioritize preventive interventions such as training and counseling.
</p>
<p>
Athey and Wager <span class="citation"><span class="citation">(<a href="#ref-athey2019">2019</a>)</span></span> use a modification of random forests to estimate heterogeneous treatment effects using a data set from The National Study of Learning Mindsets to evaluate the impact of interventions to improve student achievement.
</p>
<p>
Voigt et al <span class="citation"><span class="citation">(<a href="#ref-Voigt2017">2017</a>)</span></span> uses machine learning methods to analyze footage from body-worn cameras and understand the respectfulness of police officer language toward white and black community members during routine traffic stops.
</p>
</div>
<p>Machine learning grew from the need for systems that were adaptive, scalable, and cost-effective to build and maintain. A lot of tasks now being done using machine learning used to be done by rule-based systems, where experts would spend considerable time and effort developing and maintaining the rules. The problem with those systems was that they were rigid, not adaptive, hard to scale, and expensive to maintain. Machine learning systems started becoming popular because they could improve the system along all of these dimensions<a href="#fn41" class="footnoteRef" id="fnref41"><sup>41</sup></a>. Box 7.1 mentions several examples where machine learning is being used in commercial applications today. Social scientists are uniquely placed today to take advantage of the same advances in machine learning by having better methods to solve several key problems they are tackling. Box 7.2 describes a few social science and policy problems that are being tackled using machine learning today.<a href="#fn42" class="footnoteRef" id="fnref42"><sup>42</sup></a></p>
<p>This chapter is not an exhaustive introduction to machine learning. There are many books that have done an excellent job of that <span class="citation">(Flach <a href="#ref-Flach">2012</a>; Hastie, Tibshirani, and Friedman <a href="#ref-HastieTibshirani">2001</a>; Mitchell <a href="#ref-mitchell1997machine">1997</a>)</span>. Instead, we present a short and accessible introduction to machine learning for social scientists, give an overview of the overall machine learning process, provide an intuitive introduction to machine learning methods, give some practical tips that will be helpful in using these methods, and leave a lot of the statistical theory to machine learning textbooks. As you read more about machine learning in the research literature or the media, you will encounter names of other fields that are related (and practically the same for most social science audiences), such as statistical learning, data mining, and pattern recognition.</p>
</div>
<div id="types-of-analysis" class="section level2">
<h2><span class="header-section-number">7.3</span> Types of analysis</h2>
<p>A lot of the data analysis tasks that social scientists do can be broken down into four types:</p>
<ul>
<li><p><strong>Description</strong>: The goal is to describe patterns or groupings in historical data. You’re already familiar with descriptive statistics and exploratory data analysis methods, and we will cover more advanced versions of those later in this chapter under Unsupervised Learning.</p></li>
<li><p><strong>Detection</strong>: The goal here is not to necessarily understand historical behavior but to detect new or emerging anomalies, events, or patterns as they happen. A typical example is early outbreak detection for infectious diseases in order to inform public health officials.</p></li>
<li><p><strong>Prediction</strong>: The goal here is to use the same historical data as the description and detection methods, but use it to predict events and behaviors in the future.</p></li>
<li><p><strong>Behavior Change (or Causal Inference)</strong>: The goal here is to understand the causal relationships in the data in order to influence the outcomes we care about.</p></li>
</ul>
<p>In this chapter, we will mostly focus on Description and Prediction methods but there is a lot of work going in developing and using machine learning methods for detection as well as for behavior change and causal inference.</p>
</div>
<div id="the-machine-learning-process" class="section level2">
<h2><span class="header-section-number">7.4</span> The Machine Learning process</h2>
<p>When solving problems using machine learning methods, it is important to think of the larger data-driven problem-solving process of which these methods are a small part<a href="#fn43" class="footnoteRef" id="fnref43"><sup>43</sup></a>. A typical machine learning problem requires researchers and practitioners to take the following steps:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Understand the problem and goal</strong>: This sounds obvious but is often nontrivial. Problems typically start as vague descriptions of a goal—improving health outcomes, increasing graduation rates, understanding the effect of a variable <span class="math inline">\(X\)</span> on an outcome <span class="math inline">\(Y\)</span>, etc. It is really important to work with people who understand the domain being studied to discuss and define the problem more concretely. What is the analytical formulation of the metric that you are trying to improve? The Data Science Project Scoping Guide (<a href="http://www.datasciencepublicpolicy.org/home/resources/data-science-project-scoping-guide/" class="uri">http://www.datasciencepublicpolicy.org/home/resources/data-science-project-scoping-guide/</a>) is a good place to start when doing problem scoping for social science or policy problems</p></li>
<li><p><strong>Formulate it as a machine learning problem</strong>: Is it a classification problem or a regression problem? Is the goal to build a model that generates a ranked list prioritized by risk of an outcome, or is it to detect anomalies as new data come in? Knowing what kinds of tasks machine learning can solve will allow you to map the problem you are working on to one or more machine learning settings and give you access to a suite of methods appropriate for that task.</p></li>
<li><p><strong>Data exploration and preparation</strong>: Next, you need to carefully explore the data you have. What additional data do you need or have access to? What variable will you use to match records for integrating different data sources? What variables exist in the data set? Are they continuous or categorical? What about missing values? Can you use the variables in their original form or do you need to alter them in some way?</p></li>
<li><p><strong>Feature engineering</strong>: In machine learning language, what you might know as independent variables or predictors or factors or covariates are called “features.” Creating good features is probably the most important step in the machine learning process. This involves doing transformations, creating interaction terms, or aggregating over data points or over time and space.</p></li>
<li><p><strong>Modeling</strong>: Having formulated the problem and created your features, you now have a suite of methods to choose from. It would be great if there were a single method that always worked best for a specific type of problem, but that would make things too easy. Each method makes a difference assumption about the structure and distribution of the data and with large amounts of high-dimensional data<a href="#fn44" class="footnoteRef" id="fnref44"><sup>44</sup></a>, it is difficult to know apriori which assumption will best match the data we have. Typically, in machine learning, you take a collection of methods and try them out to empirically validate which one works the best for your problem. This process not only helps you select the best method for your problem but also helps you understand the structure of your data. We will give an overview of leading methods that are being used today in this chapter.</p></li>
<li><p><strong>Model Interpretation</strong>: Once we have built the machine learning models, we also want to understand what they are, which predictors they found important, and how much, what types of entities they flagged as high risk (and why), where they made errors, etc. All of these fall under the model interpretation, interpretability, explainability umbrella which is an active area of research right now in machine learning.</p></li>
<li><p><strong>Model Selection</strong>: As you build a large number of possible models, you need a way to select the model that is the “best”. This part of the chapter will cover methodology to first test the models on historical data as well as discuss a variety of evaluation metrics. While this chapter will focus mostly on traditionally used metrics, Chapter <a href="chap-bias.html#chap:bias">Bias and Fairness</a> will expand on this using bias and fairness related metrics. It is important to note that sometimes the machine learning literature will call this step the “validation” step using historical data, but we want to distinguish it here from validation, which is the next step.</p></li>
<li><p><strong>Model Validation</strong>: The next step, after model selection (using historical data) is validation. Validate on new data, as well as designing and running field trials or experiments.</p></li>
<li><p><strong>Deployment and Monitoring</strong>: Once you have selected the best model and validated it using historical data as well as a field trial, you are ready to put the model into practice. You still have to keep in mind that new data will be coming in, the world will be changing, and the model might also (need to) change over time. We will not cover too much of those aspects in this chapter, but they are important to keep in mind when putting the machine learning work in to practice.</p></li>
</ol>
<!--Although each step in this process is critical, this chapter will not focus on step 3 (data exploration) because we assume you already have some experience doing that, and on step 7 (deployment) because, although critical, it is outside the scope of the book. MALTE: There are more steps than 3 and 7 that we mostly ignore. -->
<p>Although each step in this process is critical, a thorough description of each is out of scope. This chapter will focus on models, terms, and techniques that form the core of machine learning.</p>
</div>
<div id="problem-formulation-mapping-a-problem-to-machine-learning-methods" class="section level2">
<h2><span class="header-section-number">7.5</span> Problem formulation: Mapping a problem to machine learning methods</h2>
<p>When working on a new problem, one of the first things we need to do is to map it to a class of machine learning methods. In general, the problems we will tackle, including the examples above, can be grouped into two major categories:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Supervised learning</strong>: These are problems where there exists a target variable (continuous or discrete) that we want to predict or classify data into. Classification, prediction, and regression all fall into this category. More formally, supervised learning methods predict a value <span class="math inline">\(Y\)</span> given input(s) <span class="math inline">\(X\)</span> by learning (or estimating or fitting or training) a function <span class="math inline">\(F\)</span>, where <span class="math inline">\(F(X) = Y\)</span>. Here, <span class="math inline">\(X\)</span> is the set of variables (known as <em>features</em> in machine learning, or in other fields as <em>predictors</em>) provided as input and <span class="math inline">\(Y\)</span> is the target/dependent variable or a <em>label</em> (as it is known in machine learning).</p>
<p>The goal of supervised learning methods is to search for that function <span class="math inline">\(F\)</span> that best estimates or predicts <span class="math inline">\(Y\)</span>. When the output <span class="math inline">\(Y\)</span> is categorical, this is known as <em>classification</em>. When <span class="math inline">\(Y\)</span> is a continuous value, this is called <em>regression</em>. Sound familiar?</p>
<p>One key distinction in machine learning is that the goal is not just to find the best function <span class="math inline">\(F\)</span> that can estimate or predict <span class="math inline">\(Y\)</span> for observed outcomes (known <span class="math inline">\(Y\)</span>s) but to find one that best generalizes to new, unseen data, often in the future. This distinction makes methods more focused on generalization and less on just fitting the data we have as best as we can. It is important to note that you do that implicitly when performing regression by not adding more and more higher-order terms to get better fit statistics. By getting better fit statistics, we <em>overfit</em> to the data and the performance on new (unseen) data often goes down. Methods like the lasso <span class="citation">(Tibshirani <a href="#ref-tibshirani1996regression">1996</a>)</span> penalize the model for having too many terms by performing what is known as <em>regularization</em><a href="#fn45" class="footnoteRef" id="fnref45"><sup>45</sup></a>.</p></li>
<li><p><strong>Unsupervised learning</strong>: These are problems where there does not exist a target variable that we want to predict but we want to understand “natural” groupings or patterns in the data. Clustering is the most common example of this type of analysis where you are given <span class="math inline">\(X\)</span> and want to group similar <span class="math inline">\(X\)</span>s together. You may have heard of “segmentation” that’s used in the marketing world to group similar customers together using clustering techniques. Principal components analysis (PCA) and related methods also fall into the unsupervised learning category.</p></li>
</ol>
<p>In between the two extremes of supervised and unsupervised learning, there is a spectrum of methods that have different levels of supervision involved (Figure <a href="chap-ml.html#fig:spectrum">7.1</a>). Supervision in this case is the presence of target variables (known in machine learning as <em>labels</em>). In unsupervised learning, none of the data points have labels. In supervised learning, all data points have labels. In between, either the percentage of examples with labels can vary or the types of labels can vary. We do not cover the weakly supervised and semi-supervised methods much in this chapter, but this is an active area of research in machine learning. Zhu <span class="citation">(Zhu <a href="#ref-zhu2005semi">2008</a>)</span> provides more details.</p>
<div class="figure" style="text-align: center"><span id="fig:spectrum"></span>
<img src="ChapterML/figures/spectrum.png" alt="Spectrum of machine learning methods from unsupervised to supervised learning" width="70%" />
<p class="caption">
Figure 7.1: Spectrum of machine learning methods from unsupervised to supervised learning
</p>
</div>
<div id="features" class="section level3">
<h3><span class="header-section-number">7.5.1</span> Features</h3>
<p>Before we get to models and methods, we need to turn our raw data into “features”. In social science, they are not called features but instead are known as variables or predictors (or covariates if you’re doing regression). <span class="roman">Good features are what makes machine learning systems effective</span>. Feature generation (or engineering, as it is often called) is where a large chunk of the time is spent in the machine learning process. This is also the phase where previous research and learnings from the domain being tackled can be incorporated into the machine learning process. As social science researchers or practitioners, you have spent a lot of time constructing features, using transformations, dummy variables, and interaction terms. All of that is still required and critical in the machine learning framework. One difference you will need to get comfortable with is that instead of carefully selecting a few predictors, machine learning systems tend to encourage the creation of <em>lots</em> of features and then empirically use holdout data to perform regularization and model selection. It is common to have models that are trained on thousands of features. Of course, it is important to keep in mind that increasing the number of features requires you to have enough data so that you’re not overfitting. Commonly used approaches to create features include:</p>
<ul>
<li><p><strong>Transformations</strong>, such as log, square, and square root.</p></li>
<li><p><strong>Dummy (binary) variables</strong>: This is often done by taking categorical variables (such as city) and creating a binary variable for each value (one variable for each city in the data). These are also called indicator variables.</p></li>
<li><p><strong>Discretization</strong>: Several methods require features to be discrete instead of continuous. Several approaches exist to convert continuous variables into discrete ones, the most common of which is equal-width binning.</p></li>
<li><p><strong>Aggregation</strong>: Aggregate features often constitute the majority of features for a given problem. These aggregations use different aggregation functions (count, min, max, average, standard deviation, etc.), often over varying windows of time and space. For example, given urban data, we would want to calculate the number (and min, max, mean, variance) of crimes within an <span class="math inline">\(m\)</span>-mile radius of an address in the past <span class="math inline">\(t\)</span> months for varying values of <span class="math inline">\(m\)</span> and <span class="math inline">\(t\)</span>, and then to use all of them as features in a classification problem. Spatiotemporal aggregation features are going to be extremely important as you build machine learning models.</p></li>
</ul>
<p>In general, it is a good idea to have the complexity in features and use a simple model, rather than using more complex models with simple features. Keeping the model simple makes it faster to train and easier to understand and explain.</p>
<!--
%  [ideally give a reference with list of features]
-->
</div>
</div>
<div id="methods" class="section level2">
<h2><span class="header-section-number">7.6</span> Methods</h2>
<p>We will start by describing unsupervised learning methods and then go on to supervised learning methods. We focus here on the intuition behind the methods and the algorithm, as well as some practical tips, rather than on the statistical theory that underlies the methods. We encourage readers to refer to machine learning books listed in Section <a href="chap-ml.html#ml:res">Resources</a>. Box 7.2 gives brief definitions of several terms we will use in this section.</p>
<div class="F00">
<p>
<strong>Box 7.2: Machine learning vocabulary</strong>
</p>
<ul>
<li>
<p>
<strong>Learning</strong>: In machine learning, you will notice the term <em>learning</em> that will be used in the context of “learning” a model. This is what you probably know as <em>fitting</em> or <em>estimating</em> a function, or <em>training</em> or <em>building</em> a model. These terms are all synonyms and are used interchangeably in the machine learning literature.
</p>
</li>
<li>
<p>
<strong>Examples</strong>: These are data points, rows, observations, or instances.
</p>
</li>
<li>
<p>
<strong>Features</strong>: These are independent variables, attributes, predictor variables, and explanatory variables.
</p>
</li>
<li>
<p>
<strong>Labels</strong>: These include the response variable, dependent variable, target variable, or outcomes.
</p>
</li>
<li>
<p>
<strong>Underfitting</strong>: This happens when a model is too simple and does not capture the structure of the data well enough.
</p>
</li>
<li>
<p>
<strong>Overfitting</strong>: This happens when a model is possibly too complex and models the noise in the data, which can result in poor generalization performance. Using in-sample measures to do model selection can result in that.
</p>
</li>
<li>
<p>
<strong>Regularization</strong>: This is a general method to avoid overfitting by applying additional constraints to the model that is learned. For example, in building logistic regression models, a common approach is to make sure the model weights (coefficients) are, on average, small in magnitude. Two common regularizations are <span class="math inline"><span class="math inline">\(L_1\)</span></span> regularization (used by the lasso), which has a penalty term that encourages the sum of the absolute values of the parameters to be small; and <span class="math inline"><span class="math inline">\(L_2\)</span></span> regularization, which encourages the sum of the squares of the parameters to be small.
</p>
</li>
</ul>
</div>
<div id="unsupervised-learning-methods" class="section level3">
<h3><span class="header-section-number">7.6.1</span> Unsupervised learning methods</h3>
<p>As mentioned earlier, unsupervised learning methods are used when we do not have a target variable to estimate or predict but want to understand clusters, groups, or patterns in the data. These methods are often used for data exploration, as in the following examples:</p>
<ol style="list-style-type: decimal">
<li><p>When faced with a large corpus of text data—for example, email records, congressional bills, speeches, or open-ended free-text survey responses—unsupervised learning methods are often used to understand and get a handle on the patterns in our data.</p></li>
<li><p>Given a data set about students and their behavior over time (academic performance, grades, test scores, attendance, etc.), one might want to understand typical behaviors as well as trajectories of these behaviors over time. Unsupervised learning methods (clustering) can be applied to these data to get student “segments” with similar behavior.</p></li>
<li><p>Given a data set about publications or patents in different fields, we can use unsupervised learning methods (association rules) to figure out which disciplines have the most collaboration and which fields have researchers who tend to publish across different fields.</p></li>
<li><p>Given a set of people who are at high risk of recidivism, clustering can be used to understand different groups of people within the high risk set, to determine intervention programs that may need to be created.</p></li>
</ol>
<p><strong>Clustering</strong></p>
<p>Clustering is the most common unsupervised learning technique and is used to group data points together that are similar to each other. The goal of clustering methods is to produce with high intra-cluster (within) similarity and low inter-cluster (between) similarity.</p>
<p>Clustering algorithms typically require a distance (or similarity) metric<a href="#fn46" class="footnoteRef" id="fnref46"><sup>46</sup></a> to generate clusters. They take a data set and a distance metric (and sometimes additional parameters), and they generate clusters based on that distance metric. The most common distance metric used is Euclidean distance, but other commonly used metrics are Manhattan, Minkowski, Chebyshev, cosine, Hamming, Pearson, and Mahalanobis. Often, domain-specific similarity metrics can be designed for use in specific problems. For example, when performing the record linkage tasks discussed in Chapter <a href="chap-link.html#chap:link">Record Linkage</a>, you can design a similarity metric that compares two first names and assigns them a high similarity (low distance) if they both map to the same canonical name, so that, for example, Sammy and Sam map to Samuel.</p>
<p>Most clustering algorithms also require the user to specify the number of clusters (or some other parameter that indirectly determines the number of clusters) in advance as a parameter. This is often difficult to do a priori and typically makes clustering an iterative and interactive task. Another aspect of clustering that makes it interactive is often the difficulty in automatically evaluating the quality of the clusters. While various analytical clustering metrics have been developed, the best clustering is task-dependent and thus must be evaluated by the user. There may be different clusterings that can be generated with the same data. You can imagine clustering similar news stories based on the topic content, based on the writing style or based on sentiment. The right set of clusters depends on the user and the task they have. Clustering is therefore typically used for exploring the data, generating clusters, exploring the clusters, and then rerunning the clustering method with different parameters or modifying the clusters (by splitting or merging the previous set of clusters). Interpreting a cluster can be nontrivial: you can look at the centroid of a cluster, look at frequency distributions of different features (and compare them to the prior distribution of each feature), or you can build a decision tree (a supervised learning method we will cover later in this chapter) where the target variable is the cluster ID that can describe the cluster using the features in your data. A good example of a tool that allows interactive clustering from text data is Ontogen <span class="citation">(Fortuna, Grobelnik, and Mladenic <a href="#ref-Ontogen">2007</a>)</span>.</p>
<p><strong><span class="math inline">\(k\)</span>-means clustering</strong></p>
<p>The most commonly used clustering algorithm is called <span class="math inline">\(k\)</span>-means, where <span class="math inline">\(k\)</span> defines the number of clusters. The algorithm works as follows:</p>
<ol style="list-style-type: decimal">
<li><p>Select <span class="math inline">\(k\)</span> (the number of clusters you want to generate).</p></li>
<li><p>Initialize by selecting <span class="math inline">\(k\)</span> points as centroids of the <span class="math inline">\(k\)</span> clusters. This is typically done by selecting <span class="math inline">\(k\)</span> points uniformly at random.</p></li>
<li><p>Assign each point a cluster according to the nearest centroid.</p></li>
<li><p>Recalculate cluster centroids based on the assignment in (3) as the mean of all data points belonging to that cluster.</p></li>
<li><p>Repeat (3) and (4) until convergence.</p></li>
</ol>
<p>The algorithm stops when the assignments do not change from one iteration to the next (Figure <a href="chap-ml.html#fig:kmeans">7.2</a>). The final set of clusters, however, depend on the starting points. If they are initialized differently, it is possible that different clusters are obtained. One common practical trick is to run <span class="math inline">\(k\)</span>-means several times, each with different (random) starting points. The <span class="math inline">\(k\)</span>-means algorithm is fast, simple, and easy to use, and is often a good first clustering algorithm to try and see if it fits your needs. When the data are of the form where the mean of the data points cannot be computed, a related method called <span class="math inline">\(K\)</span>-medoids can be used <span class="citation">(Park and Jun <a href="#ref-park2009simple">2009</a>)</span>.</p>
<div class="figure" style="text-align: center"><span id="fig:kmeans"></span>
<img src="ChapterML/figures/kmeans.png" alt="Example of $k$-means clustering with $k = 3$. The upper left panel shows the distribution of the data and the three starting points $m_1$, $m_2$, $m_3$ placed at random. On the upper right we see what happens in the first iteration. The cluster means move to more central positions in their respective clusters. The lower left panel shows the second iteration. After six iterations the cluster means have converged to their final destinations and the result is shown in the lower right panel" width="70%" />
<p class="caption">
Figure 7.2: Example of <span class="math inline">\(k\)</span>-means clustering with <span class="math inline">\(k = 3\)</span>. The upper left panel shows the distribution of the data and the three starting points <span class="math inline">\(m_1\)</span>, <span class="math inline">\(m_2\)</span>, <span class="math inline">\(m_3\)</span> placed at random. On the upper right we see what happens in the first iteration. The cluster means move to more central positions in their respective clusters. The lower left panel shows the second iteration. After six iterations the cluster means have converged to their final destinations and the result is shown in the lower right panel
</p>
</div>
<p><strong>Expectation-maximization (EM) clustering</strong></p>
<p>You may be familiar with the EM algorithm in the context of imputing missing data. EM is a general approach to maximum likelihood in the presence of incomplete data. However, it is also used as a clustering method where the missing data are the clusters a data point belongs to. Unlike <span class="math inline">\(k\)</span>-means, where each data point gets assigned to only one cluster, EM does a soft assignment where each data point gets a probabilistic assignment to various clusters. The EM algorithm iterates until the estimates converge to some (locally) optimal solution.</p>
<p>The EM algorithm is fairly good at dealing with outliers as well as high-dimensional data, compared to <span class="math inline">\(k\)</span>-means. It also has a few limitations. First, it does not work well with a large number of clusters or when a cluster contains few examples. Also, when the value of <span class="math inline">\(k\)</span> is larger than the number of actual clusters in the data, EM may not give reasonable results.</p>
<p><strong>Mean shift clustering</strong></p>
<p>Mean shift clustering works by finding dense regions in the data by defining a window around each data point and computing the mean of the data points in the window. Then it shifts the center of the window to the mean and repeats the algorithm till it converges. After each iteration, we can consider that the window shifts to a denser region of the data set. The algorithm proceeds as follows:</p>
<ol style="list-style-type: decimal">
<li><p>Fix a window around each data point (based on the bandwidth parameter that defines the size of the window).</p></li>
<li><p>Compute the mean of data within the window.</p></li>
<li><p>Shift the window to the mean and repeat till convergence.</p></li>
</ol>
<p>Mean shift needs a bandwidth parameter <span class="math inline">\(h\)</span> to be tuned, which influences the convergence rate and the number of clusters. A large <span class="math inline">\(h\)</span> might result in merging distinct clusters. A small <span class="math inline">\(h\)</span> might result in too many clusters. Mean shift might not work well in higher dimensions since the number of local maxima is pretty high and it might converge to a local optimum quickly.</p>
<p>One of the most important differences between mean shift and <span class="math inline">\(k\)</span>-means is that <span class="math inline">\(k\)</span>-means makes two broad assumptions: the number of clusters is already known and the clusters are shaped spherically (or elliptically). Mean shift does not assume anything about the number of clusters (but the value of <span class="math inline">\(h\)</span> indirectly determines that). Also, it can handle arbitrarily shaped clusters.</p>
<p>The <span class="math inline">\(k\)</span>-means algorithm is also sensitive to initializations, whereas mean shift is fairly robust to initializations. Typically, mean shift is run for each point, or sometimes points are selected uniformly randomly. Similarly, <span class="math inline">\(k\)</span>-means is sensitive to outliers, while mean shift is less sensitive. On the other hand, the benefits of mean shift come at a cost—speed. The <span class="math inline">\(k\)</span>-means procedure is fast, whereas classic mean shift is computationally slow but can be easily parallelized.</p>
<p><strong>Hierarchical clustering</strong></p>
<p>The clustering methods that we have seen so far, often termed <em>partitioning</em> methods, produce a flat set of clusters with no hierarchy. Sometimes, we want to generate a hierarchy of clusters, and methods that can do that are of two types:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Agglomerative (bottom-up)</strong>: Start with each point as its own cluster and iteratively merge the closest clusters. The iterations stop either when the clusters are too far apart to be merged (based on a predefined distance criterion) or when there is a sufficient number of clusters (based on a predefined threshold).</p></li>
<li><p><strong>Divisive (top-down)</strong>: Start with one cluster and create splits recursively.</p></li>
</ol>
<p>Typically, agglomerative clustering is used more often than divisive clustering. One reason is that it is significantly faster, although both of them are typically slower than direct partition methods such as <span class="math inline">\(k\)</span>-means and EM. Another disadvantage of these methods is that they are <em>greedy</em>, that is, a data point that is incorrectly assigned to the “wrong” cluster in an earlier split or merge cannot be reassigned again later on.</p>
<p><strong>Spectral clustering</strong></p>
<p>Figure <a href="chap-ml.html#fig:spectral">7.3</a> shows the clusters that <span class="math inline">\(k\)</span>-means would generate on the data set in the figure. It is obvious that the clusters produced are not the clusters you would want, and that is one drawback of methods such as <span class="math inline">\(k\)</span>-means. Two points that are far away from each other will be put in different clusters even if there are other data points that create a “path” between them. Spectral clustering fixes that problem by clustering data that are connected but not necessarily (what is called) compact or clustered within convex boundaries. Spectral clustering methods work by representing data as a graph (or network), where data points are nodes in the graph and the edges (connections between nodes) represent the similarity between the two data points.</p>
<div class="figure" style="text-align: center"><span id="fig:spectral"></span>
<img src="ChapterML/figures/spectral.png" alt="The same data set can produce drastically different clusters: (a) k-means; (b) spectral clustering" width="70%" />
<p class="caption">
Figure 7.3: The same data set can produce drastically different clusters: (a) k-means; (b) spectral clustering
</p>
</div>
<p>The algorithm works as follows:</p>
<ol style="list-style-type: decimal">
<li><p>Compute a similarity matrix from the data. This involves determining a pairwise distance function (using one of the distance functions we described earlier).</p></li>
<li><p>With this matrix, we can now perform graph partitioning, where connected graph components are interpreted as clusters. The graph must be partitioned such that edges connecting different clusters have low weights and edges within the same cluster have high values.</p></li>
<li><p>We can now partition these data represented by the similarity matrix in a variety of ways. One common way is to use the normalized cuts method. Another way is to compute a graph Laplacian from the similarity matrix.</p></li>
<li><p>Compute the eigenvectors and eigenvalues of the Laplacian.</p></li>
<li><p>The <span class="math inline">\(k\)</span> eigenvectors are used as proxy data for the original data set, and they are fed into <span class="math inline">\(k\)</span>-means clustering to produce cluster assignments for each original data point.</p></li>
</ol>
<p>Spectral clustering is in general much better than <span class="math inline">\(k\)</span>-means in clustering performance but much slower to run in practice. For large-scale problems, <span class="math inline">\(k\)</span>-means is a preferred clustering algorithm to run because of efficiency and speed.</p>
<p><strong>Principal components analysis</strong></p>
<p>Principal components analysis is another unsupervised method used for finding patterns and structure in data. In contrast to clustering methods, the output is not a set of clusters but a set of <em>principal components</em> that are linear combinations of the original variables. PCA is typically used when you have a large number of variables and you want a reduced number that you can analyze. This approach is often called <em>dimensionality reduction</em>. It generates linearly uncorrelated dimensions that can be used to understand the underlying structure of the data. In mathematical terms, given a set of data on <span class="math inline">\(n\)</span> dimensions, PCA aims to find a linear subspace of dimension <span class="math inline">\(d\)</span> lower than <span class="math inline">\(n\)</span> such that the data points lie mainly on this linear subspace.</p>
<p>PCA is related to several other methods you may already know about. Multidimensional scaling, factor analysis, and independent component analysis differ from PCA in the assumptions they make, but they are often used for similar purposes of dimensionality reduction and discovering the underlying structure in a data set.</p>
<p><strong>Association rules</strong></p>
<p>Association rules are a different type of analysis method and originate from the data mining and database community, primarily focused on finding frequent co-occurring associations among a collection of items. This method is sometimes referred to as “market basket analysis,” since that was the original application area of association rules. The goal is to find associations of items that occur together more often than you would randomly expect. The classic example (probably a myth) is “men who go to the store to buy diapers will also tend to buy beer at the same time.” This type of analysis would be performed by applying association rules to a set of supermarket purchase data. For social scientists, this method can be used on data that contains social services that individuals have received in the past to determine what types of services “co-occur” in people and proactively offer those services to people in need.</p>
<p>Association rules take the form <span class="math inline">\(X_1, X_2, X_3 \Rightarrow Y\)</span> with support <span class="math inline">\(S\)</span> and confidence <span class="math inline">\(C\)</span>, implying that when a transaction contains items <span class="math inline">\(\{X_1, X_2, X_3\}\)</span> <span class="math inline">\(C\)</span>% of the time, they also contain item <span class="math inline">\(Y\)</span> and there are at least <span class="math inline">\(S\)</span>% of transactions where the antecedent is true. This is useful in cases where we want to find patterns that are both <em>frequent</em> and <em>statistically significant</em>, by specifying thresholds for support <span class="math inline">\(S\)</span> and confidence <span class="math inline">\(C\)</span>.</p>
<p>Support and confidence are useful metrics to generate rules but are often not enough. Another important metric used to generate rules (or reduce the number of spurious patterns generated) is <em>lift</em>. Lift is simply estimated by the ratio of the joint probability of two items, <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>, to the product of their individual probabilities: <span class="math inline">\(P(x,y)/[P(x)P(y)]\)</span>. If the two items are statistically independent, then <span class="math inline">\(P(x,y)=P(x)P(y)\)</span>, corresponding to a lift of <span class="math inline">\(1\)</span>. Note that anti-correlation yields lift values less than 1, which is also an interesting pattern, corresponding to mutually exclusive items that rarely occur together.</p>
<p>Association rule algorithms work as follows: Given a set of transactions (rows) and items for that transaction:</p>
<ol style="list-style-type: decimal">
<li><p>Find all combinations of items in a set of transactions that occur with a specified minimum frequency. These combinations are called <em>frequent itemsets</em>.</p></li>
<li><p>Generate association rules that express co-occurrence of items within frequent itemsets.</p></li>
</ol>
<p>For our purposes, association rule methods are an efficient way to take a <em>basket</em> of features (e.g., areas of publication of a researcher, different organizations an individual has worked at in their career, all the cities or neighborhoods someone may have lived in) and find co-occurrence patterns. This may sound trivial, but as data sets and number of features get larger, it becomes computationally expensive and association rule mining algorithms provide a fast and efficient way of doing it.</p>
</div>
<div id="sec:MLchapter:super" class="section level3">
<h3><span class="header-section-number">7.6.2</span> Supervised learning</h3>
<p>We now turn to the problem of supervised learning, which typically involves methods for classification, prediction, and regression. We will mostly focus on classification methods in this chapter since many of the regression methods in machine learning are fairly similar to methods with which you are already familiar. Remember that classification means predicting a discrete (or categorical) variable. Most of the classification methods that we will cover can also be used for Regression (predicting continuous outcomes).</p>
<p>In general, supervised learning methods take as input pairs of data points <span class="math inline">\((X,Y)\)</span> where <span class="math inline">\(X\)</span> are the predictor variables (features) and <span class="math inline">\(Y\)</span> is the target variable (label). The supervised learning method then uses these pairs as <em>training data</em> and <em>learns</em> a model <span class="math inline">\(F\)</span>, where <span class="math inline">\(F(X)\sim Y\)</span>. This model <span class="math inline">\(F\)</span> is then used to predict <span class="math inline">\(Y\)</span>s for new data points <span class="math inline">\(X\)</span>. As mentioned earlier, the goal is not to build a model that best fits known data but a model that is useful for future predictions and minimizes future generalization error. This is the key goal that differentiates many of the methods that you know from the methods that we will describe next. In order to minimize future error, we want to build models that are not just <em>overfitting</em> on past data.</p>
<p>Another goal, often prioritized in the social sciences, that machine learning methods do not optimize for is getting a structural form of the model. Machine learning models for classification can take different structural forms (ranging from linear models, to sets of rules, to more complex non-linear forms), and it may not always be possible to write them down in a compact form as an equation. This does not, however, make them incomprehensible or uninterpretable. Another focus of machine learning models for supervised learning is prediction, and not necessarily causal inference<a href="#fn47" class="footnoteRef" id="fnref47"><sup>47</sup></a>. Some of these models can be used to help with causal inference, but they are typically optimized for prediction tasks. We believe that there are many social science and policy problems where better prediction methods can be extremely beneficial <span class="citation">(Kleinberg et al. <a href="#ref-Kleinberg2015">2015</a>)</span>. <!-- reference already exists in section 7.7 --></p>
<p>In this chapter, we mostly deal with binary classification problems: that is, problems in which the data points are to be classified into one of two categories. Several of the methods that we will cover can also be used for multiclass classification (classifying a data point into one of <span class="math inline">\(n\)</span> categories) or for multi-label classification (classifying a data point into <span class="math inline">\(m\)</span> of <span class="math inline">\(n\)</span> categories where <span class="math inline">\(m\ge1\)</span>). There are also approaches to take multiclass problems and turn them into a set of binary problems that we will mention briefly in the next section.</p>
<p>Before we describe supervised learning methods, we want to recap a few principles as well as terms that we have used and will be using in the rest of the chapter.</p>
<p><strong>Training a model</strong></p>
<p>Once we have finished data exploration, filled in missing values, created predictor variables (features), and decided what our target variable (label) is, we now have pairs of <span class="math inline">\(X,Y\)</span> to start training (or building) the model.</p>
<p><strong>Using the model to score new data</strong></p>
<p>We are building this model so we can predict <span class="math inline">\(Y\)</span> for a new set of <span class="math inline">\(X\)</span>s—using the model means, getting new data, generating the same features to get the vector <span class="math inline">\(X\)</span>, and then applying the model to produce <span class="math inline">\(Y\)</span>.</p>
<p>One common technique for supervised learning is logistic regression, a method you will already be familiar with. We will give an overview of some of the other methods used in machine learning. It is important to remember that as you use increasingly powerful classification methods, you need more data to <em>train</em> the models.</p>
<p><strong><span class="math inline">\(k\)</span>-nearest neighbor</strong></p>
<p>The method <span class="math inline">\(k\)</span>-nearest neighbor (<span class="math inline">\(k\)</span>-NN) is one of the simpler classification methods in machine learning. It belongs to a family of models sometimes known as <em>memory-based models</em> or <em>instance-based models</em>. An example is classified by finding its <span class="math inline">\(k\)</span> nearest neighbors and taking majority vote (or some other aggregation function). We need two key things: a value for <span class="math inline">\(k\)</span> and a distance metric with which to find the <span class="math inline">\(k\)</span> nearest neighbors. Typically, different values of <span class="math inline">\(k\)</span> are used to empirically find the best one. Small values of <span class="math inline">\(k\)</span> lead to predictions having high variance but can capture the local structure of the data. Larger values of <span class="math inline">\(k\)</span> build more global models that are lower in variance but may not capture local structure in the data as well.</p>
<p>Figure <a href="chap-ml.html#fig:knn">7.4</a> provides an example for <span class="math inline">\(k = 1, 3, 5\)</span> nearest neighbors. The number of neighbors (<span class="math inline">\(k\)</span>) is a parameter, and the prediction depends heavily on how it is determined. In this example, point B is classified differently if <span class="math inline">\(k = 3\)</span>.</p>
<div class="figure" style="text-align: center"><span id="fig:knn"></span>
<img src="ChapterML/figures/knn.png" alt="Example of $k$-nearest neighbor with $k = 1, 3, 5$ neighbors. We want to predict the points A and B. The 1-nearest neighbor for both points is red (&quot;Patent not granted&quot;), the 3-nearest neighbor predicts point A (B) to be red (green) with probability 2/3, and the 5-nearest neighbor predicts again both points to be red with probabilities 4/5 and 3/5, respectively." width="70%" />
<p class="caption">
Figure 7.4: Example of <span class="math inline">\(k\)</span>-nearest neighbor with <span class="math inline">\(k = 1, 3, 5\)</span> neighbors. We want to predict the points A and B. The 1-nearest neighbor for both points is red (“Patent not granted”), the 3-nearest neighbor predicts point A (B) to be red (green) with probability 2/3, and the 5-nearest neighbor predicts again both points to be red with probabilities 4/5 and 3/5, respectively.
</p>
</div>
<p>Training for <span class="math inline">\(k\)</span>-NN just means storing the data, making this method useful in applications where data are coming in extremely quickly and a model needs to be updated frequently. All the work, however, gets pushed to scoring time, since all the distance calculations happen when a new data point needs to be classified. There are several optimized methods designed to make <span class="math inline">\(k\)</span>-NN more efficient that are worth looking into if that is a situation that is applicable to your problem.</p>
<p>In addition to selecting <span class="math inline">\(k\)</span> and an appropriate distance metric, we also have to be careful about the scaling of the features. When distances between two data points are large for one feature and small for a different feature, the method will rely almost exclusively on the first feature to find the closest points. The smaller distances on the second feature are nearly irrelevant to calculate the overall distance. A similar problem occurs when continuous and categorical predictors are used together. To resolve the scaling issues, various options for rescaling exist. For example, a common approach is to center all features at mean <span class="math inline">\(0\)</span> and scale them to variance <span class="math inline">\(1\)</span>.</p>
<p>There are several variations of <span class="math inline">\(k\)</span>-NN. One of these is weighted nearest neighbors, where different features are weighted differently or different examples are weighted based on the distance from the example being classified. The method <span class="math inline">\(k\)</span>-NN also has issues when the data are sparse and has high dimensionality, which means that every point is far away from virtually every other point, and hence pairwise distances tend to be uninformative. This can also happen when a lot of features are irrelevant and drown out the relevant features’ signal in the distance calculations.</p>
<p>Notice that the nearest-neighbor method can easily be applied to regression problems with a real-valued target variable. In fact, the method is completely oblivious to the type of target variable and can potentially be used to predict text documents, images, and videos, based on the aggregation function after the nearest neighbors are found.</p>
<p><strong>Support vector machines</strong></p>
<p>Support vector machines are one of the most popular and best-performing classification methods in machine learning today. The mathematics behind SVMs has a lot of prerequisites that are beyond the scope of this book, but we will give you an intuition of how SVMs work, what they are good for, and how to use them.</p>
<p>We are all familiar with linear models (e.g., logistic regression) that separate two classes by fitting a line in two dimensions (or a hyperplane in higher dimensions) in the middle (see Figure <a href="chap-ml.html#fig:svm">7.5</a>). An important decision that linear models have to make is which linear separator we should prefer when there are several we can build.</p>
<div class="figure" style="text-align: center"><span id="fig:svm"></span>
<img src="ChapterML/figures/svm.png" alt="Support vector machines" width="100%" />
<p class="caption">
Figure 7.5: Support vector machines
</p>
</div>
<p>You can see in Figure <a href="chap-ml.html#fig:svm">7.5</a> that multiple lines offer a solution to the problem. Is any of them better than the others? We can intuitively define a criterion to estimate the worth of the lines: A line is bad if it passes too close to the points because it will be noise sensitive and it will not generalize correctly. Therefore, our goal should be to find the line passing as far as possible from all points.</p>
<p>The SVM algorithm is based on finding the hyperplane that maximizes the <em>margin</em> of the training data. The training examples that are closest to the hyperplane are called <em>support vectors</em> since they are <em>supporting</em> the margin (as the margin is only a function of the support vectors).</p>
<p>An important concept to learn when working with SVMs is <em>kernels</em>. SVMs are a specific instance of a class of methods called <em>kernel methods</em>. So far, we have only talked about SVMs as linear models. Linear works well in high-dimensional data but sometimes you need nonlinear models, often in cases of low-dimensional data or in image or video data. Unfortunately, traditional ways of generating nonlinear models get computationally expensive since you have to explicitly generate all the features such as squares, cubes, and all the interactions. Kernels are a way to keep the efficiency of the linear machinery but still build models that can capture nonlinearity in the data without creating all the nonlinear features.</p>
<p>You can essentially think of kernels as similarity functions and use them to create a linear separation of the data by (implicitly) mapping the data to a higher-dimensional space. Essentially, we take an <span class="math inline">\(n\)</span>-dimensional input vector <span class="math inline">\(X\)</span>, map it into a high-dimensional (infinite-dimensional) feature space, and construct an optimal separating hyperplane in this space. We refer you to relevant papers for more detail on SVMs and nonlinear kernels <span class="citation">(Shawe-Taylor and Cristianini <a href="#ref-ShaweTaylor2004">2004</a>; Scholkopf and Smola <a href="#ref-Scholkopf2001">2001</a>)</span>. SVMs are also related to logistic regression, but use a different loss/penalty function <span class="citation">(Hastie, Tibshirani, and Friedman <a href="#ref-HastieTibshirani">2001</a>)</span>.</p>
<p>When using SVMs, there are several parameters you have to optimize, ranging from the <em>regularization</em> parameter <span class="math inline">\(C\)</span>, which determines the tradeoff between minimizing the training error and minimizing model complexity, to more kernel-specific parameters. It is often a good idea to do a grid search to find the optimal parameters. Another tip when using SVMs is to normalize the features; one common approach to doing that is to normalize each data point to be a vector of unit length.</p>
<p>Linear SVMs are effective in high-dimensional spaces, especially when the space is sparse such as text classification where the number of data points (perhaps tens of thousands) is often much less than the number of features (a hundred thousand to a million or more). SVMs are also fairly robust when the number of irrelevant features is large (unlike the <span class="math inline">\(k\)</span>-NN approaches that we mentioned earlier) as well as when the class distribution is skewed, that is, when the class of interest is significantly less than 50% of the data.</p>
<p>One disadvantage of SVMs is that they do not directly provide probability estimates. They assign a score based on the distance from the margin. The farther a point is from the margin, the higher the magnitude of the score. This score is good for ranking examples, but getting accurate probability estimates takes more work and requires more labeled data to be used to perform probability calibrations.</p>
<p>In addition to classification, there are also variations of SVMs that can be used for regression <span class="citation">(Smola and Schölkopf <a href="#ref-SmolaRegression04">2004</a>)</span> and ranking <span class="citation">(Chapelle and Keerthi <a href="#ref-Chapelle2010">2010</a>)</span>.</p>
<p><strong>Decision trees</strong></p>
<p>Decision trees are yet another set of methods that are helpful for prediction. Typical decision trees learn a set of rules from training data represented as a tree. An exemplary decision tree is shown in Figure <a href="chap-ml.html#fig:tree">7.6</a>. Each level of a tree <em>splits</em> the tree to create a branch using a feature and a value (or range of values). In the example tree, the first split is made on the feature <em>number of visits in the past year</em> and the value <span class="math inline">\(4\)</span>. The second level of the tree now has two splits: one using <em>average length of visit</em> with value <span class="math inline">\(2\)</span> days and the other using the value <span class="math inline">\(10\)</span> days.</p>
<p><img src="ChapterML/figures/tree.png" width="70%" style="display: block; margin: auto;" /></p>
<div class="figure" style="text-align: center"><span id="fig:tree"></span>
<img src="ChapterML/figures/tree-rectangle.png" alt="An exemplary decision tree. The top figure is the standard representation for trees. The bottom figure offers an alternative view of the same tree. The feature space is partitioned into numerous rectangles, which is another way to view a tree, representing its nonlinear character more explicitly" width="70%" />
<p class="caption">
Figure 7.6: An exemplary decision tree. The top figure is the standard representation for trees. The bottom figure offers an alternative view of the same tree. The feature space is partitioned into numerous rectangles, which is another way to view a tree, representing its nonlinear character more explicitly
</p>
</div>
<p>Various algorithms exist to build decision trees. C4.5, CHAID, and CART (Classification and Regression Trees) are the most popular. Each needs to determine the next best feature to split on. The goal is to find feature splits that can best reduce class impurity in the data, that is, a split that will ideally put all (or as many as possible) positive class examples on one side and all (or as many as possible) negative examples on the other side. One common measure of impurity that comes from information theory is <em>entropy</em>, and it is calculated as <span class="math display">\[H(X) = -\sum_x p(x) \log p(x).\]</span></p>
<p>Entropy is maximum (1) when both classes have equal numbers of examples in a node. It is minimum (0) when all examples are from the same class. At each node in the tree, we can evaluate all the possible features and select the one that most reduces the entropy given the tree so far. This expected change in entropy is known as <em>information gain</em> and is one of the most common criteria used to create decision trees. Other measures that are used instead of information gain are Gini and chi-squared.</p>
<p>If we keep constructing the tree in this manner, selecting the next best feature to split on, the tree ends up fairly deep and tends to overfit the data. To prevent overfitting, we can either have a stopping criterion or <em>prune</em> the tree after it is fully grown. Common stopping criteria include minimum number of data points to have before doing another feature split, maximum depth, and maximum purity. Typical pruning approaches use holdout data (or cross-validation, which will be discussed later in this chapter) to cut off parts of the tree.</p>
<p>Once the tree is built, a new data point is classified by running it through the tree and, once it reaches a terminal node, using some aggregation function to give a prediction (classification or regression). Typical approaches include performing maximum likelihood (if the leaf node contains 10 examples, 8 positive and 2 negative, any data point that gets into that node will get an 80% probability of being positive). Trees used for regression often build the tree as described above but then fit a linear regression model at each leaf node.</p>
<p>Decision trees have several advantages. The interpretation of a tree is straightforward as long as the tree is not too large. Trees can be turned into a set of rules that experts in a particular domain can possibly dig deeper into, validate, and modify. Trees also do not require too much feature engineering. There is no need to create interaction terms since trees can implicitly do that by splitting on two features, one after another.</p>
<p>Unfortunately, along with these benefits come a set of disadvantages. Decision trees, in general, do not perform well, compared to SVMs, random forests, or logistic regression. They are also unstable: small changes in data can result in very different trees. The lack of stability comes from the fact that small changes in the training data may lead to different splitting points. As a consequence, the whole tree may take a different structure. The suboptimal predictive performance can be seen from the fact that trees partition the predictor space into a few rectangular regions, each one predicting only a single value (see the bottom part of Figure <a href="chap-ml.html#fig:tree">7.6</a>.</p>
<p><strong>Ensemble methods</strong></p>
<p>Combinations of models are generally known as model ensembles. They are among the most powerful techniques in machine learning, often outperforming other methods, although at the cost of increased algorithmic and model complexity.</p>
<p>The intuition behind building ensembles of models is to build several models, each somewhat different. This diversity can come from various sources such as: training models on subsets of the data; training models on subsets of the features; or a combination of these two.</p>
<p>Ensemble methods in machine learning have two things in common. First, they construct multiple, diverse predictive models from adapted versions of the training data (most often reweighted or resampled). Second, they combine the predictions of these models in some way, often by simple averaging or voting (possibly weighted).</p>
<p><strong>Bagging</strong></p>
<p>Bagging stands for “bootstrap aggregation”<a href="#fn48" class="footnoteRef" id="fnref48"><sup>48</sup></a>: we first create bootstrap samples from the original data and then aggregate the predictions using models trained on each bootstrap sample. Given a data set of size <span class="math inline">\(N\)</span>, the method works as follows:</p>
<ol style="list-style-type: decimal">
<li><p>Create <span class="math inline">\(k\)</span> bootstrap samples (with replacement), each of size <span class="math inline">\(N\)</span>, resulting in <span class="math inline">\(k\)</span> data sets. Only about 63% of the original training examples will be represented in any given bootstrapped set.</p></li>
<li><p>Train a model on each of the <span class="math inline">\(k\)</span> data sets, resulting in <span class="math inline">\(k\)</span> models.</p></li>
<li><p>For a new data point <span class="math inline">\(X\)</span>, predict the output using each of the <span class="math inline">\(k\)</span> models.</p></li>
<li><p>Aggregate the <span class="math inline">\(k\)</span> predictions (typically using average or voting) to get the prediction for <span class="math inline">\(X\)</span>.</p></li>
</ol>
<p>A nice feature of this method is that any underlying model can be used, but decision trees are often the most commonly used base model. One reason for this is that decision trees are typically high variance and unstable, that is, they can change drastically given small changes in data, and bagging is effective at reducing the variance of the overall model. Another advantage of bagging is that each model can be trained in parallel, making it efficient to scale to large data sets.</p>
<p><strong>Boosting</strong></p>
<p>Boosting is another popular ensemble technique, and it often results in improving the base classifier being used. In fact, if your only goal is improving accuracy, you will most likely find that boosting will achieve that. The basic idea is to keep training classifiers iteratively, each iteration focusing on examples that the previous one got wrong. At the end, you have a set of classifiers, each trained on smaller and smaller subsets of the training data. Given a new data point, all the classifiers predict the target, and a weighted average of those predictions is used to get the final prediction, where the weight is proportional to the accuracy of each classifier. The algorithm works as follows:</p>
<ol style="list-style-type: decimal">
<li><p>Assign equal weights to every example.</p></li>
<li><p>For each iteration:</p>
<ol style="list-style-type: decimal">
<li><p>Train classifier on the weighted examples.</p></li>
<li><p>Predict on the training data.</p></li>
<li><p>Calculate error of the classifier on the training data.</p></li>
<li><p>Calculate the new weighting on the examples based on the errors of the classifier.</p></li>
<li><p>Reweight examples.</p></li>
</ol></li>
<li><p>Generate a weighted classifier based on the accuracy of each classifier.</p></li>
</ol>
<p>One constraint on the classifier used within boosting is that it should be able to handle weighted examples (either directly or by replicating the examples that need to be overweighted). The most common classifiers used in boosting are decision stumps (single-level decision trees), but deeper trees can also work well.</p>
<p>Boosting is a common way to <em>boost</em> the performance of a classification method but comes with additional complexity, both in the training time and in interpreting the predictions. A disadvantage of boosting is that it is difficult to parallelize since the next iteration of boosting relies on the results of the previous iteration.</p>
<p>A nice property of boosting is its ability to identify outliers: examples that are either mislabeled in the training data, or are inherently ambiguous and hard to categorize. Because boosting focuses its weight on the examples that are more difficult to classify, the examples with the highest weight often turn out to be outliers. On the other hand, if the number of outliers is large (lots of noise in the data), these examples can hurt the performance of boosting by focusing too much on them.</p>
<p><strong>Random forests</strong></p>
<p>Given a data set of size <span class="math inline">\(N\)</span> and containing <span class="math inline">\(M\)</span> features, the random forest training algorithm works as follows:</p>
<ol style="list-style-type: decimal">
<li><p>Create <span class="math inline">\(n\)</span> bootstrap samples from the original data of size <span class="math inline">\(N\)</span>. Remember, this is similar to the first step in bagging. Increasing <span class="math inline">\(n\)</span> will lead to similar or better results, but also requires more computational resources. Typically <span class="math inline">\(n\)</span> ranges from 100 to a few thousand but is best determined empirically.</p></li>
<li><p>For each bootstrap sample, train a decision tree using <span class="math inline">\(m\)</span> features (where <span class="math inline">\(m\)</span> is typically much smaller than <span class="math inline">\(M\)</span>) at each node of the tree. The <span class="math inline">\(m\)</span> features are selected uniformly at random from the <span class="math inline">\(M\)</span> features in the data set, and the decision tree will select the best split among the <span class="math inline">\(m\)</span> features. The value of <span class="math inline">\(m\)</span> is held constant during the forest growing.</p></li>
<li><p>A new test example/data point is classified by all the trees, and the final classification is done by majority vote (or another appropriate aggregation method).</p></li>
</ol>
<p>Random forests often achieve remarkable results while being simple to use. They can be easily parallelized, making them efficient to run on large data sets, and can handle a large number of features, even with a lot of missing values. Random forests can get complex, with hundreds or thousands of trees that are fairly deep, so it is difficult to interpret the learned model. At the same time, they provide a nice way to estimate feature importance, giving a sense of what features were important in building the classifier.</p>
<p>Another nice aspect of random forests is the ability to compute a proximity matrix that gives the similarity between every pair of data points. This is calculated by computing the number of times two examples land in the same terminal node. The more that happens, the closer the two examples are. We can use this proximity matrix for clustering, locating outliers, or explaining the predictions for a specific example.</p>
<p><strong>Stacking</strong></p>
<p>Stacking is a technique that deals with the task of learning a meta-level classifier to combine the predictions of multiple base-level classifiers. This meta-algorithm is trained to combine the model predictions to form a final set of predictions. This can be used for both regression and classification. The algorithm works as follows:</p>
<ol style="list-style-type: decimal">
<li><p>Split the data set into <span class="math inline">\(n\)</span> equal-sized sets: <span class="math inline">\(set_1, set_2,\ldots,set_n\)</span>.</p></li>
<li><p>Train base models on all possible combinations of <span class="math inline">\(n-1\)</span> sets and, for each model, use it to predict on <span class="math inline">\(set_i\)</span> what was left out of the training set. This would give us a set of predictions on every data point in the original data set.</p></li>
<li><p>Now train a second-stage stacker model on the predicted classes or the predicted probability distribution over the classes from the first-stage (base) model(s).</p></li>
</ol>
<p>By using the first-stage predictions as features, a stacker model gets more information on the problem space than if it were trained in isolation. The technique is similar to cross-validation, an evaluation methodology that we will cover later in this chapter.</p>
<p><strong>Neural networks and deep learning</strong></p>
<p>Neural networks are a set of multi-layer classifiers where the outputs of one layer feed into the inputs of the next layer. The layers between the input and output layers are called <em>hidden layers</em>, and the more hidden layers a neural network has, the more complex functions it can learn. Neural networks were popular in the 1980s and early 1990s, but then fell out of fashion because they were slow and expensive to train, even with only one or two hidden layers. Since 2006, a set of techniques has been developed that enable learning in deeper neural networks. These techniques, with access to massive computational resources and large amounts of data, have enabled much deeper (and larger) networks to be Trained and it turns out that these perform far better on many problems than shallow neural networks (with just a single hidden layer). The reason for the better performance is the ability of deep nets to build up a complex hierarchy of concepts, learning multiple levels of representation and abstraction that help to make sense of data such as images, sound, and text.</p>
<p>There are a few different types of neural networks that are popular today:</p>
<ul>
<li><p>Convolutional Neural Networks (<strong>CNN</strong>s): These are often used in detecting objects in images and in doing image search, but their applicability goes beyond just image analysis and they can be used to find patterns in other types of data as well. CNNs treat input data (such as images) in a spatial manner (in two or three dimensions for example), and are able to capture spatial dependencies in the data.</p></li>
<li><p>Recurrent Neural Networks (<strong>RNN</strong>s): are suitable for modeling sequential data that has temporal dependencies. They are trained to generate the next steps in a sequence, such as the next letters in a word, or the next words in a sentence, voice recording, or video. They are typically used in translation, speech generation, and time series prediction tasks. A popular variation of RNNs is LSTM (Long Short Term Memory) that are used because of their ability and effectiveness in modeling long-range dependencies.</p></li>
<li><p>Generative Adversarial Network (<strong>GAN</strong>s): have been shown to be quite adept at generating new, realistic images based on other training images. GANs train two models in parallel. One network (called generator) is trained to generate data (based on historical examples of previously occurring data such as images or text or video). The other network (discriminator) tries to classify these generated images as real or synthetic. During training a GAN, the goal is to generate data that is realistic enough that the discriminator network is fooled to the point that it cannot distinguish the difference between the real and the synthetic input data.</p></li>
</ul>
<p>Goodfellow et al. <span class="citation">(<a href="#ref-Goodfellow2016">2016</a>)</span> provide a (mathematical) introduction to deep learning.</p>
<p>Currently, deep neural networks are popular for a certain class of problems and a lot of research is being done on them. It is, however, important to keep in mind that they may often require a lot more data than are available in many problems. In many problems, such as natural language processing, image, and video analysis, there are techniques to start from a pre-trained neural network model, that reduces the need for additional training data. Training deep neural networks also requires a lot of computational power, but that is less likely to be an issue for most people today with increased access to computing resources. Typical cases where deep learning has been shown to be effective involve lots of images, video, and text data. We are in the early stages of development of this class of methods, and although there seems to be a lot of potential, we need a much better understanding of why they are effective and the problems for which they are well suited.</p>
</div>
<div id="binary-vs-multiclass-classification-problems" class="section level3">
<h3><span class="header-section-number">7.6.3</span> Binary vs Multiclass classification problems</h3>
<p>In the discussion above, we framed classification problems as binary classification problems with a 0 or 1 output. There are many problems where we have multiple classes, such as classifying companies into their industry codes or predicting whether a student will drop out, transfer, or graduate. Several solutions have been designed to deal with the multiclass classification problem:</p>
<ul>
<li><p><strong>Direct multiclass</strong>: Use methods that can directly perform multiclass classification. Examples of such methods are <span class="math inline">\(K\)</span>-nearest neighbor, decision trees, and random forests. There are extensions of support vector machines that exist for multiclass classification as well <span class="citation">(Crammer and Singer <a href="#ref-crammer2002">2002</a>)</span>, but they can often be slow to train.</p></li>
<li><p><strong>Convert to one versus all (OVA)</strong>: This is a common approach to solve multiclass classification problems using binary classifiers. Any problem with <span class="math inline">\(n\)</span> classes can be turned into <span class="math inline">\(n\)</span> binary classification problems, where each classifier is trained to distinguish between one versus all the other classes. A new example can be classified by combining the predictions from all the <span class="math inline">\(n\)</span> classifiers and selecting the class with the highest score. This is a simple and efficient approach, and one that is commonly used, but it suffers from each classification problem possibly having an imbalanced class distribution (due to the negative class being a collection of multiple classes). Another limitation of this approach is that it requires the scores of each classifier to be calibrated so that they are comparable across all of them.</p></li>
<li><p><strong>Convert to pairwise</strong>: In this approach, we can create binary classifiers to distinguish between each pair of classes, resulting in <span class="math inline">\(\binom{n}{2}\)</span> binary classifiers. This results in a large number of classifiers, but each classifier usually has a balanced classification problem. A new example is classified by taking the predictions of all the binary classifiers and using majority voting.</p></li>
</ul>
</div>
<div id="skewed-or-imbalanced-classification-problems" class="section level3">
<h3><span class="header-section-number">7.6.4</span> Skewed or imbalanced classification problems</h3>
<p>A lot of problems you will deal with will not have uniform (balanced) distributions for both classes. This is often the case with problems in fraud detection, network security, and medical diagnosis where the class of interest is not very common. The same is true in many social science and public policy problems around behavior prediction, such as predicting which students will not graduate on time, which children may be at risk of getting lead poisoning, or which homes are likely to be abandoned in a given city. You will notice that applying standard machine learning methods may result in all the predictions being for the most frequent category in such situations, making it problematic to detect the infrequent classes. There has been a lot of work in machine learning research on dealing with such problems <span class="citation">(Chawla <a href="#ref-Chawla05">2005</a>; Kuhn and Johnson <a href="#ref-KuhnJohnson2013">2013</a>)</span> that we will not cover in detail here. Common approaches to deal with class imbalance include oversampling from the minority class and undersampling from the majority class. It is important to keep in mind that the sampling approaches do not need to result in a <span class="math inline">\(1:1\)</span> ratio. Many supervised learning methods described in this chapter (such as Random Forests and SVMs) can work well even with a <span class="math inline">\(10:1\)</span> imbalance. Also, it is critical to make sure that you only resample the training set; keep the distribution of the test set the same as that of the original data since you will not know the class labels of new data in practice and will not be able to resample.</p>
</div>
<div id="model-interpretability" class="section level3">
<h3><span class="header-section-number">7.6.5</span> Model interpretability</h3>
<p>As social scientists (or good machine learning practitioners), we do not only care about building machine learning models but also want to understand what the models “learned”, and how to use them to make inferences and decisions. Understanding, or interpreting machine learning models is a key requirement for most social science and policy problems. There are various reasons for this including:</p>
<ul>
<li>Providing information that can help in debugging and improving models</li>
<li>Increasing trust in the models and hence increasing their adoption by decisionmakers</li>
<li>Improving the decisions being made using the models by reinforcing the correct predictions and helping the decision-maker override the wrong predictions.</li>
<li>Helping select appropriate interventions based on the explanations</li>
<li>Providing legal recourse to people being affected by the decisions made using the models</li>
</ul>
<p><strong>Global versus Individual-Level Explanations</strong></p>
<p>When thinking about model interpretability, there are two types of interpretability:</p>
<ul>
<li>Global: At the overall model level</li>
<li>Individual: Explaining an individual classification/prediction that is made by a model.</li>
</ul>
<p>Both of these are important for different reasons. We need global interpretability to help understand the overall model but we also need explanations for individual classifications when these models are helping a person make decisions about individual cases. A social worker identifying the risk of a client going back to the homeless shelter and determining appropriate interventions to reduce that risk, or a counselor in an employment agency determining how likely an individual is to be long-term unemployed and connecting them with appropriate training programs or job opportunities need individual-level explanations of predictions/recommendations that the machine learning model is generating.</p>
<p><em>Global Interpretability</em></p>
<p>Each method results in a model that needs to be interpreted in a way that is appropriate for that method. For example, for a decision tree, we may want to view the tree to understand what types of classifications are being made. This can of course get cumbersome and difficult if the tree is extremely large. For logistic regression models, we can look at the coefficients and odds-ratios, but it is often difficult to mentally account for different variables controlling for each other. In general, the models discussed above have different ways of exposing their “feature importances”^[some measure of how uesful that fgeature was for the given model] and we often use that as a proxy for global model interpretability.</p>
<p>Another way of interpreting a model is to understand how the model scores individual data points. We can take the set of entities that are scored by the model, and generate cross-tabs that highlight how the top x% of the scored/predicted entities are different from the rest of the entities. This approach allows us to get an idea of what the model is doing, not in general, but on the entities of interest to us and makes interpretability a little more intuitive and generalizable across different model types.</p>
<p>A different approach that some have taken in this area has been to sparse^[Using a small number of features/predictors] models, making them easier to interpret. The motivation behind these simple, sparse models is that they are inherently interpretble and do not require the use of additional analysis for humans to understand them. Examples of such work include Ustun and Rudin <span class="citation">(<a href="#ref-Ustun2019">2019</a>)</span>, Ustun and Rudin <span class="citation">(<a href="#ref-Ustun2016">2016</a>)</span>, and Caruana et al. <span class="citation">(<a href="#ref-Caruana2015">2015</a>)</span>. These models may not perform well in every task so it’s important for us to explore the range of models in terms of performance and complexity, and decide what level and type of interpretability we need and how to balance that with the accuracy of those models.</p>
<p><em>Individual-Level Explanations</em></p>
<p>While it’s important to understand the models we are building at a global level, in many social science applications, we want to get an explanation for why a data point was classified/predicteda certain way by the model. There has been a lot of recent work on methods for generating individual-level explanations for predictions made by machine learning models. These fall into two areas: 1. Model specific methods: These are used to generate explanations for predictions made by a specific class of methods, such as neural networks or random forests. 2. Model agnostic methods: These can be used to generate explanations for individual predictions made by any type of model. Examples of this include LIME <span class="citation">(Ribeiro, Singh, and Guestrin <a href="#ref-ribeiro-16">2016</a>)</span>, MAPLE <span class="citation">(Plumb, Molitor, and Talwalkar <a href="#ref-Plumb2018">2018</a>)</span>, and SHAP values <span class="citation">(Lundberg and Lee <a href="#ref-Lundberg2017">2017</a>)</span>.</p>
<p>It’s important to keep in mind though that these “explanations” are typically not causal, and are often restricted to be a ranked list of “features”. One way to think about them is that these features were most important in assigning this data point the score it was given by a particular model. This is currently an active area of machine learning research and will hopefully mature into a set of methods and tools useful for social scientists using machine learning to solve problems that require a better and deeper understanding of their predictions.</p>
</div>
</div>
<div id="evaluation" class="section level2">
<h2><span class="header-section-number">7.7</span> Evaluation</h2>
<p>The previous section introduced us to a variety of methods, all with certain pros and cons, and no single method guaranteed to outperform others for a given problem. This section focuses on evaluation methods, with three primary goals:</p>
<ol style="list-style-type: decimal">
<li><p>Model selection: How do we select a method to use in the future? What parameters should we select for that method?</p></li>
<li><p>Performance estimation: How do we estimate how well our model will perform once it is deployed and applied to new data?</p></li>
<li><p>A deeper understanding of the types of models that work well and those that don’t can point to the effectiveness and applicability of existing methods and provide a better understanding of the structure of the data and the problem we are tackling.</p></li>
</ol>
<p>This section will cover evaluation methodologies as well as metrics that are commonly used. <!--We will start by describing common evaluation
methodologies that use existing data and then move on to field trials.
The methodologies we describe below apply both to regression and
classification problems. MALTE: no field trials. it is clear enough that we describe both regression and classification probs --></p>
<div id="methodology" class="section level3">
<h3><span class="header-section-number">7.7.1</span> Methodology</h3>
<p><strong>In-sample evaluation</strong></p>
<p>As social scientists, you already evaluate methods on how well they perform in-sample (on the set that the model was trained on). As we mentioned earlier in the chapter, the goal of machine learning methods is to generalize to new data, and validating models in-sample does not allow us to do that. We focus here on evaluation methodologies that allow us to optimize (as best as we can) for generalization performance. The methods are illustrated in Figure <a href="chap-ml.html#fig:holdout">7.7</a>.</p>
<p><strong>Out-of-sample and holdout set</strong></p>
<p>The simplest way to focus on generalization is to <em>pretend</em> to generalize to new (unseen) data. One way to do that is to take the original data and randomly split them into two sets: a <em>training set</em> and a <em>test set</em> (sometimes also called the <em>holdout</em> or <em>validation set</em>). We can decide how much to keep in each set (typically the splits range from 50–50 to 80–20, depending on the size of the data set). We then train our models on the training set and classify the data in the test set, allowing us to get an estimate of the relative performance of the methods.</p>
<p>One drawback of this approach is that we may be extremely lucky or unlucky with our random split. One way to get around the problem that is to repeatedly create multiple training and test sets. We can then train on <span class="math inline">\(TR_1\)</span> and test on <span class="math inline">\(TE_1\)</span>, train on <span class="math inline">\(TR_2\)</span> and test on <span class="math inline">\(TE_2\)</span>, and so on. The performance measures on each test set can then give us an estimate of the performance of different methods and how much they vary across different random sets.</p>
<div class="figure" style="text-align: center"><span id="fig:holdout"></span>
<img src="ChapterML/figures/holdout.png" alt="Validation methodologies: holdout set and cross-validation" width="70%" />
<p class="caption">
Figure 7.7: Validation methodologies: holdout set and cross-validation
</p>
</div>
<p><strong>Cross-validation</strong></p>
<p>Cross-validation is a more sophisticated holdout training and testing procedure that takes away some of the shortcomings of the holdout set approach. Cross-validation begins by splitting a labeled data set into <span class="math inline">\(k\)</span> partitions (called folds). Typically, <span class="math inline">\(k\)</span> is set to <span class="math inline">\(5\)</span> or <span class="math inline">\(10\)</span>. Cross-validation then proceeds by iterating <span class="math inline">\(k\)</span> times. In each iteration, one of the <span class="math inline">\(k\)</span> folds is held out as the test set, while the other <span class="math inline">\(k-1\)</span> folds are combined and used to train the model. A nice property of cross-validation is that every example is used in one test set for testing the model. Each iteration of cross-validation gives us a performance estimate that can then be aggregated (typically averaged) to generate the overall estimate.</p>
<p>An extreme case of cross-validation is called leave-one-out cross-validation, where given a data set of size <span class="math inline">\(N\)</span>, we create <span class="math inline">\(N\)</span> folds. That means iterating over each data point, holding it out as the test set, and training on the rest of the <span class="math inline">\(N-1\)</span> examples. This illustrates the benefit of cross-validation by giving us good generalization estimates (by training on as much of the data set as possible) and making sure the model is tested on each data point.</p>
<p><strong>Temporal validation</strong></p>
<p>The cross-validation and holdout set approaches described above assume that the data have no time dependencies and that the distribution is stationary over time. This assumption is almost always violated in practice and affects performance estimates for a model.</p>
<div class="figure" style="text-align: center"><span id="fig:temporal"></span>
<img src="ChapterML/figures/temporal.png" alt="Temporal validation" width="70%" />
<p class="caption">
Figure 7.8: Temporal validation
</p>
</div>
<p>In most practical problems, we want to use a validation strategy that emulates the way in which our models will be used and provides an accurate performance estimate. We will call this <em>temporal validation</em>. For a given point in time <span class="math inline">\(t_i\)</span>, we train our models only on information available to us before <span class="math inline">\(t_i\)</span> to avoid training on data from the “future.” We then predict and evaluate on data from <span class="math inline">\(t_i\)</span> to <span class="math inline">\(t_i\)</span> + <span class="math inline">\(d\)</span> and iterate, expanding the training window while keeping the test window size constant at <span class="math inline">\(d\)</span>. Figure <a href="chap-ml.html#fig:temporal">7.8</a> shows this validation process with <span class="math inline">\(t_i=2010\)</span> and <span class="math inline">\(d=1\)</span> year. The test set window <span class="math inline">\(d\)</span> depends on a few factors related to how the model will be deployed to best emulate reality:</p>
<ol style="list-style-type: decimal">
<li><p>How far out in the future do predictions need to be made? For example, if the set of students who need to be targeted for interventions has to be finalized at the beginning of the school year for the entire year, then <span class="math inline">\(d = 1\)</span> year.</p></li>
<li><p>How often will the model be updated? If the model is being updated daily, then we can move the window by a day at a time to reflect the deployment scenario.</p></li>
<li><p>How often will the system get new data? If we are getting new data frequently, we can make predictions more frequently.</p></li>
</ol>
<p>Temporal validation is similar to how time series models are evaluated (also known as backtesting) and should be the validation approach used for most practical problems.</p>
</div>
<div id="metrics" class="section level3">
<h3><span class="header-section-number">7.7.2</span> Metrics</h3>
<p>The previous subsection focused on validation methodologies assuming we have an evaluation metric in mind. This section will go over commonly used evaluation metrics. You are probably familiar with using <span class="math inline">\(R^2\)</span>, analysis of the residuals, and mean squared error (MSE) to evaluate the quality of regression models. For regression problems, the MSE calculates the average squared differences between predictions <span class="math inline">\(\hat{y}_i\)</span> and true values <span class="math inline">\(y_i\)</span>. When prediction models have smaller MSE, they are better. However, the MSE itself is hard to interpret because it measures quadratic differences. Instead, the root mean squared error (RMSE) is more intuitive as it as measure of mean differences on the original scale of the response variable. Yet another alternative is the mean absolute error (MAE), which measures average absolute distances between predictions and true values.</p>
<p>We will now describe some additional evaluation metrics commonly used in machine learning for classification. Before we dive into metrics, it is important to highlight that machine learning models for classification typically do not predict 0/1 values directly. SVMs, random forests, and logistic regression all produce a score (which is sometimes a probability) that is then turned into 0 or 1 based on a user-specific threshold. You might find that certain tools (such as scikitlearn<a href="#fn49" class="footnoteRef" id="fnref49"><sup>49</sup></a>) use a default value for that threshold (often 0.5), but it is important to know that it is an arbitrary threshold and you should select the threshold based on the data, the model, and the problem you are solving. We will cover that a little later in this section.</p>
<p>Once we have turned the real-valued predictions into 0/1 classification, we can now create a <em>confusion matrix</em> from these predictions, shown in Figure <a href="chap-ml.html#fig:cm">7.9</a>. Each data point belongs to either the positive class or the negative class, and for each data point the prediction of the classifier is either correct or incorrect. This is what the four cells of the confusion matrix represent. We can use the confusion matrix to describe several commonly used evaluation metrics.</p>
<div class="figure" style="text-align: center"><span id="fig:cm"></span>
<img src="ChapterML/figures/cm.png" alt="A *confusion matrix* created from real-valued predictions" width="70%" />
<p class="caption">
Figure 7.9: A <em>confusion matrix</em> created from real-valued predictions
</p>
</div>
<p>Accuracy is the ratio of correct predictions (both positive and negative) to all predictions: <span class="math display">\[\textrm{Accuracy}=\frac{TP + TN}{TP + TN + FP + FN}=\frac{TP + TN}{P+N}=\frac{TP + TN}{P&#39;+N&#39;},\]</span> where <span class="math inline">\(TP\)</span> denotes true positives, <span class="math inline">\(TN\)</span> true negatives, <span class="math inline">\(FP\)</span> false positives, <span class="math inline">\(FN\)</span> false negatives, and other symbols denote row or column totals. Accuracy is the most commonly described evaluation metric for classification but is surprisingly the least useful in practical situations (at least by itself). One problem with accuracy is that it does not give us an idea of <em>lift</em> compared to baseline. For example, if we have a classification problem with 95% of the data as positive and 5% as negative, a classifier with 85% is performing worse than a dumb classifier that predicts positive all the time (and will have 95% accuracy).</p>
<p>Two additional metrics that are often used are precision and recall, which are defined as follows: <span class="math display">\[\begin{aligned}
{\rm Precision} &amp;= \frac{TP}{TP + FP}=\frac{TP}{P},
\\
{\rm Recall} &amp;= \frac{TP}{TP + FN}=\frac{TP}{P&#39;}\end{aligned}\]</span> (see also Box 7.3). Precision measures the accuracy of the classifier when it predicts an example to be positive. It is the ratio of correctly predicted positive examples (<span class="math inline">\(TP\)</span>) to all examples predicted as positive (<span class="math inline">\(TP + FP\)</span>). This measure is also called <em>positive predictive value</em> in other fields. Recall measures the ability of the classifier to find positive examples. It is the ratio of all the correctly predicted positive examples (<span class="math inline">\(TP\)</span>) to all the positive examples in the data (<span class="math inline">\(TP + FN\)</span>). This is also called <em>sensitivity</em> in other fields.</p>
<p>You might have encountered another metric called <em>specificity</em> in other fields. This measure is the true negative rate: the proportion of negatives that are correctly identified.</p>
<p>Another metric that is used is the <span class="math inline">\(F_1\)</span> score, which is the harmonic mean of precision and recall: <span class="math display">\[F_1 =  \frac{2* {\rm Precision} * {\rm Recall}}{{\rm Precision} + {\rm Recall}}\]</span> (see also equation 7.1). This is often used when you want to balance both precision and recall.</p>
<p>There is often a tradeoff between precision and recall. By selecting different classification thresholds, we can vary and tune the precision and recall of a given classifier. A highly conservative classifier that only predicts a 1 when it is absolutely sure (say, a threshold of 0.9999) will most often be correct when it predicts a 1 (high precision) but will miss most 1s (low recall). At the other extreme, a classifier that says 1 to every data point (a threshold of 0.0001) will have perfect recall but low precision. Figure <a href="chap-ml.html#fig:pr">7.10</a> show a precision–recall curve that is often used to represent the performance of a given classifier.</p>
<div class="figure" style="text-align: center"><span id="fig:pr"></span>
<img src="ChapterML/figures/pr.png" alt="Precision-recall curve" width="70%" />
<p class="caption">
Figure 7.10: Precision-recall curve
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:pr2"></span>
<img src="ChapterML/figures/pr2.png" alt="Precision or recall at different thresholds" width="70%" />
<p class="caption">
Figure 7.11: Precision or recall at different thresholds
</p>
</div>
<p>If we care about optimizing for the entire precision recall space, a useful metric is the <em>area under the curve</em> (AUC-PR), which is the area under the precision–recall curve. AUC-PR must not be confused with AUC-ROC, which is the area under the related receiver operating characteristic (ROC) curve. The ROC curve is created by plotting recall versus (1 – specificity). Both AUCs can be helpful metrics to compare the performance of different methods and the maximum value the AUC can take is 1. If, however, we care about a specific part on the precision–recall curve, we have to look at finer-grained metrics.</p>
<p>Let us consider an example from public health. Most public health agencies conduct inspections of various sorts to detect health hazard violations (lead hazards, for example). The number of possible places (homes or businesses) to inspect far exceeds the inspection resources typically available. Let us assume further that they can only inspect 5% of all possible places; they would clearly want to prioritize the inspection of places that are most likely to contain the hazard. In this case, the model will score and rank all the possible inspection places in order of hazard risk. We would then want to know what percentage of the top 5% (the ones that will get inspected) are likely to be hazards, which translates to the precision in the top 5% of the most confidence predictions—precision at 5%, as it is commonly called (see Figure <a href="chap-ml.html#fig:pr2">7.11</a>). <em>Precision at top k percent</em> is a common class of metrics widely used in information retrieval and search engine literature, where you want to make sure that the results retrieved at the top of the search results are accurate. More generally, this metric is often used in problems in which the class distribution is skewed and only a small percentage of the examples will be examined manually (inspections, investigations for fraud, etc.). The literature provides many case studies of such applications <span class="citation">(Kumar, Ghani, and Mei <a href="#ref-Kumar2010">2010</a>; Lakkaraju et al. <a href="#ref-Lakkaraju2015">2015</a>; Potash et al. <a href="#ref-Potash2015">2015</a>)</span>.</p>
<p>One last metric we want to mention is a class of cost-sensitive metrics where different costs (or benefits) can be associated with the different cells in the confusion matrix. So far, we have implicitly assumed that every correct prediction and every error, whether for the positive class or the negative class, has equal costs and benefits. In many practical problems, that is not the case. For example, we may want to predict whether a patient in a hospital emergency room is likely to go into cardiac arrest in the next six hours. The cost of a false positive in this case is the cost of the intervention (which may be a few extra minutes of a physician’s time) while the cost of a false negative could be death. This type of analysis allows us to calculate the expected value of the predictions of a classifier and select the model that optimizes this cost-sensitive metric.</p>
</div>
</div>
<div id="practical-tips" class="section level2">
<h2><span class="header-section-number">7.8</span> Practical tips</h2>
<p>Here we highlight some practical tips that will be helpful when using machine learning.</p>
<div id="avoiding-leakage" class="section level3">
<h3><span class="header-section-number">7.8.1</span> Avoiding Leakage</h3>
<p>Leakage is when your model has access to data at training/building time that it wouldn’t have at test/deployment/prediction time. The result is an overoptimistic model that performs much worse when deployed.</p>
<p>The most common forms of leakage happen because of temporal issues – including data from the future in your model because you have that when you’re doing model selection but there are many other ways leakage gets introduced. Here are the most common ones</p>
<p><strong>The Big (and obvious) One</strong></p>
<ol style="list-style-type: decimal">
<li>Using a proxy for the outcome variable (label) as a feature. This one is often easy to detect because you get perfect performance but is more nuanced when the proxy is some approximation of the label/outcome variable and the performance increase is more subtle to detect easily.</li>
</ol>
<p><strong>Doing any transformation or inference using the entire dataset</strong></p>
<ol start="2" style="list-style-type: decimal">
<li><p>Using the entire data set for Imputations. Always do imputation based on your training set only, for each training set. Including the test set allows information to leak in to your models, especially in cases where the world changes in the future (when does it not?!)</p></li>
<li><p>Using the entire data set for discretizations or normalizations/scaling or many other data-based transformations. Same reason as #2. The range of a variable (age for example) can change in the future and knowing that will make your models do/look better than they actually are.</p></li>
<li><p>Using the entire data set for Feature Selection. Same reasons as #2 and #3. To play it safe, first split into train and test sets, and then do everything you need to do using that data.</p></li>
</ol>
<p><strong>Using information from the future (that will not available at training or prediction time)</strong></p>
<ol start="5" style="list-style-type: decimal">
<li><p>Using (proxies/transformation of) future outcomes as features: Similar to #1</p></li>
<li><p>Doing standard k fold cross-validation when you have temporal data. If you have temporal data (that is non-stationary – again, when is it not!), k-fold cross validation will shuffle the data and a training set will (probably) contain data from the future and a test set will (probably) contain data from the past.</p></li>
<li><p>Using data (as features) that happened before model training time but is not available until later. This is fairly common in cases where there is lag/delay in data collection or access. An event may happen today but it doesn’t appear in the database until a week, a month, or a year later and while it will be available in the data set you’re using to build and select ML models, it will not be available at prediction time in deployment.</p></li>
<li><p>Using data (as rows) in the training set based on information from the future. Including rows that match certain criteria (in the future) in the training set, such as everyone who got a social service in the next 3 months) leaks information to your model via a biased training set.</p></li>
</ol>
<p><strong>Humans using knowledge from the future</strong></p>
<ol start="9" style="list-style-type: decimal">
<li>Selecting certain models, features, and other design choices that are based on humans (ML developers, domain experts) knowing what happened in the future. This is a gray area – we do want to use all of our domain knowledge to build more effective systems but sometimes that may not generalize into the future and result in overfitted/over-optimistic models at training time and disappointment once they’re deployed.</li>
</ol>
<p>As a general rule, if you encounter a machine learning model that is performing really well, it’s probably because you’ve made an error that is resulting in leakage. One way to dig deeper is to look at the feature importances of your model to see if the most important feature(s) may be the source of that leakage.</p>
</div>
<div id="machine-learning-pipeline" class="section level3">
<h3><span class="header-section-number">7.8.2</span> Machine learning pipeline</h3>
<p>When working on machine learning projects, it is a good idea to structure your code as a modular pipeline so you can easily try different approaches and methods without major restructuring. The Python workbooks supporting this book will give you an example of a machine learning pipeline.<a href="#fn50" class="footnoteRef" id="fnref50"><sup>50</sup></a> A good pipeline will contain modules for importing data, doing exploration, feature generation, classification, and evaluation. You can then instantiate a specific workflow by combining these modules.</p>
<p>An important component of the machine learning pipeline is comparing different methods. With all the methods out there and all the hyperparameters they come with, how do we know which model to use and which hyperparameters to select? And what happens when we add new features to the model or when the data have “temporal drift” and change over time? One simple approach is to have a nested set of loops that loop over all the methods you have access to, then enumerate all the hyperparameters for that method, create a cross-product, and loop over all of them, comparing them across different evaluation metrics and selecting the best one to use going forward. You can even add different feature subsets and time slices to this loop, as the example in the supporting workbooks will show. Triage (<a href="http://github.com/dssg/triage" class="uri">http://github.com/dssg/triage</a>) is a good example of a machine learning pipeline that is designed to solve many public policy problems.</p>
</div>
</div>
<div id="how-can-social-scientists-benefit-from-machine-learning" class="section level2">
<h2><span class="header-section-number">7.9</span> How can social scientists benefit from machine learning?</h2>
<p>In this chapter, we have introduced you to some new methods (both unsupervised and supervised), validation methodologies, and evaluation metrics. All of these can benefit social scientists as they tackle problems in research and practice. In this section, we will give a few concrete examples where what you have learned so far can be used to improve some social science tasks:</p>
<ul>
<li><p><strong>Use of better prediction methods and methodology</strong>: Traditional statistics and social sciences have not focused much on methods for prediction. Machine learning researchers have spent the past 30 years developing and adapting methods focusing on that task. We believe that there is a lot of value for social science researchers and practitioners in learning more about those methods, applying them, and even augmenting them <span class="citation">(Kleinberg et al. <a href="#ref-Kleinberg2015">2015</a>)</span>. Two common tasks that can be improved using better prediction methods are generating counterfactuals (essentially a prediction problem) and matching. In addition, holdout sets and cross-validation can be used as a model selection methodology with any existing regression and classification methods, resulting in improved model selection and error estimates.</p></li>
<li><p><strong>Model misspecification</strong>: Linear and logistic regressions are common techniques for data analysis in the social sciences. One fundamental assumption within both is that they are additive over parameters. Machine learning provides tools when this assumption is too limiting. Hainmueller and Hazlett <span class="citation">(Hainmueller and Hazlett <a href="#ref-hainmueller2014kernel">2014</a>)</span>, for example, reanalyze data that were originally analyzed with logistic regression and come to substantially different conclusions. They argue that their analysis, which is more flexible and based on supervised learning methodology, provides three additional insights when compared to the original model. First, predictive performance is similar or better, although they do not need an extensive search to find the final model specification as it was done in the original analysis. Second, their model allows them to calculate average marginal effects that are mostly similar to the original analysis. However, for one covariate they find a substantially different result, which is due to model misspecification in the original model. Finally, the reanalysis also discovers interactions that were missed in the original publication.</p></li>
<li><p><strong>Better text analysis</strong>: Text is everywhere, but unfortunately humans are slow and expensive in analyzing text data. Thus, computers are needed to analyze large collections of text. Machine learning methods can help make this process more efficient. Feldman and Sanger <span class="citation">(Feldman and Sanger <a href="#ref-FeldmanSanger">2006</a>)</span> provide an overview of different automatic methods for text analysis. Grimmer and Stewart <span class="citation">(Grimmer and Stewart <a href="#ref-grimmer2013text">2013</a>)</span> give examples that are more specific for social scientists, and Chapter <a href="chap-text.html#chap:text">Text analysis</a> provides more details on this topic.</p></li>
<li><p><strong>Adaptive surveys</strong>: Some survey questions have a large number of possible answer categories. For example, international job classifications describe more than 500 occupational categories, and it is prohibitive to ask all categories during the survey. Instead, respondents answer an open-ended question about their job and machine learning algorithms can use the verbatim answers to suggest small sets of plausible answer options. The respondents can then select which option is the best description for their occupation, thus saving the costs for coding after the interview <span class="citation">(Schierholz et al. <a href="#ref-Schierholz2018">2018</a>)</span>.</p></li>
<li><p><strong>Estimating heterogeneous treatment effects</strong>: A standard approach to causal inference is the assignment of different treatments (e.g., medicines) to the units of interest (e.g., patients). Researchers then usually calculate the average treatment effect—the average difference in outcomes for both groups. It is also of interest if treatment effects differ for various subgroups (e.g., is a medicine more effective for younger people?). Traditional subgroup analysis has been criticized and challenged by various machine learning techniques <span class="citation">(Green and Kern <a href="#ref-green2012modeling">2012</a>; Imai, Ratkovic, and others <a href="#ref-imai2013estimating">2013</a>)</span>.</p></li>
<li><p><strong>Variable selection</strong>: Although there are many methods for variable selection, regularized methods such as the lasso are highly effective and efficient when faced with large amounts of data. Varian <span class="citation">(Hal R. Varian <a href="#ref-Varian2014">2014</a>)</span> goes into more detail and gives other methods from machine learning that can be useful for variable selection. We can also find interactions between pairs of variables (to feed into other models) using random forests, by looking at variables that co-occur in the same tree, and by calculating the strength of the interaction as a function of how many trees they co-occur in, how high they occur in the trees, and how far apart they are in a given tree.</p></li>
</ul>
</div>
<div id="advanced-topics" class="section level2">
<h2><span class="header-section-number">7.10</span> Advanced topics</h2>
<p>This has been a short but intense introduction to machine learning, and we have left out several important topics that are useful and interesting for you to know about and that are being actively researched in the machine learning community. We mention them here so you know what they are, but will not describe them in detail. These include:</p>
<ul>
<li><p>Semi-supervised learning, where a combination of labeled and unlabeled data are used for training, given a set of assumptions. Such methods are useful when labeling data is costly and where unlabeled (not manually labeled/tagged data) can help improve the machine learning models. See the MIT Press edited volume <span class="citation">(Chapelle, Schoelkopf, and Zien <a href="#ref-Chapelle2006">2006</a>)</span> for explanations and examples.</p></li>
<li><p>Recommender systems: These are commonly used by audio and video services like YouTube to generate playlists or by online shops like Amazon to suggest additional products a custumer might wish to buy. More generally, recommender systems aim to predict the preferences a user might have. One strategy is to recommend products that have similar characteristcs to the ones already selected by the same user (independent of others). Another strategy recommends a product if other persons with a similar profile selected the same product in the past.</p></li>
<li><p>Active learning, a set of machine learning algorithms that query the user or some other information source to get labels for data points that are most beneficial for the machine learning models. This is in contrast to the standard machine learning process where we often select data points to label/tag randomly. Active Learning approaches to selecting data points to label have been shown to reduce the effort needed to train machine learning models.</p></li>
<li><p>Reinforcement learning: The “supervised“ machine learning methods we’ve covered in this chapter are “one-shot” and take data points and labels as inputs. Reinforcement Learning is a different machine learning paradigm where the machine learning program takes a series of actions/decisions, and gets delayed feedback (reward or penalty) when performing a task. The goal of reinforcement learning is to determine the next best action to take in order to maximize long term performance. This has been applied to scenarios such as playing games (checkers, chess, backgammon, etc.) and in robotics <span class="citation">(Sutton and Barto <a href="#ref-Sutton2018">2018</a>)</span>.</p></li>
</ul>
</div>
<div id="summary-3" class="section level2">
<h2><span class="header-section-number">7.11</span> Summary</h2>
<p>Machine learning is an active research field, and in this chapter we have given you an overview of how the work developed in this field can be used by social scientists. We covered the overall machine learning process, methods, evaluation approaches and metrics, and some practical tips, as well as how all of this can benefit social scientists. The material described in this chapter is a snapshot of a fast-changing field, and as we are seeing increasing collaborations between machine learning researchers and social scientists, the hope and expectation is that the next few years will bring advances that will allow us to tackle social and policy problems much more effectively using new types of data and improved methods.</p>
</div>
<div id="ml:res" class="section level2">
<h2><span class="header-section-number">7.12</span> Resources</h2>
<p>We provide a Machine Learning cheat sheet to reference at <a href="https://textbook.coleridgeinitiative.org/mlcheatsheet" class="uri">https://textbook.coleridgeinitiative.org/mlcheatsheet</a>.</p>
<p>Literature for further reading that also explains most topics from this chapter in greater depth:</p>
<ul>
<li><p>Provost and Fawcett’s <em>Data Science for Business</em> <span class="citation">(Provost and Fawcett <a href="#ref-FawcettProvost">2013</a>)</span> is a good practical handbook for using machine learning to solve real-world problems.</p></li>
<li><p>Hastie et al.’s <em>The Elements of Statistical Learning</em> <span class="citation">(Hastie, Tibshirani, and Friedman <a href="#ref-HastieTibshirani">2001</a>)</span> is a classic and is available online for free.</p></li>
<li><p>James et al.’s <em>An Introduction to Statistical Learning</em> <span class="citation">(James et al. <a href="#ref-james2013introduction">2013</a>)</span>, from the same authors, includes less mathematics and is more approachable. It is also available online.</p></li>
<li><p>Mitchell’s <em>Machine Learning</em> <span class="citation">(Mitchell <a href="#ref-mitchell1997machine">1997</a>)</span> is a classic introduction to some of the methods and gives a good motivation underlying them.</p></li>
<li><p>Wu et al.’s “Top 10 Algorithms in Data Mining” <span class="citation">(Wu et al. <a href="#ref-wu2008top">2008</a>)</span>.</p></li>
</ul>
<p>Software:</p>
<ul>
<li><p>Python (with libraries like <code>scikit-learn</code>, <code>pandas</code>, and more).</p></li>
<li><p>R has many relevant packages <span class="citation">(Hothorn, n.d.)</span>.</p></li>
<li><p>Cloud-based: AzureML, Amazon ML, Google</p></li>
<li><p>Free: KNIME, Rapidminer, Weka (mostly for research use).</p></li>
<li><p>Commercial: IBM Modeler, SAS Enterprise Miner, Matlab.</p></li>
</ul>
<p>Many excellent courses are available online <span class="citation">(Z., n.d.)</span>, including Hastie and Tibshirani’s <em>Statistical Learning</em> <span class="citation">(Hastie and Tibshirani, n.d.)</span>.</p>
<p>Major conferences in this area include the <a href="https://icml.cc/">International Conference on Machine Learning</a>, the <a href="https://nips.cc/">Annual Conference on Neural Information Processing Systems (NeurIPS)</a>, and the <a href="https://www.kdd.org/">ACM International Conference on Knowledge Discovery and Data Mining (KDD)</a>.</p>

<!--
% todo: resolve comments on topic modeling equations
-->
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-athey2019">
<p>Athey, Susan, and Stefan Wager. 2019. “Estimating Treatment Effects with Causal Forests: An Application.” <a href="https://arxiv.org/abs/1902.07409" class="uri">https://arxiv.org/abs/1902.07409</a>.</p>
</div>
<div id="ref-Carton2016">
<p>Carton, Samuel, Jennifer Helsby, Kenneth Joseph, Ayesha Mahmud, Youngsoo Park, Joe Walsh, Crystal Cody, CPT Estella Patterson, Lauren Haynes, and Rayid Ghani. 2016. “Identifying Police Officers at Risk of Adverse Events.” In <em>Proceedings of the 22nd Acm Sigkdd International Conference on Knowledge Discovery and Data Mining</em>, 67–76. KDD 16. New York, NY, USA: Association for Computing Machinery. doi:<a href="https://doi.org/10.1145/2939672.2939698">10.1145/2939672.2939698</a>.</p>
</div>
<div id="ref-Caruana2015">
<p>Caruana, Rich, Yin Lou, Johannes Gehrke, Paul Koch, Marc Sturm, and Noemie Elhadad. 2015. “Intelligible Models for Healthcare: Predicting Pneumonia Risk and Hospital 30-Day Readmission.” Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery; Data Mining (KDD 15). Association for Computing Machinery, New York, NY, USA, 1721–1730.</p>
</div>
<div id="ref-Chapelle2010">
<p>Chapelle, O., and S. S. Keerthi. 2010. “Efficient Algorithms for Ranking with SVMs.” <em>Information Retrieval</em> 13 (3). Hingham, MA: Kluwer Academic Publishers: 201–15. doi:<a href="https://doi.org/10.1007/s10791-009-9109-9">10.1007/s10791-009-9109-9</a>.</p>
</div>
<div id="ref-Chapelle2006">
<p>Chapelle, Olivier, Bernhard Schoelkopf, and Alexander Zien, eds. 2006. <em>Semi-Supervised Learning</em>. London, U.K.: MIT Press.</p>
</div>
<div id="ref-Chawla05">
<p>Chawla, Nitesh V. 2005. “Data Mining for Imbalanced Datasets: An Overview.” In <em>The Data Mining and Knowledge Discovery Handbook</em>, edited by Oded Maimon and Lior Rokach, 853–67. Springer. <a href="http://dblp.uni-trier.de/db/books/collections/datamining2005.html#Chawla05" class="uri">http://dblp.uni-trier.de/db/books/collections/datamining2005.html#Chawla05</a>.</p>
</div>
<div id="ref-crammer2002">
<p>Crammer, Koby, and Yoram Singer. 2002. “On the Algorithmic Implementation of Multiclass Kernel-Based Vector Machines.” <em>Journal of Machine Learning Research</em> 2. JMLR.org: 265–92. <a href="http://dl.acm.org/citation.cfm?id=944790.944813" class="uri">http://dl.acm.org/citation.cfm?id=944790.944813</a>.</p>
</div>
<div id="ref-FeldmanSanger">
<p>Feldman, Ronen, and James Sanger. 2006. <em>Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data</em>. Cambridge University Press.</p>
</div>
<div id="ref-Flach">
<p>Flach, Peter. 2012. <em>Machine Learning: The Art and Science of Algorithms That Make Sense of Data</em>. Cambridge University Press.</p>
</div>
<div id="ref-Ontogen">
<p>Fortuna, Blaz, Marko Grobelnik, and Dunja Mladenic. 2007. “OntoGen: Semi-Automatic Ontology Editor.” In <em>Proceedings of the 2007 Conference on Human Interface: Part Ii</em>, 309–18. Beijing, China: Springer. <a href="http://dl.acm.org/citation.cfm?id=1766591.1766627" class="uri">http://dl.acm.org/citation.cfm?id=1766591.1766627</a>.</p>
</div>
<div id="ref-Goodfellow2016">
<p>Goodfellow, Ian, Yoshua Bengio, and Aaron Courville. 2016. <em>Deep Learning</em>. MIT Press.</p>
</div>
<div id="ref-green2012modeling">
<p>Green, Donald P., and Holger L. Kern. 2012. “Modeling Heterogeneous Treatment Effects in Survey Experiments with Bayesian Additive Regression Trees.” <em>Public Opinion Quarterly</em> 76. AAPOR: 491–511.</p>
</div>
<div id="ref-grimmer2013text">
<p>Grimmer, Justin, and Brandon M. Stewart. 2013. “Text as Data: The Promise and Pitfalls of Automatic Content Analysis Methods for Political Texts.” <em>Political Analysis</em> 21 (3). SPM-PMSAPSA: 267–97.</p>
</div>
<div id="ref-hainmueller2014kernel">
<p>Hainmueller, Jens, and Chad Hazlett. 2014. “Kernel Regularized Least Squares: Reducing Misspecification Bias with a Flexible and Interpretable Machine Learning Approach.” <em>Political Analysis</em> 22 (2). SPM-PMSAPSA: 143–68.</p>
</div>
<div id="ref-HastieTibshirani">
<p>Hastie, Trevor, Robert Tibshirani, and Jerome Friedman. 2001. <em>The Elements of Statistical Learning</em>. Springer.</p>
</div>
<div id="ref-imai2013estimating">
<p>Imai, Kosuke, Marc Ratkovic, and others. 2013. “Estimating Treatment Effect Heterogeneity in Randomized Program Evaluation.” <em>Annals of Applied Statistics</em> 7 (1). Institute of Mathematical Statistics: 443–70.</p>
</div>
<div id="ref-james2013introduction">
<p>James, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani. 2013. <em>An Introduction to Statistical Learning</em>. Springer.</p>
</div>
<div id="ref-Kleinberg2015">
<p>Kleinberg, Jon, Jens Ludwig, Sendhil Mullainathan, and Ziad Obermeyer. 2015. “Prediction Policy Problems.” <em>American Economic Review</em> 105 (5): 491–95. <a href="http://EconPapers.repec.org/RePEc:aea:aecrev:v:105:y:2015:i:5:p:491-95" class="uri">http://EconPapers.repec.org/RePEc:aea:aecrev:v:105:y:2015:i:5:p:491-95</a>.</p>
</div>
<div id="ref-KuhnJohnson2013">
<p>Kuhn, Max, and Kjell Johnson. 2013. <em>Applied Predictive Modeling</em>. Springer Science &amp; Business Media.</p>
</div>
<div id="ref-Kumar2010">
<p>Kumar, Mohit, Rayid Ghani, and Zhu-Song Mei. 2010. “Data Mining to Predict and Prevent Errors in Health Insurance Claims Processing.” In <em>Proceedings of the 16th Acm Sigkdd International Conference on Knowledge Discovery and Data Mining</em>, 65–74. KDD ’10. ACM. doi:<a href="https://doi.org/10.1145/1835804.1835816">10.1145/1835804.1835816</a>.</p>
</div>
<div id="ref-Lakkaraju2015">
<p>Lakkaraju, Himabindu, Everaldo Aguiar, Carl Shan, David Miller, Nasir Bhanpuri, Rayid Ghani, and Kecia L. Addison. 2015. “A Machine Learning Framework to Identify Students at Risk of Adverse Academic Outcomes.” In <em>Proceedings of the 21th Acm Sigkdd International Conference on Knowledge Discovery and Data Mining</em>, 1909–18. KDD ’15. ACM. doi:<a href="https://doi.org/10.1145/2783258.2788620">10.1145/2783258.2788620</a>.</p>
</div>
<div id="ref-Lundberg2017">
<p>Lundberg, Scott M., and Su-In Lee. 2017. “A Unified Approach to Interpreting Model Predictions.” In <em>Proceedings of the 31st International Conference on Neural Information Processing Systems</em>, 4768–77. NIPS 17. Red Hook, NY, USA: Curran Associates Inc.</p>
</div>
<div id="ref-mitchell1997machine">
<p>Mitchell, Tom M. 1997. <em>Machine Learning</em>. McGraw-Hill.</p>
</div>
<div id="ref-park2009simple">
<p>Park, Hae-Sang, and Chi-Hyuck Jun. 2009. “A Simple and Fast Algorithm for K-Medoids Clustering.” <em>Expert Systems with Applications</em> 36 (2). Elsevier: 3336–41.</p>
</div>
<div id="ref-Plumb2018">
<p>Plumb, Gregory, Denali Molitor, and Ameet Talwalkar. 2018. “Model Agnostic Supervised Local Explanations.” Proceedings of the 32nd International Conference on Neural Information Processing Systems (NIPS 18). Curran Associates Inc., Red Hook, NY, USA, 2520–2529.</p>
</div>
<div id="ref-Potash2015">
<p>Potash, Eric, Joe Brew, Alexander Loewi, Subhabrata Majumdar, Andrew Reece, Joe Walsh, Eric Rozier, Emile Jorgenson, Raed Mansour, and Rayid Ghani. 2015. “Predictive Modeling for Public Health: Preventing Childhood Lead Poisoning.” In <em>Proceedings of the 21th Acm Sigkdd International Conference on Knowledge Discovery and Data Mining</em>, 2039–47. KDD ’15. ACM. doi:<a href="https://doi.org/10.1145/2783258.2788629">10.1145/2783258.2788629</a>.</p>
</div>
<div id="ref-FawcettProvost">
<p>Provost, Foster, and Tom Fawcett. 2013. <em>Data Science for Business: What You Need to Know About Data Mining and Data-Analytic Thinking</em>. O’Reilly Media.</p>
</div>
<div id="ref-ribeiro-16">
<p>Ribeiro, Marco Tulio, Sameer Singh, and Carlos Guestrin. 2016. “‘Why Should I Trust You?’: Explaining the Predictions of Any Classifier.” In <em>Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, San Francisco, ca, Usa, August 13-17, 2016</em>, 1135–44.</p>
</div>
<div id="ref-samuel1959some">
<p>Samuel, Arthur L. 1959. “Some Studies in Machine Learning Using the Game of Checkers.” <em>IBM Journal of Research and Development</em> 3 (3). IBM: 210–29.</p>
</div>
<div id="ref-Schierholz2018">
<p>Schierholz, Malte, Miriam Gensicke, Nikolai Tschersich, and Frauke Kreuter. 2018. “Occupation Coding During the Interview.” <em>Journal of the Royal Statistical Society: Series A (Statistics in Society)</em> 181 (2): 379–407.</p>
</div>
<div id="ref-Scholkopf2001">
<p>Scholkopf, Bernhard, and Alexander J. Smola. 2001. <em>Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond</em>. MIT Press.</p>
</div>
<div id="ref-ShaweTaylor2004">
<p>Shawe-Taylor, John, and Nello Cristianini. 2004. <em>Kernel Methods for Pattern Analysis</em>. Cambridge University Press.</p>
</div>
<div id="ref-SmolaRegression04">
<p>Smola, Alex J., and Bernhard Schölkopf. 2004. “A Tutorial on Support Vector Regression.” <em>Statistics and Computing</em> 14 (3). Hingham, MA: Kluwer Academic Publishers: 199–222. doi:<a href="https://doi.org/10.1023/B:STCO.0000035301.49549.88">10.1023/B:STCO.0000035301.49549.88</a>.</p>
</div>
<div id="ref-Sutton2018">
<p>Sutton, Richard S., and Andrew G. Barto. 2018. <em>Reinforcement Learning. an Introduction</em>. Cambridge, MA: The MIT Press.</p>
</div>
<div id="ref-tibshirani1996regression">
<p>Tibshirani, Robert. 1996. “Regression Shrinkage and Selection via the Lasso.” <em>Journal of the Royal Statistical Society, Series B</em>. JSTOR, 267–88.</p>
</div>
<div id="ref-Ustun2016">
<p>Ustun, Berk, and Cynthia Rudin. 2016. “Supersparse Linear Integer Models for Optimized Medical Scoring Systems.” <em>Machine Learning</em> 102: 349–91.</p>
</div>
<div id="ref-Ustun2019">
<p>Ustun, Berk, and Cynthia Rudin. 2019. “Learning Optimized Risk Scores.” <em>Journal of Machine Learning Research</em> 20 (150): 1–75.</p>
</div>
<div id="ref-Varian2014">
<p>Varian, Hal R. 2014. “Big Data: New Tricks for Econometrics.” <em>Journal of Economic Perspectives</em> 28 (2): 3–28. doi:<a href="https://doi.org/10.1257/jep.28.2.3">10.1257/jep.28.2.3</a>.</p>
</div>
<div id="ref-Voigt2017">
<p>Voigt, Rob, Nicholas P. Camp, Vinodkumar Prabhakaran, William L. Hamilton, Rebecca C. Hetey, Camilla M. Griffiths, David Jurgens, Dan Jurafsky, and Jennifer L. Eberhardt. 2017. “Language from Police Body Camera Footage Shows Racial Disparities in Officer Respect.” <em>Proceedings of the National Academy of Sciences</em> 114 (25): 6521–6.</p>
</div>
<div id="ref-wu2008top">
<p>Wu, Xindong, Vipin Kumar, J. Ross Quinlan, Joydeep Ghosh, Qiang Yang, Hiroshi Motoda, Geoffrey J. McLachlan, et al. 2008. “Top 10 Algorithms in Data Mining.” <em>Knowledge and Information Systems</em> 14 (1). Springer: 1–37.</p>
</div>
<div id="ref-zhu2005semi">
<p>Zhu, Xiaojin. 2008. “Semi-Supervised Learning Literature Survey.” <a href="http://pages.cs.wisc.edu/~jerryzhu/pub/ssl_survey.pdf" class="uri">http://pages.cs.wisc.edu/~jerryzhu/pub/ssl_survey.pdf</a>.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="41">
<li id="fn41"><p>See Chapter <a href="chap-link.html#chap:link">Record Linkage</a>.<a href="chap-ml.html#fnref41">↩</a></p></li>
<li id="fn42"><p>If you have examples from your own research using the methods we describe in this chapter, please submit a link to the paper (and/or code) here: <a href="https://textbook.coleridgeinitiative.org/submitexamples" class="uri">https://textbook.coleridgeinitiative.org/submitexamples</a><a href="chap-ml.html#fnref42">↩</a></p></li>
<li id="fn43"><p>See Chapter <a href="chap-link.html#chap:link">Record Linkage</a>.<a href="chap-ml.html#fnref43">↩</a></p></li>
<li id="fn44"><p>dimensionality of the data often refers to how many variables we have in the data<a href="chap-ml.html#fnref44">↩</a></p></li>
<li id="fn45"><p>In statistical terms, regularization is an attempt to avoid overfitting the model<a href="chap-ml.html#fnref45">↩</a></p></li>
<li id="fn46"><p>Distance metrics are mathematical formulas to calculate the distance between two objects. For example, <em>Manhattan distance</em> is the distance a car would drive from one place to another place in a grid-based street system, whereas <em>Euclidean distance</em> (in two-dimensional space) is the “straight-line” distance between two points.<a href="chap-ml.html#fnref46">↩</a></p></li>
<li id="fn47"><p>The topic of causal inference is addressed in more detail in Chapter <a href="chap-errors.html#chap:errors">Data Quality and Inference Errors</a>.<a href="chap-ml.html#fnref47">↩</a></p></li>
<li id="fn48"><p>Bootstrap is a general statistical procedure that draws random samples of the original data with replacement.<a href="chap-ml.html#fnref48">↩</a></p></li>
<li id="fn49"><p>you should never use the predict function in sci-kit-learn since it assumes a 0.5 threshold<a href="chap-ml.html#fnref49">↩</a></p></li>
<li id="fn50"><p>See <a href="https://workbooks.coleridgeinitiative.org" class="uri">https://workbooks.coleridgeinitiative.org</a>.<a href="chap-ml.html#fnref50">↩</a></p></li>
</ol>
</div>
<div id="disqus_thread"></div>
<script>
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = '//big-data-and-social-science.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the
<a href="https://disqus.com/?ref_noscript">
  comments powered by Disqus.</a></noscript>
            </section>

          </div>
        </div>
      </div>
<a href="chap-viz.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="chap-text.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/Coleridge-Initiative/big-data-and-social-science/edit/master/07-ChapterML.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["big-data-and-social-science.pdf"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
