<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Big Data and Social Science</title>
  <meta name="description" content="Big Data and Social Science">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Big Data and Social Science" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="Coleridge-Initiative/big-data-and-social-science" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Big Data and Social Science" />
  
  
  

<meta name="author" content="Ian Foster">
<meta name="author" content="Rayid Ghani">
<meta name="author" content="Ron S. Jarmin">
<meta name="author" content="Frauke Kreuter">
<meta name="author" content="Julia Lane">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="chap-parallel.html">
<link rel="next" href="chap-text.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Big Data and Social Science</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="chap-intro.html"><a href="chap-intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="chap-intro.html"><a href="chap-intro.html#sec:1-1"><i class="fa fa-check"></i><b>1.1</b> Why this book?</a></li>
<li class="chapter" data-level="1.2" data-path="chap-intro.html"><a href="chap-intro.html#sec:1-2"><i class="fa fa-check"></i><b>1.2</b> Defining big data and its value</a></li>
<li class="chapter" data-level="1.3" data-path="chap-intro.html"><a href="chap-intro.html#sec:1.3"><i class="fa fa-check"></i><b>1.3</b> Social science, inference, and big data</a></li>
<li class="chapter" data-level="1.4" data-path="chap-intro.html"><a href="chap-intro.html#sec:1-5"><i class="fa fa-check"></i><b>1.4</b> Social science, data quality, and big data</a></li>
<li class="chapter" data-level="1.5" data-path="chap-intro.html"><a href="chap-intro.html#new-tools-for-new-data"><i class="fa fa-check"></i><b>1.5</b> New tools for new data</a></li>
<li class="chapter" data-level="1.6" data-path="chap-intro.html"><a href="chap-intro.html#sec:1-6"><i class="fa fa-check"></i><b>1.6</b> The book’s “use case”</a></li>
<li class="chapter" data-level="1.7" data-path="chap-intro.html"><a href="chap-intro.html#the-structure-of-the-book"><i class="fa fa-check"></i><b>1.7</b> The structure of the book</a><ul>
<li class="chapter" data-level="1.7.1" data-path="chap-intro.html"><a href="chap-intro.html#part-i-capture-and-curation"><i class="fa fa-check"></i><b>1.7.1</b> Part I: Capture and curation</a></li>
<li class="chapter" data-level="1.7.2" data-path="chap-intro.html"><a href="chap-intro.html#part-ii-modeling-and-analysis"><i class="fa fa-check"></i><b>1.7.2</b> Part II: Modeling and analysis</a></li>
<li class="chapter" data-level="1.7.3" data-path="chap-intro.html"><a href="chap-intro.html#part-iii-inference-and-ethics"><i class="fa fa-check"></i><b>1.7.3</b> Part III: Inference and ethics</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="chap-intro.html"><a href="chap-intro.html#sec:intro:resources"><i class="fa fa-check"></i><b>1.8</b> Resources</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="chap-web.html"><a href="chap-web.html"><i class="fa fa-check"></i><b>2</b> Working with Web Data and APIs</a><ul>
<li class="chapter" data-level="2.1" data-path="chap-web.html"><a href="chap-web.html#introduction"><i class="fa fa-check"></i><b>2.1</b> Introduction</a></li>
<li class="chapter" data-level="2.2" data-path="chap-web.html"><a href="chap-web.html#sec:4-1"><i class="fa fa-check"></i><b>2.2</b> Scraping information from the web</a><ul>
<li class="chapter" data-level="2.2.1" data-path="chap-web.html"><a href="chap-web.html#sec:4-1.1"><i class="fa fa-check"></i><b>2.2.1</b> Obtaining data from websites</a></li>
<li class="chapter" data-level="2.2.2" data-path="chap-web.html"><a href="chap-web.html#sec:4-1.2"><i class="fa fa-check"></i><b>2.2.2</b> Limits of scraping</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="chap-web.html"><a href="chap-web.html#sec:4-3"><i class="fa fa-check"></i><b>2.3</b> Application Programming Interfaces (APIs)</a><ul>
<li class="chapter" data-level="2.3.1" data-path="chap-web.html"><a href="chap-web.html#sec:4-3.1"><i class="fa fa-check"></i><b>2.3.1</b> Relevant APIs and resources</a></li>
<li class="chapter" data-level="2.3.2" data-path="chap-web.html"><a href="chap-web.html#sec:4-3.2"><i class="fa fa-check"></i><b>2.3.2</b> RESTful APIs, returned data, and Python wrappers</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="chap-web.html"><a href="chap-web.html#sec:4-4"><i class="fa fa-check"></i><b>2.4</b> Using an API</a></li>
<li class="chapter" data-level="2.5" data-path="chap-web.html"><a href="chap-web.html#sec:4-4.1"><i class="fa fa-check"></i><b>2.5</b> Another example: Using the ORCID API via a wrapper</a></li>
<li class="chapter" data-level="2.6" data-path="chap-web.html"><a href="chap-web.html#sec:4-6"><i class="fa fa-check"></i><b>2.6</b> Integrating data from multiple sources</a></li>
<li class="chapter" data-level="2.7" data-path="chap-web.html"><a href="chap-web.html#sec:4-9"><i class="fa fa-check"></i><b>2.7</b> Summary</a></li>
<li class="chapter" data-level="2.8" data-path="chap-web.html"><a href="chap-web.html#acknowledgements-and-copyright"><i class="fa fa-check"></i><b>2.8</b> Acknowledgements and copyright</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="chap-link.html"><a href="chap-link.html"><i class="fa fa-check"></i><b>3</b> Record Linkage</a><ul>
<li class="chapter" data-level="3.1" data-path="chap-link.html"><a href="chap-link.html#motivation"><i class="fa fa-check"></i><b>3.1</b> Motivation</a></li>
<li class="chapter" data-level="3.2" data-path="chap-link.html"><a href="chap-link.html#sec:recordlinkage"><i class="fa fa-check"></i><b>3.2</b> Introduction to record linkage</a></li>
<li class="chapter" data-level="3.3" data-path="chap-link.html"><a href="chap-link.html#preprocessing-data-for-record-linkage"><i class="fa fa-check"></i><b>3.3</b> Preprocessing data for record linkage</a></li>
<li class="chapter" data-level="3.4" data-path="chap-link.html"><a href="chap-link.html#S:indexing"><i class="fa fa-check"></i><b>3.4</b> Indexing and blocking</a></li>
<li class="chapter" data-level="3.5" data-path="chap-link.html"><a href="chap-link.html#matching"><i class="fa fa-check"></i><b>3.5</b> Matching</a><ul>
<li class="chapter" data-level="3.5.1" data-path="chap-link.html"><a href="chap-link.html#rule-based-approaches"><i class="fa fa-check"></i><b>3.5.1</b> Rule-based approaches</a></li>
<li class="chapter" data-level="3.5.2" data-path="chap-link.html"><a href="chap-link.html#probabilistic-record-linkage"><i class="fa fa-check"></i><b>3.5.2</b> Probabilistic record linkage</a></li>
<li class="chapter" data-level="3.5.3" data-path="chap-link.html"><a href="chap-link.html#machine-learning-approaches-to-linking"><i class="fa fa-check"></i><b>3.5.3</b> Machine learning approaches to linking</a></li>
<li class="chapter" data-level="3.5.4" data-path="chap-link.html"><a href="chap-link.html#disambiguating-networks"><i class="fa fa-check"></i><b>3.5.4</b> Disambiguating networks</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="chap-link.html"><a href="chap-link.html#classification"><i class="fa fa-check"></i><b>3.6</b> Classification</a><ul>
<li class="chapter" data-level="3.6.1" data-path="chap-link.html"><a href="chap-link.html#S:thresholds"><i class="fa fa-check"></i><b>3.6.1</b> Thresholds</a></li>
<li class="chapter" data-level="3.6.2" data-path="chap-link.html"><a href="chap-link.html#one-to-one-links"><i class="fa fa-check"></i><b>3.6.2</b> One-to-one links</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="chap-link.html"><a href="chap-link.html#record-linkage-and-data-protection"><i class="fa fa-check"></i><b>3.7</b> Record linkage and data protection</a></li>
<li class="chapter" data-level="3.8" data-path="chap-link.html"><a href="chap-link.html#summary"><i class="fa fa-check"></i><b>3.8</b> Summary</a></li>
<li class="chapter" data-level="3.9" data-path="chap-link.html"><a href="chap-link.html#resources"><i class="fa fa-check"></i><b>3.9</b> Resources</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="chap-db.html"><a href="chap-db.html"><i class="fa fa-check"></i><b>4</b> Databases</a><ul>
<li class="chapter" data-level="4.1" data-path="chap-db.html"><a href="chap-db.html#sec:db:intro"><i class="fa fa-check"></i><b>4.1</b> Introduction</a></li>
<li class="chapter" data-level="4.2" data-path="chap-db.html"><a href="chap-db.html#sec:db:when"><i class="fa fa-check"></i><b>4.2</b> DBMS: When and why</a></li>
<li class="chapter" data-level="4.3" data-path="chap-db.html"><a href="chap-db.html#relational-dbmss"><i class="fa fa-check"></i><b>4.3</b> Relational DBMSs</a><ul>
<li class="chapter" data-level="4.3.1" data-path="chap-db.html"><a href="chap-db.html#structured-query-language-sql"><i class="fa fa-check"></i><b>4.3.1</b> Structured Query Language (SQL)</a></li>
<li class="chapter" data-level="4.3.2" data-path="chap-db.html"><a href="chap-db.html#sec:db:sql"><i class="fa fa-check"></i><b>4.3.2</b> Manipulating and querying data</a></li>
<li class="chapter" data-level="4.3.3" data-path="chap-db.html"><a href="chap-db.html#sec:db:schema"><i class="fa fa-check"></i><b>4.3.3</b> Schema design and definition</a></li>
<li class="chapter" data-level="4.3.4" data-path="chap-db.html"><a href="chap-db.html#loading-data"><i class="fa fa-check"></i><b>4.3.4</b> Loading data</a></li>
<li class="chapter" data-level="4.3.5" data-path="chap-db.html"><a href="chap-db.html#transactions-and-crash-recovery"><i class="fa fa-check"></i><b>4.3.5</b> Transactions and crash recovery</a></li>
<li class="chapter" data-level="4.3.6" data-path="chap-db.html"><a href="chap-db.html#sec:db:index"><i class="fa fa-check"></i><b>4.3.6</b> Database optimizations</a></li>
<li class="chapter" data-level="4.3.7" data-path="chap-db.html"><a href="chap-db.html#caveats-and-challenges"><i class="fa fa-check"></i><b>4.3.7</b> Caveats and challenges</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="chap-db.html"><a href="chap-db.html#linking-dbmss-and-other-tools"><i class="fa fa-check"></i><b>4.4</b> Linking DBMSs and other tools</a></li>
<li class="chapter" data-level="4.5" data-path="chap-db.html"><a href="chap-db.html#sec:db:nosql"><i class="fa fa-check"></i><b>4.5</b> NoSQL databases</a><ul>
<li class="chapter" data-level="4.5.1" data-path="chap-db.html"><a href="chap-db.html#challenges-of-scale-the-cap-theorem"><i class="fa fa-check"></i><b>4.5.1</b> Challenges of scale: The CAP theorem</a></li>
<li class="chapter" data-level="4.5.2" data-path="chap-db.html"><a href="chap-db.html#nosql-and-keyvalue-stores"><i class="fa fa-check"></i><b>4.5.2</b> NoSQL and key–value stores</a></li>
<li class="chapter" data-level="4.5.3" data-path="chap-db.html"><a href="chap-db.html#other-nosql-databases"><i class="fa fa-check"></i><b>4.5.3</b> Other NoSQL databases</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="chap-db.html"><a href="chap-db.html#sec:db:spatial"><i class="fa fa-check"></i><b>4.6</b> Spatial databases</a></li>
<li class="chapter" data-level="4.7" data-path="chap-db.html"><a href="chap-db.html#which-database-to-use"><i class="fa fa-check"></i><b>4.7</b> Which database to use?</a><ul>
<li class="chapter" data-level="4.7.1" data-path="chap-db.html"><a href="chap-db.html#relational-dbmss-1"><i class="fa fa-check"></i><b>4.7.1</b> Relational DBMSs</a></li>
<li class="chapter" data-level="4.7.2" data-path="chap-db.html"><a href="chap-db.html#nosql-dbmss"><i class="fa fa-check"></i><b>4.7.2</b> NoSQL DBMSs</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="chap-db.html"><a href="chap-db.html#summary-1"><i class="fa fa-check"></i><b>4.8</b> Summary</a></li>
<li class="chapter" data-level="4.9" data-path="chap-db.html"><a href="chap-db.html#resources-1"><i class="fa fa-check"></i><b>4.9</b> Resources</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="chap-parallel.html"><a href="chap-parallel.html"><i class="fa fa-check"></i><b>5</b> Scaling up through Parallel and Distributed Computing</a><ul>
<li class="chapter" data-level="5.1" data-path="chap-parallel.html"><a href="chap-parallel.html#introduction-1"><i class="fa fa-check"></i><b>5.1</b> Introduction</a></li>
<li class="chapter" data-level="5.2" data-path="chap-parallel.html"><a href="chap-parallel.html#sec:intro"><i class="fa fa-check"></i><b>5.2</b> MapReduce</a></li>
<li class="chapter" data-level="5.3" data-path="chap-parallel.html"><a href="chap-parallel.html#apache-hadoop-mapreduce"><i class="fa fa-check"></i><b>5.3</b> Apache Hadoop MapReduce</a><ul>
<li class="chapter" data-level="5.3.1" data-path="chap-parallel.html"><a href="chap-parallel.html#the-hadoop-distributed-file-system"><i class="fa fa-check"></i><b>5.3.1</b> The Hadoop Distributed File System</a></li>
<li class="chapter" data-level="5.3.2" data-path="chap-parallel.html"><a href="chap-parallel.html#hadoop-setup-bringing-compute-to-the-data"><i class="fa fa-check"></i><b>5.3.2</b> Hadoop Setup: Bringing compute to the data</a></li>
<li class="chapter" data-level="5.3.3" data-path="chap-parallel.html"><a href="chap-parallel.html#hardware-provisioning"><i class="fa fa-check"></i><b>5.3.3</b> Hardware provisioning</a></li>
<li class="chapter" data-level="5.3.4" data-path="chap-parallel.html"><a href="chap-parallel.html#programming-in-hadoop"><i class="fa fa-check"></i><b>5.3.4</b> Programming in Hadoop</a></li>
<li class="chapter" data-level="5.3.5" data-path="chap-parallel.html"><a href="chap-parallel.html#programming-language-support"><i class="fa fa-check"></i><b>5.3.5</b> Programming language support</a></li>
<li class="chapter" data-level="5.3.6" data-path="chap-parallel.html"><a href="chap-parallel.html#benefits-and-limitations-of-hadoop"><i class="fa fa-check"></i><b>5.3.6</b> Benefits and Limitations of Hadoop</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="chap-parallel.html"><a href="chap-parallel.html#other-mapreduce-implementations"><i class="fa fa-check"></i><b>5.4</b> Other MapReduce Implementations</a></li>
<li class="chapter" data-level="5.5" data-path="chap-parallel.html"><a href="chap-parallel.html#apache-spark"><i class="fa fa-check"></i><b>5.5</b> Apache Spark</a></li>
<li class="chapter" data-level="5.6" data-path="chap-parallel.html"><a href="chap-parallel.html#summary-2"><i class="fa fa-check"></i><b>5.6</b> Summary</a></li>
<li class="chapter" data-level="5.7" data-path="chap-parallel.html"><a href="chap-parallel.html#resources-2"><i class="fa fa-check"></i><b>5.7</b> Resources</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="chap-ml.html"><a href="chap-ml.html"><i class="fa fa-check"></i><b>6</b> Machine Learning</a><ul>
<li class="chapter" data-level="6.1" data-path="chap-ml.html"><a href="chap-ml.html#introduction-2"><i class="fa fa-check"></i><b>6.1</b> Introduction</a></li>
<li class="chapter" data-level="6.2" data-path="chap-ml.html"><a href="chap-ml.html#what-is-machine-learning"><i class="fa fa-check"></i><b>6.2</b> What is machine learning?</a></li>
<li class="chapter" data-level="6.3" data-path="chap-ml.html"><a href="chap-ml.html#the-machine-learning-process"><i class="fa fa-check"></i><b>6.3</b> The machine learning process</a></li>
<li class="chapter" data-level="6.4" data-path="chap-ml.html"><a href="chap-ml.html#problem-formulation-mapping-a-problem-to-machine-learning-methods"><i class="fa fa-check"></i><b>6.4</b> Problem formulation: Mapping a problem to machine learning methods</a></li>
<li class="chapter" data-level="6.5" data-path="chap-ml.html"><a href="chap-ml.html#methods"><i class="fa fa-check"></i><b>6.5</b> Methods</a><ul>
<li class="chapter" data-level="6.5.1" data-path="chap-ml.html"><a href="chap-ml.html#unsupervised-learning-methods"><i class="fa fa-check"></i><b>6.5.1</b> Unsupervised learning methods</a></li>
<li class="chapter" data-level="6.5.2" data-path="chap-ml.html"><a href="chap-ml.html#sec:MLchapter:super"><i class="fa fa-check"></i><b>6.5.2</b> Supervised learning</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="chap-ml.html"><a href="chap-ml.html#evaluation"><i class="fa fa-check"></i><b>6.6</b> Evaluation</a><ul>
<li class="chapter" data-level="6.6.1" data-path="chap-ml.html"><a href="chap-ml.html#methodology"><i class="fa fa-check"></i><b>6.6.1</b> Methodology</a></li>
<li class="chapter" data-level="6.6.2" data-path="chap-ml.html"><a href="chap-ml.html#metrics"><i class="fa fa-check"></i><b>6.6.2</b> Metrics</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="chap-ml.html"><a href="chap-ml.html#practical-tips"><i class="fa fa-check"></i><b>6.7</b> Practical tips</a><ul>
<li class="chapter" data-level="6.7.1" data-path="chap-ml.html"><a href="chap-ml.html#features"><i class="fa fa-check"></i><b>6.7.1</b> Features</a></li>
<li class="chapter" data-level="6.7.2" data-path="chap-ml.html"><a href="chap-ml.html#machine-learning-pipeline"><i class="fa fa-check"></i><b>6.7.2</b> Machine learning pipeline</a></li>
<li class="chapter" data-level="6.7.3" data-path="chap-ml.html"><a href="chap-ml.html#multiclass-problems"><i class="fa fa-check"></i><b>6.7.3</b> Multiclass problems</a></li>
<li class="chapter" data-level="6.7.4" data-path="chap-ml.html"><a href="chap-ml.html#skewed-or-imbalanced-classification-problems"><i class="fa fa-check"></i><b>6.7.4</b> Skewed or imbalanced classification problems</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="chap-ml.html"><a href="chap-ml.html#how-can-social-scientists-benefit-from-machine-learning"><i class="fa fa-check"></i><b>6.8</b> How can social scientists benefit from machine learning?</a></li>
<li class="chapter" data-level="6.9" data-path="chap-ml.html"><a href="chap-ml.html#advanced-topics"><i class="fa fa-check"></i><b>6.9</b> Advanced topics</a></li>
<li class="chapter" data-level="6.10" data-path="chap-ml.html"><a href="chap-ml.html#summary-3"><i class="fa fa-check"></i><b>6.10</b> Summary</a></li>
<li class="chapter" data-level="6.11" data-path="chap-ml.html"><a href="chap-ml.html#ml:res"><i class="fa fa-check"></i><b>6.11</b> Resources</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="chap-text.html"><a href="chap-text.html"><i class="fa fa-check"></i><b>7</b> Text Analysis</a><ul>
<li class="chapter" data-level="7.1" data-path="chap-text.html"><a href="chap-text.html#understanding-what-people-write"><i class="fa fa-check"></i><b>7.1</b> Understanding what people write</a></li>
<li class="chapter" data-level="7.2" data-path="chap-text.html"><a href="chap-text.html#how-to-analyze-text"><i class="fa fa-check"></i><b>7.2</b> How to analyze text</a><ul>
<li class="chapter" data-level="7.2.1" data-path="chap-text.html"><a href="chap-text.html#processing-text-data"><i class="fa fa-check"></i><b>7.2.1</b> Processing text data</a></li>
<li class="chapter" data-level="7.2.2" data-path="chap-text.html"><a href="chap-text.html#how-much-is-a-word-worth"><i class="fa fa-check"></i><b>7.2.2</b> How much is a word worth?</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="chap-text.html"><a href="chap-text.html#sec:appapp"><i class="fa fa-check"></i><b>7.3</b> Approaches and applications</a><ul>
<li class="chapter" data-level="7.3.1" data-path="chap-text.html"><a href="chap-text.html#sec:lda"><i class="fa fa-check"></i><b>7.3.1</b> Topic modeling</a></li>
<li class="chapter" data-level="7.3.2" data-path="chap-text.html"><a href="chap-text.html#sec:ir"><i class="fa fa-check"></i><b>7.3.2</b> Information retrieval and clustering</a></li>
<li class="chapter" data-level="7.3.3" data-path="chap-text.html"><a href="chap-text.html#sec:other"><i class="fa fa-check"></i><b>7.3.3</b> Other approaches</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="chap-text.html"><a href="chap-text.html#sec:eval"><i class="fa fa-check"></i><b>7.4</b> Evaluation</a></li>
<li class="chapter" data-level="7.5" data-path="chap-text.html"><a href="chap-text.html#text-analysis-tools"><i class="fa fa-check"></i><b>7.5</b> Text analysis tools</a></li>
<li class="chapter" data-level="7.6" data-path="chap-text.html"><a href="chap-text.html#summary-4"><i class="fa fa-check"></i><b>7.6</b> Summary</a></li>
<li class="chapter" data-level="7.7" data-path="chap-text.html"><a href="chap-text.html#resources-3"><i class="fa fa-check"></i><b>7.7</b> Resources</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="chap-networks.html"><a href="chap-networks.html"><i class="fa fa-check"></i><b>8</b> Networks: The Basics</a><ul>
<li class="chapter" data-level="8.1" data-path="chap-networks.html"><a href="chap-networks.html#introduction-3"><i class="fa fa-check"></i><b>8.1</b> Introduction</a></li>
<li class="chapter" data-level="8.2" data-path="chap-networks.html"><a href="chap-networks.html#network-data"><i class="fa fa-check"></i><b>8.2</b> Network data</a><ul>
<li class="chapter" data-level="8.2.1" data-path="chap-networks.html"><a href="chap-networks.html#forms-of-network-data"><i class="fa fa-check"></i><b>8.2.1</b> Forms of network data</a></li>
<li class="chapter" data-level="8.2.2" data-path="chap-networks.html"><a href="chap-networks.html#inducing-one-mode-networks-from-two-mode-data"><i class="fa fa-check"></i><b>8.2.2</b> Inducing one-mode networks from two-mode data</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="chap-networks.html"><a href="chap-networks.html#network-measures"><i class="fa fa-check"></i><b>8.3</b> Network measures</a><ul>
<li class="chapter" data-level="8.3.1" data-path="chap-networks.html"><a href="chap-networks.html#reachability"><i class="fa fa-check"></i><b>8.3.1</b> Reachability</a></li>
<li class="chapter" data-level="8.3.2" data-path="chap-networks.html"><a href="chap-networks.html#whole-network-measures"><i class="fa fa-check"></i><b>8.3.2</b> Whole-network measures</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="chap-networks.html"><a href="chap-networks.html#comparing-collaboration-networks"><i class="fa fa-check"></i><b>8.4</b> Comparing collaboration networks</a></li>
<li class="chapter" data-level="8.5" data-path="chap-networks.html"><a href="chap-networks.html#summary-5"><i class="fa fa-check"></i><b>8.5</b> Summary</a></li>
<li class="chapter" data-level="8.6" data-path="chap-networks.html"><a href="chap-networks.html#resources-4"><i class="fa fa-check"></i><b>8.6</b> Resources</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="chap-viz.html"><a href="chap-viz.html"><i class="fa fa-check"></i><b>9</b> Information Visualization</a><ul>
<li class="chapter" data-level="9.1" data-path="chap-viz.html"><a href="chap-viz.html#sec:viz-1"><i class="fa fa-check"></i><b>9.1</b> Introduction</a></li>
<li class="chapter" data-level="9.2" data-path="chap-viz.html"><a href="chap-viz.html#sec:viz-2"><i class="fa fa-check"></i><b>9.2</b> Developing effective visualizations</a></li>
<li class="chapter" data-level="9.3" data-path="chap-viz.html"><a href="chap-viz.html#sec:viz-3"><i class="fa fa-check"></i><b>9.3</b> A data-by-tasks taxonomy</a><ul>
<li class="chapter" data-level="9.3.1" data-path="chap-viz.html"><a href="chap-viz.html#sec:viz-2.1"><i class="fa fa-check"></i><b>9.3.1</b> Multivariate data</a></li>
<li class="chapter" data-level="9.3.2" data-path="chap-viz.html"><a href="chap-viz.html#sec:viz-2.2"><i class="fa fa-check"></i><b>9.3.2</b> Spatial data</a></li>
<li class="chapter" data-level="9.3.3" data-path="chap-viz.html"><a href="chap-viz.html#sec:viz-2.4"><i class="fa fa-check"></i><b>9.3.3</b> Temporal data</a></li>
<li class="chapter" data-level="9.3.4" data-path="chap-viz.html"><a href="chap-viz.html#sec:viz-2.5"><i class="fa fa-check"></i><b>9.3.4</b> Hierarchical data</a></li>
<li class="chapter" data-level="9.3.5" data-path="chap-viz.html"><a href="chap-viz.html#sec:viz-2.6"><i class="fa fa-check"></i><b>9.3.5</b> Network data</a></li>
<li class="chapter" data-level="9.3.6" data-path="chap-viz.html"><a href="chap-viz.html#sec:viz-2.7"><i class="fa fa-check"></i><b>9.3.6</b> Text data</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="chap-viz.html"><a href="chap-viz.html#sec:viz-4"><i class="fa fa-check"></i><b>9.4</b> Challenges</a><ul>
<li class="chapter" data-level="9.4.1" data-path="chap-viz.html"><a href="chap-viz.html#sec:viz-4.1"><i class="fa fa-check"></i><b>9.4.1</b> Scalability</a></li>
<li class="chapter" data-level="9.4.2" data-path="chap-viz.html"><a href="chap-viz.html#sec:viz-4.2"><i class="fa fa-check"></i><b>9.4.2</b> Evaluation</a></li>
<li class="chapter" data-level="9.4.3" data-path="chap-viz.html"><a href="chap-viz.html#sec:viz-4.3"><i class="fa fa-check"></i><b>9.4.3</b> Visual impairment</a></li>
<li class="chapter" data-level="9.4.4" data-path="chap-viz.html"><a href="chap-viz.html#sec:viz-4.4"><i class="fa fa-check"></i><b>9.4.4</b> Visual literacy</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="chap-viz.html"><a href="chap-viz.html#sec:viz-5"><i class="fa fa-check"></i><b>9.5</b> Summary</a></li>
<li class="chapter" data-level="9.6" data-path="chap-viz.html"><a href="chap-viz.html#sec:mylabel4"><i class="fa fa-check"></i><b>9.6</b> Resources</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="chap-errors.html"><a href="chap-errors.html"><i class="fa fa-check"></i><b>10</b> Errors and Inference</a><ul>
<li class="chapter" data-level="10.1" data-path="chap-errors.html"><a href="chap-errors.html#sec:10-1"><i class="fa fa-check"></i><b>10.1</b> Introduction</a></li>
<li class="chapter" data-level="10.2" data-path="chap-errors.html"><a href="chap-errors.html#sec:10-2"><i class="fa fa-check"></i><b>10.2</b> The total error paradigm</a><ul>
<li class="chapter" data-level="10.2.1" data-path="chap-errors.html"><a href="chap-errors.html#sec:10-2.1"><i class="fa fa-check"></i><b>10.2.1</b> The traditional model</a></li>
<li class="chapter" data-level="10.2.2" data-path="chap-errors.html"><a href="chap-errors.html#sec:10-2.2"><i class="fa fa-check"></i><b>10.2.2</b> Extending the framework to big data</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="chap-errors.html"><a href="chap-errors.html#sec:10-3"><i class="fa fa-check"></i><b>10.3</b> Illustrations of errors in big data</a></li>
<li class="chapter" data-level="10.4" data-path="chap-errors.html"><a href="chap-errors.html#sec:10-4"><i class="fa fa-check"></i><b>10.4</b> Errors in big data analytics</a><ul>
<li class="chapter" data-level="10.4.1" data-path="chap-errors.html"><a href="chap-errors.html#sec:10-4.1"><i class="fa fa-check"></i><b>10.4.1</b> Errors resulting from volume, velocity, and variety, assuming perfect veracity</a></li>
<li class="chapter" data-level="10.4.2" data-path="chap-errors.html"><a href="chap-errors.html#sec:10-4.2"><i class="fa fa-check"></i><b>10.4.2</b> Errors resulting from lack of veracity</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="chap-errors.html"><a href="chap-errors.html#sec:10-5"><i class="fa fa-check"></i><b>10.5</b> Some methods for mitigating, detecting, and compensating for errors</a></li>
<li class="chapter" data-level="10.6" data-path="chap-errors.html"><a href="chap-errors.html#sec:10-6"><i class="fa fa-check"></i><b>10.6</b> Summary</a></li>
<li class="chapter" data-level="10.7" data-path="chap-errors.html"><a href="chap-errors.html#resources-5"><i class="fa fa-check"></i><b>10.7</b> Resources</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="chap-privacy.html"><a href="chap-privacy.html"><i class="fa fa-check"></i><b>11</b> Privacy and Confidentiality</a><ul>
<li class="chapter" data-level="11.1" data-path="chap-privacy.html"><a href="chap-privacy.html#introduction-4"><i class="fa fa-check"></i><b>11.1</b> Introduction</a></li>
<li class="chapter" data-level="11.2" data-path="chap-privacy.html"><a href="chap-privacy.html#why-is-access-important"><i class="fa fa-check"></i><b>11.2</b> Why is access important?</a></li>
<li class="chapter" data-level="11.3" data-path="chap-privacy.html"><a href="chap-privacy.html#providing-access"><i class="fa fa-check"></i><b>11.3</b> Providing access</a></li>
<li class="chapter" data-level="11.4" data-path="chap-privacy.html"><a href="chap-privacy.html#the-new-challenges"><i class="fa fa-check"></i><b>11.4</b> The new challenges</a></li>
<li class="chapter" data-level="11.5" data-path="chap-privacy.html"><a href="chap-privacy.html#legal-and-ethical-framework"><i class="fa fa-check"></i><b>11.5</b> Legal and ethical framework</a></li>
<li class="chapter" data-level="11.6" data-path="chap-privacy.html"><a href="chap-privacy.html#summary-6"><i class="fa fa-check"></i><b>11.6</b> Summary</a></li>
<li class="chapter" data-level="11.7" data-path="chap-privacy.html"><a href="chap-privacy.html#resources-6"><i class="fa fa-check"></i><b>11.7</b> Resources</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="chap-workbooks.html"><a href="chap-workbooks.html"><i class="fa fa-check"></i><b>12</b> Workbooks</a><ul>
<li class="chapter" data-level="12.1" data-path="chap-workbooks.html"><a href="chap-workbooks.html#introduction-5"><i class="fa fa-check"></i><b>12.1</b> Introduction</a></li>
<li class="chapter" data-level="12.2" data-path="chap-workbooks.html"><a href="chap-workbooks.html#environment"><i class="fa fa-check"></i><b>12.2</b> Environment</a><ul>
<li class="chapter" data-level="12.2.1" data-path="chap-workbooks.html"><a href="chap-workbooks.html#running-workbooks-locally"><i class="fa fa-check"></i><b>12.2.1</b> Running workbooks locally</a></li>
<li class="chapter" data-level="12.2.2" data-path="chap-workbooks.html"><a href="chap-workbooks.html#central-workbook-server"><i class="fa fa-check"></i><b>12.2.2</b> Central workbook server</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="chap-workbooks.html"><a href="chap-workbooks.html#workbook-details"><i class="fa fa-check"></i><b>12.3</b> Workbook details</a><ul>
<li class="chapter" data-level="12.3.1" data-path="chap-workbooks.html"><a href="chap-workbooks.html#social-media-and-apis"><i class="fa fa-check"></i><b>12.3.1</b> Social Media and APIs</a></li>
<li class="chapter" data-level="12.3.2" data-path="chap-workbooks.html"><a href="chap-workbooks.html#database-basics"><i class="fa fa-check"></i><b>12.3.2</b> Database basics</a></li>
<li class="chapter" data-level="12.3.3" data-path="chap-workbooks.html"><a href="chap-workbooks.html#data-linkage"><i class="fa fa-check"></i><b>12.3.3</b> Data Linkage</a></li>
<li class="chapter" data-level="12.3.4" data-path="chap-workbooks.html"><a href="chap-workbooks.html#machine-learning"><i class="fa fa-check"></i><b>12.3.4</b> Machine Learning</a></li>
<li class="chapter" data-level="12.3.5" data-path="chap-workbooks.html"><a href="chap-workbooks.html#text-analysis"><i class="fa fa-check"></i><b>12.3.5</b> Text Analysis</a></li>
<li class="chapter" data-level="12.3.6" data-path="chap-workbooks.html"><a href="chap-workbooks.html#networks"><i class="fa fa-check"></i><b>12.3.6</b> Networks</a></li>
<li class="chapter" data-level="12.3.7" data-path="chap-workbooks.html"><a href="chap-workbooks.html#visualization"><i class="fa fa-check"></i><b>12.3.7</b> Visualization</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="chap-workbooks.html"><a href="chap-workbooks.html#resources-7"><i class="fa fa-check"></i><b>12.4</b> Resources</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Big Data and Social Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="chap:ml" class="section level1">
<h1><span class="header-section-number">Chapter 6</span> Machine Learning</h1>
<p><strong>Rayid Ghani and Malte Schierholz</strong></p>
<p>This chapter introduces you to the value of machine learning in the
social sciences, particularly focusing on the overall machine learning
process as well as clustering and classification methods. You will get
an overview of the machine learning pipeline and methods and how those
methods are applied to solve social science problems. The goal is to
give an intuitive explanation for the methods and to provide practical
tips on how to use them in practice.</p>
<div id="introduction-2" class="section level2">
<h2><span class="header-section-number">6.1</span> Introduction</h2>
<p>You have probably heard of “machine learning” but are not sure exactly
what it is, how it differs from traditional statistics, and what you can
do with it. In this chapter, we will demystify machine learning, draw
connections to what you already know from statistics and data analysis,
and go deeper into some of the unique concepts and methods that have
been developed in this field. Although the field originates from
computer science (specifically, artificial intelligence), it has been
influenced quite heavily by statistics in the past 15 years. As you will
see, many of the concepts you will learn are not entirely new, but are
simply called something else. For example, you already are familiar with
logistic regression (a classification method that falls under the
supervised learning framework in machine learning) and cluster analysis
(a form of unsupervised learning). You will also learn about new methods
that are more exclusively used in machine learning, such as random
forests and support vector machines. We will keep formalisms to a
minimum and focus on getting the intuition across, as well as providing
practical tips. Our hope is this chapter will make you comfortable and
familiar with machine learning vocabulary, concepts, and processes, and
allow you to further explore and use these methods and tools in your own
research and practice.</p>
</div>
<div id="what-is-machine-learning" class="section level2">
<h2><span class="header-section-number">6.2</span> What is machine learning?</h2>
<p>When humans improve their skills with experience, they are said to
learn. Is it also possible to program computers to do the same? Arthur
Samuel, who coined the term <em>machine learning</em> in 1959
<span class="citation">(Samuel <a href="#ref-samuel1959some">1959</a>)</span>, was a pioneer in this area, programming a computer to
play checkers. The computer played against itself and human opponents,
improving its performance with every game. Eventually, after sufficient
<em>training</em> (and experience), the computer became a better player than
the human programmer. Today, machine learning has grown significantly
beyond learning to play checkers. Machine learning systems have learned
to drive (and park) autonomous cars, are embedded inside robots, can
recommend books, products, and movies we are (sometimes) interested in,
identify drugs, proteins, and genes that should be investigated further
to cure diseases, detect cancer and other diseases in medical imaging,
help us understand how the human brain learns language, help identify
which voters are persuadable in elections, detect which students are
likely to need extra support to graduate high school on time, and help
solve many more problems. Over the past 20 years, machine learning has
become an interdisciplinary field spanning computer science, artificial
intelligence, databases, and statistics. At its core, machine learning
seeks to design computer systems that improve over time with more
experience. In one of the earlier books on machine learning, Tom
Mitchell gives a more operational definition, stating that: “A computer
program is said to learn from experience <span class="math inline">\(E\)</span> with respect to some class
of tasks <span class="math inline">\(T\)</span> and performance measure <span class="math inline">\(P\)</span>, if its performance at tasks in
<span class="math inline">\(T\)</span>, as measured by <span class="math inline">\(P\)</span>, improves with experience <span class="math inline">\(E\)</span>”
<span class="citation">(Mitchell <a href="#ref-mitchell1997machine">1997</a>)</span>.</p>

<div class="F00">
<p>
<strong>Box 6.1: Commercial machine learning examples</strong>
</p>
<ul>
<li>
<p>
<strong>Speech recognition</strong>: Speech recognition software uses machine learning algorithms that are built on large amounts of initial training data. Machine learning allows these systems to be tuned and adapt to individual variations in speaking as well as across different domains.
</p>
</li>
<li>
<p>
<strong>Autonomous cars</strong>: The ongoing development of self-driving cars applies techniques from machine learning. An onboard computer continuously analyzes the incoming video and sensor streams in order to monitor the surroundings. Incoming data are matched with annotated images to recognize objects like pedestrians, traffic lights, and potholes. In order to assess the different objects, huge training data sets are required where similar objects already have been identified. This allows the autonomous car to decide on which actions to take next.
</p>
</li>
<li>
<p>
<strong>Fraud detection</strong>: Many public and private organizations face the problem of fraud and abuse. Machine learning systems are widely used to take historical cases of fraud and flag fraudulent transactions as they take place. These systems have the benefit of being adaptive, and improving with more data over time.
</p>
</li>
<li>
<p>
<strong>Personalized ads</strong>: Many online stores have personalized recommendations promoting possible products of interest. Based on individual shopping history and what other similar users bought in the past, the website predicts products a user may like and tailors recommendations. Netflix and Amazon are two examples of companies whose recommendation software predicts how a customer would rate a certain movie or product and then suggests items with the highest predicted ratings. Of course there are some caveats here, since they then adjust the recommendations to maximize profits.
</p>
</li>
<li>
<p>
<strong>Face recognition</strong>: Surveillance systems, social networking platforms, and imaging software all use face detection and face recognition to first detect faces in images (or video) and then tag them with individuals for various tasks. These systems are trained by giving examples of faces to a machine learning system which then learns to detect new faces, and tag known individuals.
</p>
</li>
</ul>
</div>
<p>Machine learning grew from the need to build systems that were adaptive,
scalable, and cost-effective to build and maintain. A lot of tasks now
being done using machine learning used to be done by rule-based systems,
where experts would spend considerable time and effort developing and
maintaining the rules. The problem with those systems was that they were
rigid, not adaptive, hard to scale, and expensive to maintain. Machine
learning systems started becoming popular because they could improve the
system along all of these dimensions<a href="#fn33" class="footnote-ref" id="fnref33"><sup>33</sup></a>. Box 6.1
mentions several examples where machine learning is being used in
commercial applications today. Social scientists are uniquely placed
today to take advantage of the same advances in machine learning by
having better methods to solve several key problems they are tackling.
We will give concrete examples later in this chapter.</p>
<p>This chapter is not an exhaustive introduction to machine learning.
There are many books that have done an excellent job of that
<span class="citation">(Flach <a href="#ref-Flach">2012</a>; Hastie, Tibshirani, and Friedman <a href="#ref-HastieTibshirani">2001</a>; Mitchell <a href="#ref-mitchell1997machine">1997</a>)</span>. Instead, we present a
short and understandable introduction to machine learning for social
scientists, give an overview of the overall machine learning process,
provide an intuitive introduction to machine learning methods, give some
practical tips that will be helpful in using these methods, and leave a
lot of the statistical theory to machine learning textbooks. As you read
more about machine learning in the research literature or the media, you
will encounter names of other fields that are related (and practically
the same for most social science audiences), such as statistical
learning, data mining, and pattern recognition.</p>
</div>
<div id="the-machine-learning-process" class="section level2">
<h2><span class="header-section-number">6.3</span> The machine learning process</h2>
<p>When solving problems using machine learning methods, it is important to
think of the larger data-driven problem-solving process of which these
methods are a small part<a href="#fn34" class="footnote-ref" id="fnref34"><sup>34</sup></a>. A typical machine learning problem requires
researchers and practitioners to take the following steps:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Understand the problem and goal</strong>: This sounds obvious but is often nontrivial. Problems typically
start as vague descriptions of a goal—improving health outcomes,
increasing graduation rates, understanding the effect of a variable
<span class="math inline">\(X\)</span> on an outcome <span class="math inline">\(Y\)</span>, etc. It is really important to work with
people who understand the domain being studied to dig deeper and
define the problem more concretely. What is the analytical
formulation of the metric that you are trying to optimize?</p></li>
<li><p><strong>Formulate it as a machine learning problem</strong>: Is it a classification problem or a regression problem? Is the goal
to build a model that generates a ranked list prioritized by risk,
or is it to detect anomalies as new data come in? Knowing what kinds
of tasks machine learning can solve will allow you to map the
problem you are working on to one or more machine learning settings
and give you access to a suite of methods.</p></li>
<li><p><strong>Data exploration and preparation</strong>: Next, you need to carefully explore the data you have. What
additional data do you need or have access to? What variable will
you use to match records for integrating different data sources?
What variables exist in the data set? Are they continuous or
categorical? What about missing values? Can you use the variables in
their original form or do you need to alter them in some way?</p></li>
<li><p><strong>Feature engineering</strong>: In machine learning language, what you might know as independent
variables or predictors or factors or covariates are called
“features.” Creating good features is probably the most important
step in the machine learning process. This involves doing
transformations, creating interaction terms, or aggregating over
data points or over time and space.</p></li>
<li><p><strong>Method selection</strong>: Having formulated the problem and created your features, you now
have a suite of methods to choose from. It would be great if there
were a single method that always worked best for a specific type of
problem, but that would make things too easy. Typically, in machine
learning, you take a collection of methods and try them out to
empirically validate which one works the best for your problem. We
will give an overview of leading methods that are being used today
in this chapter.</p></li>
<li><p><strong>Evaluation</strong>: As you build a large number of possible models, you need a way to
select the model that is the best. This part of the chapter will
cover the validation methodology to first validate the models on
historical data as well as discuss a variety of evaluation metrics.
The next step is to validate using a field trial or experiment.</p></li>
<li><p><strong>Deployment</strong>: Once you have selected the best model and validated it using
historical data as well as a field trial, you are ready to put the
model into practice. You still have to keep in mind that new data
will be coming in, and the model might change over time. We will not
cover too much of those aspects in this chapter, but they are
important to keep in mind.</p></li>
</ol>
</div>
<div id="problem-formulation-mapping-a-problem-to-machine-learning-methods" class="section level2">
<h2><span class="header-section-number">6.4</span> Problem formulation: Mapping a problem to machine learning methods</h2>
<p>When working on a new problem, one of the first things we need to do is
to map it to a class of machine learning methods. In general, the
problems we will tackle, including the examples above, can be grouped
into two major categories:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Supervised learning</strong>: These are problems where there exists a target variable (continuous
or discrete) that we want to predict or classify data into.
Classification, prediction, and regression all fall into this
category. More formally, supervised learning methods predict a value
<span class="math inline">\(Y\)</span> given input(s) <span class="math inline">\(X\)</span> by learning (or estimating or fitting or
training) a function <span class="math inline">\(F\)</span>, where <span class="math inline">\(F(X) = Y\)</span>. Here, <span class="math inline">\(X\)</span> is the set of
variables (known as <em>features</em> in machine learning, or in other
fields as <em>predictors</em>) provided as input and <span class="math inline">\(Y\)</span> is the
target/dependent variable or a <em>label</em> (as it is known in machine
learning).</p>
<p>The goal of supervised learning methods is to search for that
function <span class="math inline">\(F\)</span> that best predicts <span class="math inline">\(Y\)</span>. When the output <span class="math inline">\(Y\)</span> is
categorical, this is known as <em>classification</em>. When <span class="math inline">\(Y\)</span> is a
continuous value, this is called <em>regression</em>. Sound familiar?</p>
<p>One key distinction in machine learning is that the goal is not just
to find the best function <span class="math inline">\(F\)</span> that can predict <span class="math inline">\(Y\)</span> for observed
outcomes (known <span class="math inline">\(Y\)</span>s) but to find one that best generalizes to new,
unseen data. This distinction makes methods more focused on
generalization and less on just fitting the data we have as best as
we can. It is important to note that you do that implicitly when
performing regression by not adding more and more higher-order terms
to get better fit statistics. By getting better fit statistics, we
<em>overfit</em> to the data and the performance on new (unseen) data often
goes down. Methods like the lasso <span class="citation">(Tibshirani <a href="#ref-tibshirani1996regression">1996</a>)</span>
penalize the model for having too many terms by performing what is
known as <em>regularization</em><a href="#fn35" class="footnote-ref" id="fnref35"><sup>35</sup></a>.</p></li>
<li><p><strong>Unsupervised learning</strong>: These are problems where there does not exist a target variable that
we want to predict but we want to understand “natural” groupings or
patterns in the data. Clustering is the most common example of this
type of analysis where you are given <span class="math inline">\(X\)</span> and want to group similar
<span class="math inline">\(X\)</span>s together. Principal components analysis (PCA) and related
methods also fall into the unsupervised learning category.</p></li>
</ol>
<p>In between the two extremes of supervised and unsupervised learning,
there is a spectrum of methods that have different levels of supervision
involved (Figure
<a href="chap-ml.html#fig:spectrum">6.1</a>). Supervision in this case is the presence
of target variables (known in machine learning as <em>labels</em>). In
unsupervised learning, none of the data points have labels. In
supervised learning, all data points have labels. In between, either the
percentage of examples with labels can vary or the types of labels can
vary. We do not cover the weakly supervised and semi-supervised methods
much in this chapter, but this is an active area of research in machine
learning. Zhu <span class="citation">(Zhu <a href="#ref-zhu2005semi">2008</a>)</span> provides more details.</p>
<div class="figure" style="text-align: center"><span id="fig:spectrum"></span>
<img src="ChapterML/figures/spectrum.png" alt="Spectrum of machine learning methods from unsupervised to supervised learning" width="70%" />
<p class="caption">
Figure 6.1: Spectrum of machine learning methods from unsupervised to supervised learning
</p>
</div>
</div>
<div id="methods" class="section level2">
<h2><span class="header-section-number">6.5</span> Methods</h2>
<p>We will start by describing unsupervised learning methods and then go on
to supervised learning methods. We focus here on the intuition behind
the methods and the algorithm, as well as practical tips, rather than on
the statistical theory that underlies the methods. We encourage readers
to refer to machine learning books listed in
Section <a href="chap-ml.html#ml:res">Resources</a>. Box 6.2 gives brief definitions of several terms we will use in this section.</p>
<div class="F00">
<p>
<strong>Box 6.2: Machine learning vocabulary</strong>
</p>
<ul>
<li>
<p>
<strong>Learning</strong>: In machine learning, you will notice the term <em>learning</em> that will be used in the context of “learning” a model. This is what you probably know as <em>fitting</em> or <em>estimating</em> a function, or <em>training</em> or <em>building</em> a model. These terms are all synonyms and are used interchangeably in the machine learning literature.
</p>
</li>
<li>
<p>
<strong>Examples</strong>: These are data points and instances.
</p>
</li>
<li>
<p>
<strong>Features</strong>: These are independent variables, attributes, predictor variables, and explanatory variables.
</p>
</li>
<li>
<p>
<strong>Labels</strong>: These include the response variable, dependent variable, and target variable.
</p>
</li>
<li>
<p>
<strong>Underfitting</strong>: This happens when a model is too simple and does not capture the structure of the data well enough.
</p>
</li>
<li>
<p>
<strong>Overfitting</strong>: This happens when a model is possibly too complex and models the noise in the data, which can result in poor generalization performance. Using in-sample measures to do model selection can result in that.
</p>
</li>
<li>
<p>
<strong>Regularization</strong>: This is a general method to avoid overfitting by applying additional constraints to the model that is learned. A common approach is to make sure the model weights are, on average, small in magnitude. Two common regularizations are <span class="math inline"><span class="math inline">\(L_1\)</span></span> regularization (used by the lasso), which has a penalty term that encourages the sum of the absolute values of the parameters to be small; and <span class="math inline"><span class="math inline">\(L_2\)</span></span> regularization, which encourages the sum of the squares of the parameters to be small.
</p>
</li>
</ul>
</div>
<div id="unsupervised-learning-methods" class="section level3">
<h3><span class="header-section-number">6.5.1</span> Unsupervised learning methods</h3>
<p>As mentioned earlier, unsupervised learning methods are used when we do
not have a target variable to predict but want to understand “natural”
clusters or patterns in the data. These methods are often used for
initial data exploration, as in the following examples:</p>
<ol style="list-style-type: decimal">
<li><p>When faced with a large corpus of text data—for example, email
records, congressional bills, speeches, or open-ended free-text
survey responses—unsupervised learning methods are often used to
understand and get a handle on what the data contain.</p></li>
<li><p>Given a data set about students and their behavior over time
(academic performance, grades, test scores, attendance, etc.), one
might want to understand typical behaviors as well as trajectories
of these behaviors over time. Unsupervised learning methods
(clustering) can be applied to these data to get student “segments”
with similar behavior.</p></li>
<li><p>Given a data set about publications or patents in different fields,
we can use unsupervised learning methods (association rules) to
figure out which disciplines have the most collaboration and which
fields have researchers who tend to publish across different fields.</p></li>
</ol>
<p><strong>Clustering</strong></p>
<p>Clustering is the most common unsupervised learning technique and is
used to group data points together that are similar to each other. The
goal of clustering methods is to produce with high intra-cluster
(within) similarity and low inter-cluster (between) similarity.</p>
<p>Clustering algorithms typically require a distance (or similarity)
metric<a href="#fn36" class="footnote-ref" id="fnref36"><sup>36</sup></a> to generate clusters. They take a data set and a distance metric
(and sometimes additional parameters), and they generate clusters based
on that distance metric. The most common distance metric used is
Euclidean distance, but other commonly used metrics are Manhattan,
Minkowski, Chebyshev, cosine, Hamming, Pearson, and Mahalanobis. Often,
domain-specific similarity metrics can be designed for use in specific
problems. For example, when performing the record linkage tasks
discussed in Chapter <a href="chap-link.html#chap:link">Record Linkage</a>, you can design a similarity metric that compares
two first names and assigns them a high similarity (low distance) if
they both map to the same canonical name, so that, for example, Sammy
and Sam map to Samuel.</p>
<p>Most clustering algorithms also require the user to specify the number
of clusters (or some other parameter that indirectly determines the
number of clusters) in advance as a parameter. This is often difficult
to do a priori and typically makes clustering an iterative and
interactive task. Another aspect of clustering that makes it interactive
is often the difficulty in automatically evaluating the quality of the
clusters. While various analytical clustering metrics have been
developed, the best clustering is task-dependent and thus must be
evaluated by the user. There may be different clusterings that can be
generated with the same data. You can imagine clustering similar news
stories based on the topic content, based on the writing style or based
on sentiment. The right set of clusters depends on the user and the task
they have. Clustering is therefore typically used for exploring the
data, generating clusters, exploring the clusters, and then rerunning
the clustering method with different parameters or modifying the
clusters (by splitting or merging the previous set of clusters).
Interpreting a cluster can be nontrivial: you can look at the centroid
of a cluster, look at frequency distributions of different features (and
compare them to the prior distribution of each feature), or you can
build a decision tree (a supervised learning method we will cover later
in this chapter) where the target variable is the cluster ID that can
describe the cluster using the features in your data. A good example of
a tool that allows interactive clustering from text data is Ontogen
<span class="citation">(Fortuna, Grobelnik, and Mladenic <a href="#ref-Ontogen">2007</a>)</span>.</p>

<p><strong><span class="math inline">\(k\)</span>-means clustering</strong></p>
<p>The most commonly used clustering algorithm is called <span class="math inline">\(k\)</span>-means, where
<span class="math inline">\(k\)</span> defines the number of clusters. The algorithm works as follows:</p>
<ol style="list-style-type: decimal">
<li><p>Select <span class="math inline">\(k\)</span> (the number of clusters you want to generate).</p></li>
<li><p>Initialize by selecting <span class="math inline">\(k\)</span> points as centroids of the <span class="math inline">\(k\)</span> clusters.
This is typically done by selecting <span class="math inline">\(k\)</span> points uniformly at random.</p></li>
<li><p>Assign each point a cluster according to the nearest centroid.</p></li>
<li><p>Recalculate cluster centroids based on the assignment in (3) as the
mean of all data points belonging to that cluster.</p></li>
<li><p>Repeat (3) and (4) until convergence.</p></li>
</ol>
<p>The algorithm stops when the assignments do not change from one
iteration to the next (Figure
<a href="chap-ml.html#fig:kmeans">6.2</a>). The final set of clusters, however, depend
on the starting points. If they are initialized differently, it is
possible that different clusters are obtained. One common practical
trick is to run <span class="math inline">\(k\)</span>-means several times, each with different (random)
starting points. The <span class="math inline">\(k\)</span>-means algorithm is fast, simple, and easy to
use, and is often a good first clustering algorithm to try and see if it
fits your needs. When the data are of the form where the mean of the
data points cannot be computed, a related method called <span class="math inline">\(K\)</span>-medoids can
be used <span class="citation">(Park and Jun <a href="#ref-park2009simple">2009</a>)</span>.</p>
<div class="figure" style="text-align: center"><span id="fig:kmeans"></span>
<img src="ChapterML/figures/kmeans.png" alt="Example of $k$-means clustering with $k = 3$. The upper left panel shows the distribution of the data and the three starting points $m_1$, $m_2$, $m_3$ placed at random. On the upper right we see what happens in the first iteration. The cluster means move to more central positions in their respective clusters. The lower left panel shows the second iteration. After six iterations the cluster means have converged to their final destinations and the result is shown in the lower right panel" width="70%" />
<p class="caption">
Figure 6.2: Example of <span class="math inline">\(k\)</span>-means clustering with <span class="math inline">\(k = 3\)</span>. The upper left panel shows the distribution of the data and the three starting points <span class="math inline">\(m_1\)</span>, <span class="math inline">\(m_2\)</span>, <span class="math inline">\(m_3\)</span> placed at random. On the upper right we see what happens in the first iteration. The cluster means move to more central positions in their respective clusters. The lower left panel shows the second iteration. After six iterations the cluster means have converged to their final destinations and the result is shown in the lower right panel
</p>
</div>
<p><strong>Expectation-maximization (EM) clustering</strong></p>

<p>You may be familiar with the EM algorithm in the context of imputing
missing data. EM is a general approach to maximum likelihood in the
presence of incomplete data. However, it is also used as a clustering
method where the missing data are the clusters a data point belongs to.
Unlike <span class="math inline">\(k\)</span>-means, where each data point gets assigned to only one
cluster, EM does a soft assignment where each data point gets a
probabilistic assignment to various clusters. The EM algorithm iterates
until the estimates converge to some (locally) optimal solution.</p>
<p>The EM algorithm is fairly good at dealing with outliers as well as
high-dimensional data, compared to <span class="math inline">\(k\)</span>-means. It also has a few
limitations. First, it does not work well with a large number of
clusters or when a cluster contains few examples. Also, when the value
of <span class="math inline">\(k\)</span> is larger than the number of actual clusters in the data, EM may
not give reasonable results.</p>
<p><strong>Mean shift clustering</strong></p>
<p>Mean shift clustering works by finding dense regions in the data by
defining a window around each data point and computing the mean of the
data points in the window. Then it shifts the center of the window to
the mean and repeats the algorithm till it converges. After each
iteration, we can consider that the window shifts to a denser region of
the data set. The algorithm proceeds as follows:</p>
<ol style="list-style-type: decimal">
<li><p>Fix a window around each data point (based on the bandwidth
parameter that defines the size of the window).</p></li>
<li><p>Compute the mean of data within the window.</p></li>
<li><p>Shift the window to the mean and repeat till convergence.</p></li>
</ol>
<p>Mean shift needs a bandwidth parameter <span class="math inline">\(h\)</span> to be tuned, which influences
the convergence rate and the number of clusters. A large <span class="math inline">\(h\)</span> might
result in merging distinct clusters. A small <span class="math inline">\(h\)</span> might result in too
many clusters. Mean shift might not work well in higher dimensions since
the number of local maxima is pretty high and it might converge to a
local optimum quickly.</p>
<p>One of the most important differences between mean shift and <span class="math inline">\(k\)</span>-means
is that <span class="math inline">\(k\)</span>-means makes two broad assumptions: the number of clusters is
already known and the clusters are shaped spherically (or elliptically).
Mean shift does not assume anything about the number of clusters (but
the value of <span class="math inline">\(h\)</span> indirectly determines that). Also, it can handle
arbitrarily shaped clusters.</p>
<p>The <span class="math inline">\(k\)</span>-means algorithm is also sensitive to initializations, whereas
mean shift is fairly robust to initializations. Typically, mean shift is
run for each point, or sometimes points are selected uniformly randomly.
Similarly, <span class="math inline">\(k\)</span>-means is sensitive to outliers, while mean shift is less
sensitive. On the other hand, the benefits of mean shift come at a
cost—speed. The <span class="math inline">\(k\)</span>-means procedure is fast, whereas classic mean
shift is computationally slow but can be easily parallelized.</p>
<p><strong>Hierarchical clustering</strong></p>

<p>The clustering methods that we have seen so far, often termed
<em>partitioning</em> methods, produce a flat set of clusters with no
hierarchy. Sometimes, we want to generate a hierarchy of clusters, and
methods that can do that are of two types:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Agglomerative (bottom-up)</strong>: Start with each point as its own cluster and iteratively merge the
closest clusters. The iterations stop either when the clusters are
too far apart to be merged (based on a predefined distance
criterion) or when there is a sufficient number of clusters (based
on a predefined threshold).</p></li>
<li><p><strong>Divisive (top-down)</strong>: Start with one cluster and create splits recursively.</p></li>
</ol>
<p>Typically, agglomerative clustering is used more often than divisive
clustering. One reason is that it is significantly faster, although both
of them are typically slower than direct partition methods such as
<span class="math inline">\(k\)</span>-means and EM. Another disadvantage of these methods is that they are
<em>greedy</em>, that is, a data point that is incorrectly assigned to the
“wrong” cluster in an earlier split or merge cannot be reassigned again
later on.</p>
<p><strong>Spectral clustering</strong></p>
<p>Figure <a href="chap-ml.html#fig:spectral">6.3</a> shows the clusters that <span class="math inline">\(k\)</span>-means would
generate on the data set in the figure. It is obvious that the clusters
produced are not the clusters you would want, and that is one drawback
of methods such as <span class="math inline">\(k\)</span>-means. Two points that are far away from each
other will be put in different clusters even if there are other data
points that create a “path” between them. Spectral clustering fixes that
problem by clustering data that are connected but not necessarily (what
is called) compact or clustered within convex boundaries. Spectral
clustering methods work by representing data as a graph (or network),
where data points are nodes in the graph and the edges (connections
between nodes) represent the similarity between the two data points.</p>
<div class="figure" style="text-align: center"><span id="fig:spectral"></span>
<img src="ChapterML/figures/spectral.png" alt="The same data set can produce drastically different clusters: (a) k-means; (b) spectral clustering" width="70%" />
<p class="caption">
Figure 6.3: The same data set can produce drastically different clusters: (a) k-means; (b) spectral clustering
</p>
</div>

<p>The algorithm works as follows:</p>
<ol style="list-style-type: decimal">
<li><p>Compute a similarity matrix from the data. This involves determining
a pairwise distance function (using one of the distance functions we
described earlier).</p></li>
<li><p>With this matrix, we can now perform graph partitioning, where
connected graph components are interpreted as clusters. The graph
must be partitioned such that edges connecting different clusters
have low weights and edges within the same cluster have high values.</p></li>
<li><p>We can now partition these data represented by the similarity matrix
in a variety of ways. One common way is to use the normalized cuts
method. Another way is to compute a graph Laplacian from the
similarity matrix.</p></li>
<li><p>Compute the eigenvectors and eigenvalues of the Laplacian.</p></li>
<li><p>The <span class="math inline">\(k\)</span> eigenvectors are used as proxy data for the original data
set, and they are fed into <span class="math inline">\(k\)</span>-means clustering to produce cluster
assignments for each original data point.</p></li>
</ol>
<p>Spectral clustering is in general much better than <span class="math inline">\(k\)</span>-means in
clustering performance but much slower to run in practice. For
large-scale problems, <span class="math inline">\(k\)</span>-means is a preferred clustering algorithm to
run because of efficiency and speed.</p>
<p><strong>Principal components analysis</strong></p>
<p>Principal components analysis is another unsupervised method used for
finding patterns and structure in data. In contrast to clustering
methods, the output is not a set of clusters but a set of <em>principal
components</em> that are linear combinations of the original variables. PCA
is typically used when you have a large number of variables and you want
a reduced number that you can analyze. This approach is often called
<em>dimensionality reduction</em>. It generates linearly uncorrelated
dimensions that can be used to understand the underlying structure of
the data. In mathematical terms, given a set of data on <span class="math inline">\(n\)</span> dimensions,
PCA aims to find a linear subspace of dimension <span class="math inline">\(d\)</span> lower than <span class="math inline">\(n\)</span> such
that the data points lie mainly on this linear subspace.</p>
<p>PCA is related to several other methods you may already know about.
Multidimensional scaling, factor analysis, and independent component
analysis differ from PCA in the assumptions they make, but they are
often used for similar purposes of dimensionality reduction and
discovering the underlying structure in a data set.</p>
<p><strong>Association rules</strong></p>
<p>Association rules are a different type of analysis method and originate
from the data mining and database community, primarily focused on
finding frequent co-occurring associations among a collection of items.
This methods is sometimes referred to as “market basket analysis,” since
that was the original application area of association rules. The goal is
to find associations of items that occur together more often than you
would randomly expect. The classic example (probably a myth) is “men who
go to the store to buy diapers will also tend to buy beer at the same
time.” This type of analysis would be performed by applying association
rules to a set of supermarket purchase data.</p>
<p>Association rules take the form <span class="math inline">\(X_1, X_2, X_3 \Rightarrow Y\)</span> with
support <span class="math inline">\(S\)</span> and confidence <span class="math inline">\(C\)</span>, implying that when a transaction
contains items <span class="math inline">\(\{X_1, X_2, X_3\}\)</span> <span class="math inline">\(C\)</span>% of the time, they also contain
item <span class="math inline">\(Y\)</span> and there are at least <span class="math inline">\(S\)</span>% of transactions where the
antecedent is true. This is useful in cases where we want to find
patterns that are both <em>frequent</em> and <em>statistically significant</em>, by
specifying thresholds for support <span class="math inline">\(S\)</span> and confidence <span class="math inline">\(C\)</span>.</p>
<p>Support and confidence are useful metrics to generate rules but are
often not enough. Another important metric used to generate rules (or
reduce the number of spurious patterns generated) is <em>lift</em>. Lift is
simply estimated by the ratio of the joint probability of two items, <span class="math inline">\(x\)</span>
and <span class="math inline">\(y\)</span>, to the product of their individual probabilities:
<span class="math inline">\(P(x,y)/[P(x)P(y)]\)</span>. If the two items are statistically independent,
then <span class="math inline">\(P(x,y)=P(x)P(y)\)</span>, corresponding to a lift of <span class="math inline">\(1\)</span>. Note that
anti-correlation yields lift values less than 1, which is also an
interesting pattern, corresponding to mutually exclusive items that
rarely occur together.</p>
<p>Association rule algorithms work as follows: Given a set of transactions
(rows) and items for that transaction:</p>
<ol style="list-style-type: decimal">
<li><p>Find all combinations of items in a set of transactions that occur
with a specified minimum frequency. These combinations are called
<em>frequent itemsets</em>.</p></li>
<li><p>Generate association rules that express co-occurrence of items
within frequent itemsets.</p></li>
</ol>
<p>For our purposes, association rule methods are an efficient way to take
a <em>basket</em> of features (e.g., areas of publication of a researcher,
different organizations an individual has worked at in their career, all
the cities or neighborhoods someone may have lived in) and find
co-occurrence patterns. This may sound trivial, but as data sets and
number of features get larger, it becomes computationally expensive and
association rule mining algorithms provide a fast and efficient way of
doing it.</p>
</div>
<div id="sec:MLchapter:super" class="section level3">
<h3><span class="header-section-number">6.5.2</span> Supervised learning</h3>
<p>We now turn to the problem of supervised learning, which typically
involves methods for classification, prediction, and regression. We will
mostly focus on classification methods in this chapter since many of the
regression methods in machine learning are fairly similar to methods
with which you are already familiar. Remember that classification means
predicting a discrete (or categorical) variable. Some of the
classification methods that we will cover can also be used for
regression, a fact that we will mention when describing that method.</p>
<p>In general, supervised learning methods take as input pairs of data
points <span class="math inline">\((X,Y)\)</span> where <span class="math inline">\(X\)</span> are the predictor variables (features) and <span class="math inline">\(Y\)</span>
is the target variable (label). The supervised learning method then uses
these pairs as <em>training data</em> and learns a model <span class="math inline">\(F\)</span>, where
<span class="math inline">\(F(X)\sim Y\)</span>. This model <span class="math inline">\(F\)</span> is then used to predict <span class="math inline">\(Y\)</span>s for new data
points <span class="math inline">\(X\)</span>. As mentioned earlier, the goal is not to build a model that
best fits known data but a model that is useful for future predictions
and minimizes future generalization error. This is the key goal that
differentiates many of the methods that you know from the methods that
we will describe next. In order to minimize future error, we want to
build models that are not just <em>overfitting</em> on past data.</p>
<p>Another goal, often prioritized in the social sciences, that machine
learning methods do not optimize for is getting a structural form of the
model. Machine learning models for classification can take different
structural forms (ranging from linear models, to sets of rules, to more
complex forms), and it may not always be possible to write them down in
a compact form as an equation. This does not, however, make them
incomprehensible or uninterpretable. Another focus of machine learning
models for supervised learning is prediction, and not causal inference<a href="#fn37" class="footnote-ref" id="fnref37"><sup>37</sup></a>.
Some of these models can be used to help with causal inference, but they
are typically optimized for prediction tasks. We believe that there are
many social science and policy problems where better prediction methods
can be extremely beneficial.</p>
<p>In this chapter, we mostly deal with binary classification problems:
that is, problems in which the data points are to be classified into one
of two categories. Several of the methods that we will cover can also be
used for multiclass classification (classifying a data point into one of
<span class="math inline">\(n\)</span> categories) or for multi-label classification (classifying a data
point into <span class="math inline">\(m\)</span> of <span class="math inline">\(n\)</span> categories where <span class="math inline">\(m\ge1\)</span>). There are also
approaches to take multiclass problems and turn them into a set of
binary problems that we will mention briefly at the end of the chapter.</p>
<p>Before we describe supervised learning methods, we want to recap a few
principles as well as terms that we have used and will be using in the
rest of the chapter.</p>
<p><strong>Training a model</strong></p>
<p>Once we have finished data exploration, filled in missing values,
created predictor variables (features), and decided what our target
variable (label) is, we now have pairs of <span class="math inline">\(X,Y\)</span> to start training (or
building) the model.</p>
<p><strong>Using the model to score new data</strong></p>
<p>We are building this model so we can predict <span class="math inline">\(Y\)</span> for a new set of
<span class="math inline">\(X\)</span>s—using the model means, getting new data, generating the same
features to get the vector <span class="math inline">\(X\)</span>, and then applying the model to produce
<span class="math inline">\(Y\)</span>.</p>
<p>One common technique for supervised learning is logistic regression, a
method you will already be familiar with. We will give an overview of
some of the other methods used in machine learning. It is important to
remember that as you use increasingly powerful classification methods,
you need more data to <em>train</em> the models.</p>
<p><strong><span class="math inline">\(k\)</span>-nearest neighbor</strong></p>
<p>The method <span class="math inline">\(k\)</span>-nearest neighbor (<span class="math inline">\(k\)</span>-NN) is one of the simpler
classification methods in machine learning. It belongs to a family of
models sometimes known as <em>memory-based models</em> or <em>instance-based
models</em>. An example is classified by finding its <span class="math inline">\(k\)</span> nearest neighbors
and taking majority vote (or some other aggregation function). We need
two key things: a value for <span class="math inline">\(k\)</span> and a distance metric with which to find
the <span class="math inline">\(k\)</span> nearest neighbors. Typically, different values of <span class="math inline">\(k\)</span> are used
to empirically find the best one. Small values of <span class="math inline">\(k\)</span> lead to
predictions having high variance but can capture the local structure of
the data. Larger values of <span class="math inline">\(k\)</span> build more global models that are lower
in variance but may not capture local structure in the data as well.</p>
<p>Figure <a href="chap-ml.html#fig:knn">6.4</a> provides an example for <span class="math inline">\(k = 1, 3, 5\)</span> nearest
neighbors. The number of neighbors (<span class="math inline">\(k\)</span>) is a parameter, and the
prediction depends heavily on how it is determined. In this example,
point B is classified differently if <span class="math inline">\(k = 3\)</span>.</p>
<div class="figure" style="text-align: center"><span id="fig:knn"></span>
<img src="ChapterML/figures/knn.png" alt="Example of $k$-nearest neighbor with $k = 1, 3, 5$ neighbors. We want to predict the points A and B. The 1-nearest neighbor for both points is red (&quot;Patent not granted&quot;), the 3-nearest neighbor predicts point A (B) to be red (green) with probability 2/3, and the 5-nearest neighbor predicts again both points to be red with probabilities 4/5 and 3/5, respectively." width="70%" />
<p class="caption">
Figure 6.4: Example of <span class="math inline">\(k\)</span>-nearest neighbor with <span class="math inline">\(k = 1, 3, 5\)</span> neighbors. We want to predict the points A and B. The 1-nearest neighbor for both points is red (“Patent not granted”), the 3-nearest neighbor predicts point A (B) to be red (green) with probability 2/3, and the 5-nearest neighbor predicts again both points to be red with probabilities 4/5 and 3/5, respectively.
</p>
</div>

<p>Training for <span class="math inline">\(k\)</span>-NN just means storing the data, making this method
useful in applications where data are coming in extremely quickly and a
model needs to be updated frequently. All the work, however, gets pushed
to scoring time, since all the distance calculations happen when a new
data point needs to be classified. There are several optimized methods
designed to make <span class="math inline">\(k\)</span>-NN more efficient that are worth looking into if
that is a situation that is applicable to your problem.</p>
<p>In addition to selecting <span class="math inline">\(k\)</span> and an appropriate distance metric, we also
have to be careful about the scaling of the features. When distances
between two data points are large for one feature and small for a
different feature, the method will rely almost exclusively on the first
feature to find the closest points. The smaller distances on the second
feature are nearly irrelevant to calculate the overall distance. A
similar problem occurs when continuous and categorical predictors are
used together. To resolve the scaling issues, various options for
rescaling exist. For example, a common approach is to center all
features at mean <span class="math inline">\(0\)</span> and scale them to variance <span class="math inline">\(1\)</span>.</p>
<p>There are several variations of <span class="math inline">\(k\)</span>-NN. One of these is weighted nearest
neighbors, where different features are weighted differently or
different examples are weighted based on the distance from the example
being classified. The method <span class="math inline">\(k\)</span>-NN also has issues when the data are
sparse and has high dimensionality, which means that every point is far
away from virtually every other point, and hence pairwise distances tend
to be uninformative. This can also happen when a lot of features are
irrelevant and drown out the relevant features’ signal in the distance
calculations.</p>
<p>Notice that the nearest-neighbor method can easily be applied to
regression problems with a real-valued target variable. In fact, the
method is completely oblivious to the type of target variable and can
potentially be used to predict text documents, images, and videos, based
on the aggregation function after the nearest neighbors are found.</p>

<p><strong>Support vector machines</strong></p>
<p>Support vector machines are one of the most popular and best-performing
classification methods in machine learning today. The mathematics behind
SVMs has a lot of prerequisites that are beyond the scope of this book,
but we will give you an intuition of how SVMs work, what they are good
for, and how to use them.</p>
<p>We are all familiar with linear models that separate two classes by
fitting a line in two dimensions (or a hyperplane in higher dimensions)
in the middle (see Figure <a href="chap-ml.html#fig:svm">6.5</a>). An important decision that linear models have
to make is which linear separator we should prefer when there are
several we can build.</p>
<div class="figure" style="text-align: center"><span id="fig:svm"></span>
<img src="ChapterML/figures/svm.png" alt="Support vector machines" width="100%" />
<p class="caption">
Figure 6.5: Support vector machines
</p>
</div>
<p>You can see in Figure <a href="chap-ml.html#fig:svm">6.5</a> that multiple lines offer a solution to the
problem. Is any of them better than the others? We can intuitively
define a criterion to estimate the worth of the lines: A line is bad if
it passes too close to the points because it will be noise sensitive and
it will not generalize correctly. Therefore, our goal should be to find
the line passing as far as possible from all points.</p>
<p>The SVM algorithm is based on finding the hyperplane that maximizes the
<em>margin</em> of the training data. The training examples that are closest to
the hyperplane are called <em>support vectors</em> since they are <em>supporting</em>
the margin (as the margin is only a function of the support vectors).</p>
<p>An important concept to learn when working with SVMs is <em>kernels</em>. SVMs
are a specific instance of a class of methods called <em>kernel methods</em>.
So far, we have only talked about SVMs as linear models. Linear works
well in high-dimensional data but sometimes you need nonlinear models,
often in cases of low-dimensional data or in image or video data.
Unfortunately, traditional ways of generating nonlinear models get
computationally expensive since you have to explicitly generate all the
features such as squares, cubes, and all the interactions. Kernels are a
way to keep the efficiency of the linear machinery but still build
models that can capture nonlinearity in the data without creating all
the nonlinear features.</p>
<p>You can essentially think of kernels as similarity functions and use
them to create a linear separation of the data by (implicitly) mapping
the data to a higher-dimensional space. Essentially, we take an
<span class="math inline">\(n\)</span>-dimensional input vector <span class="math inline">\(X\)</span>, map it into a high-dimensional (
infinite-dimensional) feature space, and construct an optimal separating
hyperplane in this space. We refer you to relevant papers for more
detail on SVMs and nonlinear kernels <span class="citation">(Shawe-Taylor and Cristianini <a href="#ref-ShaweTaylor2004">2004</a>; Scholkopf and Smola <a href="#ref-Scholkopf2001">2001</a>)</span>.
SVMs are also related to logistic regression, but use a different
loss/penalty function <span class="citation">(Hastie, Tibshirani, and Friedman <a href="#ref-HastieTibshirani">2001</a>)</span>.</p>
<p>When using SVMs, there are several parameters you have to optimize,
ranging from the <em>regularization</em> parameter <span class="math inline">\(C\)</span>, which determines the
tradeoff between minimizing the training error and minimizing model
complexity, to more kernel-specific parameters. It is often a good idea
to do a grid search to find the optimal parameters. Another tip when
using SVMs is to normalize the features; one common approach to doing
that is to normalize each data point to be a vector of unit length.</p>
<p>Linear SVMs are effective in high-dimensional spaces, especially when
the space is sparse such as text classification where the number of data
points (perhaps tens of thousands) is often much less than the number of
features (a hundred thousand to a million or more). SVMs are also fairly
robust when the number of irrelevant features is large (unlike the
<span class="math inline">\(k\)</span>-NN approaches that we mentioned earlier) as well as when the class
distribution is skewed, that is, when the class of interest is
significantly less than 50% of the data.</p>
<p>One disadvantage of SVMs is that they do not directly provide
probability estimates. They assign a score based on the distance from
the margin. The farther a point is from the margin, the higher the
magnitude of the score. This score is good for ranking examples, but
getting accurate probability estimates takes more work and requires more
labeled data to be used to perform probability calibrations.</p>
<p>In addition to classification, there are also variations of SVMs that
can be used for regression <span class="citation">(Smola and Schölkopf <a href="#ref-SmolaRegression04">2004</a>)</span> and ranking
<span class="citation">(Chapelle and Keerthi <a href="#ref-Chapelle2010">2010</a>)</span>.</p>
<p><strong>Decision trees</strong></p>
<p>Decision trees are yet another set of methods that are helpful for
prediction. Typical decision trees learn a set of rules from training
data represented as a tree. An exemplary decision tree is shown in
Figure <a href="chap-ml.html#fig:tree">6.6</a>. Each level of a tree <em>splits</em> the tree to
create a branch using a feature and a value (or range of values). In the
example tree, the first split is made on the feature <em>number of visits
in the past year</em> and the value <span class="math inline">\(4\)</span>. The second level of the tree now
has two splits: one using <em>average length of visit</em> with value <span class="math inline">\(2\)</span> days
and the other using the value <span class="math inline">\(10\)</span> days.</p>
<img src="ChapterML/figures/tree.png" width="70%" style="display: block; margin: auto;" />
<div class="figure" style="text-align: center"><span id="fig:tree"></span>
<img src="ChapterML/figures/tree-rectangle.png" alt="An exemplary decision tree. The top figure is the standard representation for trees. The bottom figure offers an alternative view of the same tree. The feature space is partitioned into numerous rectangles, which is another way to view a tree, representing its nonlinear character more explicitly" width="70%" />
<p class="caption">
Figure 6.6: An exemplary decision tree. The top figure is the standard representation for trees. The bottom figure offers an alternative view of the same tree. The feature space is partitioned into numerous rectangles, which is another way to view a tree, representing its nonlinear character more explicitly
</p>
</div>
<p>Various algorithms exist to build decision trees. C4.5, CHAID, and CART
(Classification and Regression Trees) are the most Each needs to
determine the next best feature to split on. The goal is to find feature
splits that can best reduce class impurity in the data, that is, a split
that will ideally put all (or as many as possible) positive class
examples on one side and all (or as many as possible) negative examples
on the other side. One common measure of impurity that comes from
information theory is <em>entropy</em>, and it is calculated as
<span class="math display">\[H(X) = -\sum_x p(x) \log p(x).\]</span></p>
<p>Entropy is maximum (1) when both classes have equal numbers of examples
in a node. It is minimum (0) when all examples are from the same class.
At each node in the tree, we can evaluate all the possible features and
select the one that most reduces the entropy given the tree so far. This
expected change in entropy is known as <em>information gain</em> and is one of
the most common criteria used to create decision trees. Other measures
that are used instead of information gain are Gini and chi-squared.</p>
<p>If we keep constructing the tree in this manner, selecting the next best
feature to split on, the tree ends up fairly deep and tends to overfit
the data. To prevent overfitting, we can either have a stopping
criterion or <em>prune</em> the tree after it is fully grown. Common stopping
criteria include minimum number of data points to have before doing
another feature split, maximum depth, and maximum purity. Typical
pruning approaches use holdout data (or cross-validation, which will be
discussed later in this chapter) to cut off parts of the tree.</p>
<p>Once the tree is built, a new data point is classified by running it
through the tree and, once it reaches a terminal node, using some
aggregation function to give a prediction (classification or
regression). Typical approaches include performing maximum likelihood
(if the leaf node contains 10 examples, 8 positive and 2 negative, any
data point that gets into that node will get an 80% probability of being
positive). Trees used for regression often build the tree as described
above but then fit a linear regression model at each leaf node.</p>
<p>Decision trees have several advantages. The interpretation of a tree is
straightforward as long as the tree is not too large. Trees can be
turned into a set of rules that experts in a particular domain can
possibly dig deeper into, validate, and modify. Trees also do not
require too much feature engineering. There is no need to create
interaction terms since trees can implicitly do that by splitting on two
features, one after another.</p>
<p>Unfortunately, along with these benefits come a set of disadvantages.
Decision trees, in general, do not perform well, compared to SVMs,
random forests, or logistic regression. They are also unstable: small
changes in data can result in very different trees. The lack of
stability comes from the fact that small changes in the training data
may lead to different splitting points. As a consequence, the whole tree
may take a different structure. The suboptimal predictive performance
can be seen from the fact that trees partition the predictor space into
a few rectangular regions, each one predicting only a single value (see
the bottom part of Figure <a href="chap-ml.html#fig:tree">6.6</a>.</p>
<p><strong>Ensemble methods</strong></p>
<p>Combinations of models are generally known as model ensembles. They are
among the most powerful techniques in machine learning, often
outperforming other methods, although at the cost of increased
algorithmic and model complexity.</p>
<p>The intuition behind building ensembles of models is to build several
models, each somewhat different. This diversity can come from various
sources such as: training models on subsets of the data; training models
on subsets of the features; or a combination of these two.</p>
<p>Ensemble methods in machine learning have two things in common. First,
they construct multiple, diverse predictive models from adapted versions
of the training data (most often reweighted or resampled). Second, they
combine the predictions of these models in some way, often by simple
averaging or voting (possibly weighted).</p>
<p><strong>Bagging</strong></p>
<p>Bagging stands for “bootstrap aggregation”<a href="#fn38" class="footnote-ref" id="fnref38"><sup>38</sup></a>: we first create bootstrap
samples from the original data and then aggregate the predictions using
models trained on each bootstrap sample. Given a data set of size <span class="math inline">\(N\)</span>,
the method works as follows:</p>
<ol style="list-style-type: decimal">
<li><p>Create <span class="math inline">\(k\)</span> bootstrap samples (with replacement), each of size <span class="math inline">\(N\)</span>,
resulting in <span class="math inline">\(k\)</span> data sets. Only about 63% of the original training
examples will be represented in any given bootstrapped set.</p></li>
<li><p>Train a model on each of the <span class="math inline">\(k\)</span> data sets, resulting in <span class="math inline">\(k\)</span> models.</p></li>
<li><p>For a new data point <span class="math inline">\(X\)</span>, predict the output using each of the <span class="math inline">\(k\)</span>
models.</p></li>
<li><p>Aggregate the <span class="math inline">\(k\)</span> predictions (typically using average or voting) to
get the prediction for <span class="math inline">\(X\)</span>.</p></li>
</ol>
<p>A nice feature of this method is that any underlying model can be used,
but decision trees are often the most commonly used base model. One
reason for this is that decision tress are typically high variance and
unstable, that is, they can change drastically given small changes in
data, and bagging is effective at reducing the variance of the overall
model. Another advantage of bagging is that each model can be trained in
parallel, making it efficient to scale to large data sets.</p>
<p><strong>Boosting</strong></p>
<p>Boosting is another popular ensemble technique, and it often results in
improving the base classifier being used. In fact, if your only goal is
improving accuracy, you will most likely find that boosting will achieve
that. The basic idea is to keep training classifiers iteratively, each
iteration focusing on examples that the previous one got wrong. At the
end, you have a set of classifiers, each trained on smaller and smaller
subsets of the training data. Given a new data point, all the
classifiers predict the target, and a weighted average of those
predictions is used to get the final prediction, where the weight is
proportional to the accuracy of each classifier. The algorithm works as
follows:</p>
<ol style="list-style-type: decimal">
<li><p>Assign equal weights to every example.</p></li>
<li><p>For each iteration:</p>
<ol style="list-style-type: decimal">
<li><p>Train classifier on the weighted examples.</p></li>
<li><p>Predict on the training data.</p></li>
<li><p>Calculate error of the classifier on the training data.</p></li>
<li><p>Calculate the new weighting on the examples based on the errors
of the classifier.</p></li>
<li><p>Reweight examples.</p></li>
</ol></li>
<li><p>Generate a weighted classifier based on the accuracy of each
classifier.</p></li>
</ol>
<p>One constraint on the classifier used within boosting is that it should
be able to handle weighted examples (either directly or by replicating
the examples that need to be overweighted). The most common classifiers
used in boosting are decision stumps (single-level decision trees), but
deeper trees can also work well.</p>
<p>Boosting is a common way to <em>boost</em> the performance of a classification
method but comes with additional complexity, both in the training time
and in interpreting the predictions. A disadvantage of boosting is that
it is difficult to parallelize since the next iteration of boosting
relies on the results of the previous iteration.</p>
<p>A nice property of boosting is its ability to identify outliers:
examples that are either mislabeled in the training data, or are
inherently ambiguous and hard to categorize. Because boosting focuses
its weight on the examples that are more difficult to classify, the
examples with the highest weight often turn out to be outliers. On the
other hand, if the number of outliers is large (lots of noise in the
data), these examples can hurt the performance of boosting by focusing
too much on them.</p>
<p><strong>Random forests</strong></p>
<p>Given a data set of size <span class="math inline">\(N\)</span> and containing <span class="math inline">\(M\)</span> features, the random
forest training algorithm works as follows:</p>
<ol style="list-style-type: decimal">
<li><p>Create <span class="math inline">\(n\)</span> bootstrap samples from the original data of size <span class="math inline">\(N\)</span>.
Remember, this is similar to the first step in bagging. Typically
<span class="math inline">\(n\)</span> ranges from 100 to a few thousand but is best determined
empirically.</p></li>
<li><p>For each bootstrap sample, train a decision tree using <span class="math inline">\(m\)</span> features
(where <span class="math inline">\(m\)</span> is typically much smaller than <span class="math inline">\(M\)</span>) at each node of the
tree. The <span class="math inline">\(m\)</span> features are selected uniformly at random from the <span class="math inline">\(M\)</span>
features in the data set, and the decision tree will select the best
split among the <span class="math inline">\(m\)</span> features. The value of <span class="math inline">\(m\)</span> is held constant
during the forest growing.</p></li>
<li><p>A new test example/data point is classified by all the trees, and
the final classification is done by majority vote (or another
appropriate aggregation method).</p></li>
</ol>
<p>Random forests are probably the most accurate classifiers being used
today in machine learning. They can be easily parallelized, making them
efficient to run on large data sets, and can handle a large number of
features, even with a lot of missing values. Random forests can get
complex, with hundreds or thousands of trees that are fairly deep, so it
is difficult to interpret the learned model. At the same time, they
provide a nice way to estimate feature importance, giving a sense of
what features were important in building the classifier.</p>
<p>Another nice aspect of random forests is the ability to compute a
proximity matrix that gives the similarity between every pair of data
points. This is calculated by computing the number of times two examples
land in the same terminal node. The more that happens, the closer the
two examples are. We can use this proximity matrix for clustering,
locating outliers, or explaining the predictions for a specific example.</p>
<p><strong>Stacking</strong></p>
<p>Stacking is a technique that deals with the task of learning a
meta-level classifier to combine the predictions of multiple base-level
classifiers. This meta-algorithm is trained to combine the model
predictions to form a final set of predictions. This can be used for
both regression and classification. The algorithm works as follows:</p>
<ol style="list-style-type: decimal">
<li><p>Split the data set into <span class="math inline">\(n\)</span> equal-sized sets:
<span class="math inline">\(set_1, set_2,\ldots,set_n\)</span>.</p></li>
<li><p>Train base models on all possible combinations of <span class="math inline">\(n-1\)</span> sets and,
for each model, use it to predict on <span class="math inline">\(set_i\)</span> what was left out of
the training set. This would give us a set of predictions on every
data point in the original data set.</p></li>
<li><p>Now train a second-stage stacker model on the predicted classes or
the predicted probability distribution over the classes from the
first-stage (base) model(s).</p></li>
</ol>
<p>By using the first-stage predictions as features, a stacker model gets
more information on the problem space than if it were trained in
isolation. The technique is similar to cross-validation, an evaluation
methodology that we will cover later in this chapter.</p>
<p><strong>Neural networks and deep learning</strong></p>
<p>Neural networks are a set of multi-layer classifiers where the outputs
of one layer feed into the inputs of the next layer. The layers between
the input and output layers are called <em>hidden layers</em>, and the more
hidden layers a neural network has, the more complex functions it can
learn. Neural networks were popular in the 1980s and early 1990s, but
then fell out of fashion because they were slow and expensive to train,
even with only one or two hidden layers. Since 2006, a set of techniques
has been developed that enable learning in deeper neural networks. These
techniques have enabled much deeper (and larger) networks to be
trained—people now routinely train networks with five to ten hidden
layers. And it turns out that these perform far better on many problems
than shallow neural networks (with just a single hidden layer). The
reason for the better performance is the ability of deep nets to build
up a complex hierarchy of concepts, learning multiple levels of
representation and abstraction that help to make sense of data such as
images, sound, and text.</p>
<p>Usually, with a supervised neural network you try to predict a target
vector, <span class="math inline">\(Y\)</span>, from a matrix of inputs, <span class="math inline">\(X\)</span>. But when you train a deep
neural network, it uses a combination of supervised and unsupervised
learning. In an unsupervised neural network, you try to predict the
matrix <span class="math inline">\(X\)</span> using the same matrix <span class="math inline">\(X\)</span> as the input. In doing this, the
network can learn something intrinsic about the data without the help of
a separate target or label. The learned information is stored as the
weights of the network.</p>
<p>Currently, deep neural networks are trendy and a lot of research is
being done on them. It is, however, important to keep in mind that they
are applicable for a narrow class of problems with which social
scientists would deal and that they often require a lot more data than
are available in most problems. Training deep neural networks also
requires a lot of computational power, but that is less likely to be an
issue for most people. Typical cases where deep learning has been shown
to be effective involve lots of images, video, and text data. We are
still in the early stages of development of this class of methods, and
the next few years will give us a much better understanding of why they
are effective and the problems for which they are well suited.</p>
</div>
</div>
<div id="evaluation" class="section level2">
<h2><span class="header-section-number">6.6</span> Evaluation</h2>
<p>The previous section introduced us to a variety of methods, all with
certain pros and cons, and no single method guaranteed to outperforms
others for a given problem. This section focuses on evaluation methods,
with three primary goals:</p>
<ol style="list-style-type: decimal">
<li><p>Model selection: How do we select a method to use? What parameters
should we select for that method?</p></li>
<li><p>Performance estimation: How well will our model do once it is
deployed and applied to new data?</p></li>
<li><p>A deeper understanding of the model can point to inaccuracies of
existing methods and provide a better understanding of the data and
the problem we are tackling.</p></li>
</ol>
<p>This section will cover evaluation methodologies as well as metrics that
are commonly used. We will start by describing common evaluation
methodologies that use existing data and then move on to field trials.
The methodologies we describe below apply both to regression and
classification problems.</p>
<div id="methodology" class="section level3">
<h3><span class="header-section-number">6.6.1</span> Methodology</h3>
<p><strong>In-sample evaluation</strong></p>
<p>As social scientists, you already evaluate methods on how well they
perform in-sample (on the set that the model was trained on). As we
mentioned earlier in the chapter, the goal of machine learning methods
is to generalize to new data, and validating models in-sample does not
allow us to do that. We focus here on evaluation methodologies that
allow us to optimize (as best as we can) for generalization performance.
The methods are illustrated in
Figure <a href="chap-ml.html#fig:holdout">6.7</a>.</p>
<p><strong>Out-of-sample and holdout set</strong></p>
<p>The simplest way to focus on generalization is to <em>pretend</em> to
generalize to new (unseen) data. One way to do that is to take the
original data and randomly split them into two sets: a <em>training set</em>
and a <em>test set</em> (sometimes also called the <em>holdout</em> or <em>validation
set</em>). We can decide how much to keep in each set (typically the splits
range from 50–50 to 80–20, depending on the size of the data set). We
then train our models on the training set and classify the data in the
test set, allowing us to get an estimate of the relative performance of
the methods.</p>
<p>One drawback of this approach is that we may be extremely lucky or
unlucky with our random split. One way to get around the problem that is
to repeatedly create multiple training and test sets. We can then train
on <span class="math inline">\(TR_1\)</span> and test on <span class="math inline">\(TE_1\)</span>, train on <span class="math inline">\(TR_2\)</span> and test on <span class="math inline">\(TE_2\)</span>, and so
on. The performance measures on each test set can then give us an
estimate of the performance of different methods and how much they vary
across different random sets.</p>
<div class="figure" style="text-align: center"><span id="fig:holdout"></span>
<img src="ChapterML/figures/holdout.png" alt="Validation methodologies: holdout set and cross-validation" width="70%" />
<p class="caption">
Figure 6.7: Validation methodologies: holdout set and cross-validation
</p>
</div>
<p><strong>Cross-validation</strong></p>
<p>Cross-validation is a more sophisticated holdout training and testing
procedure that takes away some of the shortcomings of the holdout set
approach. Cross-validation begins by splitting a labeled data set into
<span class="math inline">\(k\)</span> partitions (called folds). Typically, <span class="math inline">\(k\)</span> is set to <span class="math inline">\(5\)</span> or <span class="math inline">\(10\)</span>.
Cross-validation then proceeds by iterating <span class="math inline">\(k\)</span> times. In each
iteration, one of the <span class="math inline">\(k\)</span> folds is held out as the test set, while the
other <span class="math inline">\(k-1\)</span> folds are combined and used to train the model. A nice
property of cross-validation is that every example is used in one test
set for testing the model. Each iteration of cross-validation gives us a
performance estimate that can then be aggregated (typically averaged) to
generate the overall estimate.</p>
<p>An extreme case of cross-validation is called leave-one-out
cross-validation, where given a data set of size <span class="math inline">\(N\)</span>, we create <span class="math inline">\(N\)</span>
folds. That means iterating over each data point, holding it out as the
test set, and training on the rest of the <span class="math inline">\(N-1\)</span> examples. This
illustrates the benefit of cross-validation by giving us good
generalization estimates (by training on as much of the data set as
possible) and making sure the model is tested on each data point.</p>
<p><strong>Temporal validation</strong></p>

<p>The cross-validation and holdout set approaches described above assume
that the data have no time dependencies and that the distribution is
stationary over time. This assumption is almost always violated in
practice and affects performance estimates for a model.</p>
<div class="figure" style="text-align: center"><span id="fig:temporal"></span>
<img src="ChapterML/figures/temporal.png" alt="Temporal validation" width="70%" />
<p class="caption">
Figure 6.8: Temporal validation
</p>
</div>
<p>In most practical problems, we want to use a validation strategy that
emulates the way in which our models will be used and provides an
accurate performance estimate. We will call this <em>temporal validation</em>.
For a given point in time <span class="math inline">\(t_i\)</span>, we train our models only on information
available to us before <span class="math inline">\(t_i\)</span> to avoid training on data from the
“future.” We then predict and evaluate on data from <span class="math inline">\(t_i\)</span> to <span class="math inline">\(t_i\)</span> + <span class="math inline">\(d\)</span>
and iterate, expanding the training window while keeping the test window
size constant at <span class="math inline">\(d\)</span>.
Figure <a href="chap-ml.html#fig:temporal">6.8</a> shows this validation process with
<span class="math inline">\(t_i=2010\)</span> and <span class="math inline">\(d=1\)</span> year. The test set window <span class="math inline">\(d\)</span> depends on a few
factors related to how the model will be deployed to best emulate
reality:</p>
<ol style="list-style-type: decimal">
<li><p>How far out in the future do predictions need to be made? For
example, if the set of students who need to be targeted for
interventions has to be finalized at the beginning of the school
year for the entire year, then <span class="math inline">\(d = 1\)</span> year.</p></li>
<li><p>How often will the model be updated? If the model is being updated
daily, then we can move the window by a day at a time to reflect the
deployment scenario.</p></li>
<li><p>How often will the system get new data? If we are getting new data
frequently, we can make predictions more frequently.</p></li>
</ol>
<p>Temporal validation is similar to how time series models are evaluated
and should be the validation approach used for most practical problems.</p>
</div>
<div id="metrics" class="section level3">
<h3><span class="header-section-number">6.6.2</span> Metrics</h3>
<p>The previous subsection focused on validation methodologies assuming we
have a evaluation metric in mind. This section will go over commonly
used evaluation metrics. You are probably familiar with using <span class="math inline">\(R^2\)</span>,
analysis of the residuals, and mean squared error (MSE) to evaluate the
quality of regression models. For regression problems, the MSE
calculates the average squared differences between predictions
<span class="math inline">\(\hat{y}_i\)</span> and true values <span class="math inline">\(y_i\)</span>. When prediction models have smaller
MSE, they are better. However, the MSE itself is hard to interpret
because it measures quadratic differences. Instead, the root mean
squared error (RMSE) is more intuitive as it as measure of mean
differences on the original scale of the response variable. Yet another
alternative is the mean absolute error (MAE), which measures average
absolute distances between predictions and true values.</p>
<p>We will now describe some additional evaluation metrics commonly used in
machine learning for classification. Before we dive into metrics, it is
important to highlight that machine learning models for classification
typically do not predict 0/1 values directly. SVMs, random forests, and
logistic regression all produce a score (which is sometimes a
probability) that is then turned into 0 or 1 based on a user-specific
threshold. You might find that certain tools (such as ) use a default
value for that threshold (often 0.5), but it is important to know that
it is an arbitrary threshold and you should select the threshold based
on the data, the model, and the problem you are solving. We will cover
that a little later in this section.</p>
<p>Once we have turned the real-valued predictions into 0/1 classification,
we can now create a <em>confusion matrix</em> from these predictions, shown in
Figure <a href="chap-ml.html#fig:cm">6.9</a>. Each data point belongs to either the positive class or the negative
class, and for each data point the prediction of the classifier is
either correct or incorrect. This is what the four cells of the
confusion matrix represent. We can use the confusion matrix to describe
several commonly used evaluation metrics.</p>
<div class="figure" style="text-align: center"><span id="fig:cm"></span>
<img src="ChapterML/figures/cm.PNG" alt="A *confusion matrix* created from real-valued predictions" width="70%" />
<p class="caption">
Figure 6.9: A <em>confusion matrix</em> created from real-valued predictions
</p>
</div>
<p>Accuracy is the ratio of correct predictions (both positive and negative) to all
predictions:
<span class="math display">\[\textrm{Accuracy}=\frac{TP + TN}{TP + TN + FP + FN}=\frac{TP + TN}{P+N}=\frac{TP + TN}{P&#39;+N&#39;},\]</span>
where <span class="math inline">\(TP\)</span> denotes true positives, <span class="math inline">\(TN\)</span> true negatives, <span class="math inline">\(FP\)</span> false
positives, <span class="math inline">\(FN\)</span> false negatives, and other symbols denote row or column
totals as in Figure . Accuracy is the most commonly described evaluation
metric for classification but is surprisingly the least useful in
practical situations (at least by itself). One problem with accuracy is
that it does not give us an idea of <em>lift</em> compared to baseline. For
example, if we have a classification problem with 95% of the data as
positive and 5% as negative, a classifier with 85% is performing worse
than a dumb classifier that predicts positive all the time (and will
have 95% accuracy).</p>
<p>Two additional metrics that are often used are precision and recall,
which are defined as follows: <span class="math display">\[\begin{aligned}
{\rm Precision} &amp;= \frac{TP}{TP + FP}=\frac{TP}{P},
\\
{\rm Recall} &amp;= \frac{TP}{TP + FN}=\frac{TP}{P&#39;}\end{aligned}\]</span> (see
also Box 7.3). Precision measures the accuracy of the classifier when it
predicts an example to be positive. It is the ratio of correctly
predicted positive examples (<span class="math inline">\(TP\)</span>) to all examples predicted as positive
(<span class="math inline">\(TP + FP\)</span>). This measure is also called <em>positive predictive value</em> in
other fields. Recall measures the ability of the classifier to find positive
examples. It is the ratio of all the correctly predicted positive
examples (<span class="math inline">\(TP\)</span>) to all the positive examples in the data (<span class="math inline">\(TP + FN\)</span>).
This is also called <em>sensitivity</em> in other fields.</p>
<p>You might have encountered another metric called <em>specificity</em> in other
fields. This measure is the true negative rate: the proportion of
negatives that are correctly identified.</p>
<p>Another metric that is used is the <span class="math inline">\(F_1\)</span> score, which is the harmonic
mean of precision and recall:
<span class="math display">\[F_1 =  \frac{2* {\rm Precision} * {\rm Recall}}{{\rm Precision} + {\rm Recall}}\]</span>
(see also equation 7.1). This is often used when you want to balance
both precision and recall.</p>
<p>There is often a tradeoff between precision and recall. By selecting
different classification thresholds, we can vary and tune the precision
and recall of a given classifier. A highly conservative classifier that
only predicts a 1 when it is absolutely sure (say, a threshold of
0.9999) will most often be correct when it predicts a 1 (high precision)
but will miss most 1s (low recall). At the other extreme, a classifier
that says 1 to every data point (a threshold of 0.0001) will have
perfect recall but low precision.
Figure <a href="chap-ml.html#fig:pr">6.10</a> show a precision–recall curve that is often used
to represent the performance of a given classifier.</p>
<div class="figure" style="text-align: center"><span id="fig:pr"></span>
<img src="ChapterML/figures/pr.png" alt="Precision-recall curve" width="70%" />
<p class="caption">
Figure 6.10: Precision-recall curve
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:pr2"></span>
<img src="ChapterML/figures/pr2.png" alt="Precision or recall at different thresholds" width="70%" />
<p class="caption">
Figure 6.11: Precision or recall at different thresholds
</p>
</div>
<p>If we care about optimizing for the entire precision recall space, a
useful metric is the <em>area under the curve</em> (AUC-PR), which is the area
under the precision–recall curve. AUC-PR must not be confused with
AUC-ROC, which is the area under the related receiver operating
characteristic (ROC) curve. The ROC curve is created by plotting recall
versus (1 – specificity). Both AUCs can be helpful metrics to compare
the performance of different methods and the maximum value the AUC can
take is 1. If, however, we care about a specific part on the
precision–recall curve, we have to look at finer-grainedmetrics.</p>
<p>Let us consider an example from public health. Most public health
agencies conduct inspections of various sorts to detect health hazard
violations (lead hazards, for example). The number of possible places
(homes or businesses) to inspect far exceeds the inspection resources
typically available. Let us assume further that they can only inspect 5%
of all possible places; they would clearly want to prioritize the
inspection of places that are most likely to contain the hazard. In this
case, the model will score and rank all the possible inspection places
in order of hazard risk. We would then want to know what percentage of
the top 5% (the ones that will get inspected) are likely to be hazards,
which translates to the precision in the top 5% of the most confidence
predictions—precision at 5%, as it is commonly called (see Figure
<a href="chap-ml.html#fig:pr2">6.11</a>). <em>Precision at top k percent</em> is a
common class of metrics widely used in information retrieval and search
engine literature, where you want to make sure that the results
retrieved at the top of the search results are accurate. More generally,
this metric is often used in problems in which the class distribution is
skewed and only a small percentage of the examples will be examined
manually (inspections, investigations for fraud, etc.). The literature
provides many case studies of such applications
<span class="citation">(Kumar, Ghani, and Mei <a href="#ref-Kumar2010">2010</a>; Lakkaraju et al. <a href="#ref-Lakkaraju2015">2015</a>; Potash et al. <a href="#ref-Potash2015">2015</a>)</span>.</p>

<p>One last metric we want to mention is a class of cost-sensitive metrics
where different costs (or benefits) can be associated with the different
cells in the confusion matrix. So far, we have implicitly assumed that
every correct prediction and every error, whether for the positive class
or the negative class, has equal costs and benefits. In many practical
problems, that is not the case. For example, we may want to predict
whether a patient in a hospital emergency room is likely to go into
cardiac arrest in the next six hours. The cost of a false positive in
this case is the cost of the intervention (which may be a few extra
minutes of a physician’s time) while the cost of a false negative could
be death. This type of analysis allows us to calculate the expected
value of the predictions of a classifier and select the model that
optimizes this cost-sensitive metric.</p>
</div>
</div>
<div id="practical-tips" class="section level2">
<h2><span class="header-section-number">6.7</span> Practical tips</h2>
<p>Here we highlight some practical tips that will be helpful when working
with machine learning methods.</p>
<div id="features" class="section level3">
<h3><span class="header-section-number">6.7.1</span> Features</h3>
<p>So far in this chapter, we have focused a lot on methods and process,
and we have not discussed features in detail. In social science, they
are not called features but instead are known as variables or
predictors. <span class="roman">Good features are what makes machine learning systems
effective</span>. Feature generation (or engineering, as it is often
called) is where the bulk of the time is spent in the machine learning
process. As social science researchers or practitioners, you have spent
a lot of time constructing features, using transformations, dummy
variables, and interaction terms. All of that is still required and
critical in the machine learning framework. One difference you will need
to get comfortable with is that instead of carefully selecting a few
predictors, machine learning systems tend to encourage the creation of
lots of features and then empirically use holdout data to perform
regularization and model selection. It is common to have models that are
trained on thousands of features. Commonly used approaches to create
features include:</p>
<ul>
<li><p><strong>Transformations</strong>, such as log, square, and square root.</p></li>
<li><p><strong>Dummy (binary) variables</strong>: This is often done by taking categorical variables (such as city)
and creating a binary variable for each value (one variable for each
city in the data). These are also called indicator variables.</p></li>
<li><p><strong>Discretization</strong>: Several methods require features to be discrete instead of
continuous. Several approaches exist to convert continuous variables
into discrete ones, the most common of which is equal-width binning.</p></li>
<li><p><strong>Aggregation</strong>: Aggregate features often constitute the majority of features for a
given problem. These aggregations use different aggregation
functions (count, min, max, average, standard deviation, etc.),
often over varying windows of time and space. For example, given
urban data, we would want to calculate the number (and min, max,
mean, variance) of crimes within an <span class="math inline">\(m\)</span>-mile radius of an address in
the past <span class="math inline">\(t\)</span> months for varying values of <span class="math inline">\(m\)</span> and <span class="math inline">\(t\)</span>, and then to
use all of them as features in a classification problem.</p></li>
</ul>
<p>In general, it is a good idea to have the complexity in features and use
a simple model, rather than using more complex models with simple
features. Keeping the model simple makes it faster to train and easier
to understand.</p>
</div>
<div id="machine-learning-pipeline" class="section level3">
<h3><span class="header-section-number">6.7.2</span> Machine learning pipeline</h3>
<p>When working on machine learning projects, it is a good idea to
structure your code as a modular pipeline so you can easily try
different approaches and methods without major restructuring. The Python
workbooks supporting this book will give you an example of a machine
learning pipeline. A good pipeline will contain modules for importing
data, doing exploration, feature generation, classification, and
evaluation. You can then instantiate a specific workflow by combining
these modules.</p>
<p>An important component of the machine learning pipeline is comparing
different methods. With all the methods out there and all the
hyperparameters they come with, how do we know which model to use and
which hyperparameters to select? And what happens when we add new
features to the model or when the data have “temporal drift” and change
over time? One simple approach is to have a nested set of loops that
loop over all the methods you have access to, then enumerate all the
hyperparameters for that method, create a cross-product, and loop over
all of them, comparing them across different evaluation metrics and
selecting the best one to use going forward. You can even add different
feature subsets and time slices to this loop, as the example in the
supporting workbooks will show.</p>
</div>
<div id="multiclass-problems" class="section level3">
<h3><span class="header-section-number">6.7.3</span> Multiclass problems</h3>
<p>In the supervised learning section, we framed classification problems as
binary classification problems with a 0 or 1 output. There are many
problems where we have multiple classes, such as classifying companies
into their industry codes or predicting whether a student will drop out,
transfer, or graduate. Several solutions have been designed to deal with
the multiclass classification problem:</p>
<ul>
<li><p><strong>Direct multiclass</strong>: Use methods that can directly perform multiclass classification.
Examples of such methods are <span class="math inline">\(K\)</span>-nearest neighbor, decision trees,
and random forests. There are extensions of support vector machines
that exist for multiclass classification as well <span class="citation">(Crammer and Singer <a href="#ref-crammer2002">2002</a>)</span>, but
they can often be slow to train.</p></li>
<li><p><strong>Convert to one versus all (OVA)</strong>: This is a common approach to solve multiclass classification
problems using binary classifiers. Any problem with <span class="math inline">\(n\)</span> classes can
be turned into <span class="math inline">\(n\)</span> binary classification problems, where each
classifier is trained to distinguish between one versus all the
other classes. A new example can be classified by combining the
predictions from all the <span class="math inline">\(n\)</span> classifiers and selecting the class
with the highest score. This is a simple and efficient approach, and
one that is commonly used, but it suffers from each classification
problem possibly having an imbalanced class distribution (due to the
negative class being a collection of multiple classes). Another
limitation of this approach is that it requires the scores of each
classifier to be calibrated so that they are comparable across all
of them.</p></li>
<li><p><strong>Convert to pairwise</strong>: In this approach, we can create binary classifiers to distinguish
between each pair of classes, resulting in <span class="math inline">\(\binom{n}{2}\)</span> binary
classifiers. This results in a large number of classifiers, but each
classifier usually has a balanced classification problem. A new
example is classified by taking the predictions of all the binary
classifiers and using majority voting.</p></li>
</ul>
</div>
<div id="skewed-or-imbalanced-classification-problems" class="section level3">
<h3><span class="header-section-number">6.7.4</span> Skewed or imbalanced classification problems</h3>
<p>A lot of problems you will deal with will not have uniform (balanced)
distributions for both classes. This is often the case with problems in
fraud detection, network security, and medical diagnosis where the class
of interest is not very common. The same is true in many social science
and public policy problems around behavior prediction, such as
predicting which students will not graduate on time, which children may
be at risk of getting lead poisoning, or which homes are likely to be
abandoned in a given city. You will notice that applying standard
machine learning methods may result in all the predictions being for the
most frequent category in such situations, making it problematic to
detect the infrequent classes. There has been a lot of work in machine
learning research on dealing with such problems
<span class="citation">(Chawla <a href="#ref-Chawla05">2005</a>; Kuhn and Johnson <a href="#ref-KuhnJohnson2013">2013</a>)</span> that we will not cover in detail here.
Common approaches to deal with class imbalance include oversampling from
the minority class and undersampling from the majority class. It is
important to keep in mind that the sampling approaches do not need to
result in a <span class="math inline">\(1:1\)</span> ratio. Many supervised learning methods described in
this chapter (such as SVMs) can work well even with a <span class="math inline">\(10:1\)</span> imbalance.
Also, it is critical to make sure that you only resample the training
set; keep the distribution of the test set the same as that of the
original data since you will not know the class labels of new data in
practice and will not be able to resample.</p>
</div>
</div>
<div id="how-can-social-scientists-benefit-from-machine-learning" class="section level2">
<h2><span class="header-section-number">6.8</span> How can social scientists benefit from machine learning?</h2>
<p>In this chapter, we have introduced you to some new methods (both
unsupervised and supervised), validation methodologies, and evaluation
metrics. All of these can benefit social scientists as they tackle
problems in research and practice. In this section, we will give a few
concrete examples where what you have learned so far can be used to
improve some social science tasks:</p>
<ul>
<li><p><strong>Use of better prediction methods and methodology</strong>: Traditional statistics and social sciences have not focused much on
methods for prediction. Machine learning researchers have spent the
past 30 years developing and adapting methods focusing on that task.
We believe that there is a lot of value for social science
researchers and practitioners in learning more about those methods,
applying them, and even augmenting them <span class="citation">(Kleinberg et al. <a href="#ref-Kleinberg2015">2015</a>)</span>. Two common
tasks that can be improved using better prediction methods are
generating counterfactuals (essentially a prediction problem) and
matching. In addition, holdout sets and cross-validation can be used
as a model selection methodology with any existing regression and
classification methods, resulting in improved model selection and
error estimates.</p></li>
<li><p><strong>Model misspecification</strong>: Linear and logistic regressions are common techniques for data
analysis in the social sciences. One fundamental assumption within
both is that they are additive over parameters. Machine learning
provides tools when this assumption is too limiting. Hainmueller and
Hazlett <span class="citation">(Hainmueller and Hazlett <a href="#ref-hainmueller2014kernel">2014</a>)</span>, for example, reanalyze data that
were originally analyzed with logistic regression and come to
substantially different conclusions. They argue that their analysis,
which is more flexible and based on supervised learning methodology,
provides three additional insights when compared to the original
model. First, predictive performance is similar or better, although
they do not need an extensive search to find the final model
specification as it was done in the original analysis. Second, their
model allows them to calculate average marginal effects that are
mostly similar to the original analysis. However, for one covariate
they find a substantially different result, which is due to model
misspecification in the original model. Finally, the reanalysis also
discovers interactions that were missed in the original publication.</p></li>
<li><p><strong>Better text analysis</strong>: Text is everywhere, but unfortunately humans are slow and expensive
in analyzing text data. Thus, computers are needed to analyze large
collections of text. Machine learning methods can help make this
process more efficient. Feldman and Sanger <span class="citation">(Feldman and Sanger <a href="#ref-FeldmanSanger">2006</a>)</span> provide
an overview of different automatic methods for text analysis.
Grimmer and Stewart <span class="citation">(Grimmer and Stewart <a href="#ref-grimmer2013text">2013</a>)</span> give examples that are more
specific for social scientists, and
Chapter <a href="chap-text.html#chap:text">Text analysis</a> provides more details on this topic.</p></li>
<li><p><strong>Adaptive surveys</strong>: Some survey questions have a large number of possible answer
categories. For example, international job classifications describe
more than 500 occupational categories, and it is prohibitive to ask
all categories during the survey. Instead, respondents answer an
open-ended question about their job and machine learning algorithms
can use the verbatim answers to suggest small sets of plausible
answer options. The respondents can then select which option is the
best description for their occupation, thus saving the costs for
coding after the interview.</p></li>
<li><p><strong>Estimating heterogeneous treatment effects</strong>: A standard approach to causal inference is the assignment of
different treatments (e.g., medicines) to the units of interest
(e.g., patients). Researchers then usually calculate the average
treatmenteffect—the average difference in outcomes for both
groups. It is also of interest if treatment effects differ for
various subgroups (e.g., is a medicine more effective for younger
people?). Traditional subgroup analysis has been criticized and
challenged by various machine learning techniques
<span class="citation">(Green and Kern <a href="#ref-green2012modeling">2012</a>; Imai, Ratkovic, and others <a href="#ref-imai2013estimating">2013</a>)</span>.</p></li>
<li><p><strong>Variable selection</strong>: Although there are many methods for variable selection, regularized
methods such as the lasso are highly effective and efficient when
faced with large amounts of data. Varian <span class="citation">(Varian <a href="#ref-Varian2014">2014</a>)</span> goes into
more detail and gives other methods from machine learning that can
be useful for variable selection. We can also find interactions
between pairs of variables (to feed into other models) using random
forests, by looking at variables that co-occur in the same tree, and
by calculating the strength of the interaction as a function of how
many trees they co-occur in, how high they occur in the trees, and
how far apart they are in a given tree.</p></li>
</ul>
</div>
<div id="advanced-topics" class="section level2">
<h2><span class="header-section-number">6.9</span> Advanced topics</h2>
<p>This has been a short but intense introduction to machine learning, and
we have left out several important topics that are useful and
interesting for you to know about and that are being actively researched
in the machine learning community. We mention them here so you know what
they are, but will not describe them in detail. These include:</p>
<ul>
<li><p>Semi-supervised learning,</p></li>
<li><p>Active learning,</p></li>
<li><p>Reinforcement learning,</p></li>
<li><p>Streaming data,</p></li>
<li><p>Anomaly detection,</p></li>
<li><p>Recommender systems.</p></li>
</ul>
</div>
<div id="summary-3" class="section level2">
<h2><span class="header-section-number">6.10</span> Summary</h2>
<p>Machine learning is a active research field, and in this chapter we have
given you an overview of how the work developed in this field can be
used by social scientists. We covered the overall machine learning
process, methods, evaluation approaches and metrics, and some practical
tips, as well as how all of this can benefit social scientists. The
material described in this chapter is a snapshot of a fast-changing
field, and as we are seeing increasing collaborations between machine
learning researchers and social scientists, the hope and expectation is
that the next few years will bring advances that will allow us to tackle
social and policy problems much more effectively using new types of data
and improved methods.</p>
</div>
<div id="ml:res" class="section level2">
<h2><span class="header-section-number">6.11</span> Resources</h2>
<p>Literature for further reading that also explains most topics from this
chapter in greater depth:</p>
<ul>
<li><p>Hastie et al.’s <em>The Elements of Statistical Learning</em>
<span class="citation">(Hastie, Tibshirani, and Friedman <a href="#ref-HastieTibshirani">2001</a>)</span> is a classic and is available online for free.</p></li>
<li><p>James et al.’s <em>An Introduction to Statistical Learning</em>
<span class="citation">(James et al. <a href="#ref-james2013introduction">2013</a>)</span>, from the same authors, includes less
mathematics and is more approachable. It is also available online.</p></li>
<li><p>Mitchell’s <em>Machine Learning</em> <span class="citation">(Mitchell <a href="#ref-mitchell1997machine">1997</a>)</span> is a good
introduction to some of the methods and gives a good motivation
underlying them.</p></li>
<li><p>Provost and Fawcett’s <em>Data Science for Business</em> <span class="citation">(Provost and Fawcett <a href="#ref-FawcettProvost">2013</a>)</span>
is a good practical handbook for using machine learning to solve
real-world problems.</p></li>
<li><p>Wu et al.’s “Top 10 Algorithms in Data Mining” <span class="citation">(Wu et al. <a href="#ref-wu2008top">2008</a>)</span>.</p></li>
</ul>
<p>Software:</p>
<ul>
<li><p>Python (with libraries like <code>scikit-learn</code>, <code>pandas</code>, and more).</p></li>
<li><p>R has many relevant packages <span class="citation">(Hothorn, <a href="#ref-cranML">n.d.</a>)</span>.</p></li>
<li><p>Cloud-based: AzureML, Amazon ML.</p></li>
<li><p>Free: KNIME, Rapidminer, Weka (mostly for research use).</p></li>
<li><p>Commercial: IBM Modeler, SAS Enterprise Miner, Matlab.</p></li>
</ul>
<p>Many excellent courses are available online <span class="citation">(Z., <a href="#ref-MLcourses">n.d.</a>)</span>, including
Hastie and Tibshirani’s <em>Statistical Learning</em> <span class="citation">(Hastie and Tibshirani, <a href="#ref-SLcourse">n.d.</a>)</span>.</p>
<p>Major conferences in this area include the International Conference on
Machine Learning <span class="citation">(ICML, <a href="#ref-ICML">n.d.</a>)</span>, the Annual Conference on Neural Information
Processing Systems (NIPS) <span class="citation">(NIPS, <a href="#ref-nips">n.d.</a>)</span>, and the ACM International Conference
on Knowledge Discovery and Data Mining (KDD) <span class="citation">(KDD, <a href="#ref-kdd">n.d.</a>)</span>.</p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-samuel1959some">
<p>Samuel, Arthur L. 1959. “Some Studies in Machine Learning Using the Game of Checkers.” <em>IBM Journal of Research and Development</em> 3 (3). IBM: 210–29.</p>
</div>
<div id="ref-mitchell1997machine">
<p>Mitchell, Tom M. 1997. <em>Machine Learning</em>. McGraw-Hill.</p>
</div>
<div id="ref-Flach">
<p>Flach, Peter. 2012. <em>Machine Learning: The Art and Science of Algorithms That Make Sense of Data</em>. Cambridge University Press.</p>
</div>
<div id="ref-HastieTibshirani">
<p>Hastie, Trevor, Robert Tibshirani, and Jerome Friedman. 2001. <em>The Elements of Statistical Learning</em>. Springer.</p>
</div>
<div id="ref-tibshirani1996regression">
<p>Tibshirani, Robert. 1996. “Regression Shrinkage and Selection via the Lasso.” <em>Journal of the Royal Statistical Society, Series B</em>. JSTOR, 267–88.</p>
</div>
<div id="ref-zhu2005semi">
<p>Zhu, Xiaojin. 2008. “Semi-Supervised Learning Literature Survey.” <a href="http://pages.cs.wisc.edu/~jerryzhu/pub/ssl_survey.pdf" class="uri">http://pages.cs.wisc.edu/~jerryzhu/pub/ssl_survey.pdf</a>.</p>
</div>
<div id="ref-Ontogen">
<p>Fortuna, Blaz, Marko Grobelnik, and Dunja Mladenic. 2007. “OntoGen: Semi-Automatic Ontology Editor.” In <em>Proceedings of the 2007 Conference on Human Interface: Part Ii</em>, 309–18. Beijing, China: Springer. <a href="http://dl.acm.org/citation.cfm?id=1766591.1766627" class="uri">http://dl.acm.org/citation.cfm?id=1766591.1766627</a>.</p>
</div>
<div id="ref-park2009simple">
<p>Park, Hae-Sang, and Chi-Hyuck Jun. 2009. “A Simple and Fast Algorithm for K-Medoids Clustering.” <em>Expert Systems with Applications</em> 36 (2). Elsevier: 3336–41.</p>
</div>
<div id="ref-ShaweTaylor2004">
<p>Shawe-Taylor, John, and Nello Cristianini. 2004. <em>Kernel Methods for Pattern Analysis</em>. Cambridge University Press.</p>
</div>
<div id="ref-Scholkopf2001">
<p>Scholkopf, Bernhard, and Alexander J. Smola. 2001. <em>Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond</em>. MIT Press.</p>
</div>
<div id="ref-SmolaRegression04">
<p>Smola, Alex J., and Bernhard Schölkopf. 2004. “A Tutorial on Support Vector Regression.” <em>Statistics and Computing</em> 14 (3). Hingham, MA: Kluwer Academic Publishers: 199–222. <a href="https://doi.org/10.1023/B:STCO.0000035301.49549.88" class="uri">https://doi.org/10.1023/B:STCO.0000035301.49549.88</a>.</p>
</div>
<div id="ref-Chapelle2010">
<p>Chapelle, O., and S. S. Keerthi. 2010. “Efficient Algorithms for Ranking with SVMs.” <em>Information Retrieval</em> 13 (3). Hingham, MA: Kluwer Academic Publishers: 201–15. <a href="https://doi.org/10.1007/s10791-009-9109-9" class="uri">https://doi.org/10.1007/s10791-009-9109-9</a>.</p>
</div>
<div id="ref-Kumar2010">
<p>Kumar, Mohit, Rayid Ghani, and Zhu-Song Mei. 2010. “Data Mining to Predict and Prevent Errors in Health Insurance Claims Processing.” In <em>Proceedings of the 16th Acm Sigkdd International Conference on Knowledge Discovery and Data Mining</em>, 65–74. KDD ’10. ACM. <a href="https://doi.org/10.1145/1835804.1835816" class="uri">https://doi.org/10.1145/1835804.1835816</a>.</p>
</div>
<div id="ref-Lakkaraju2015">
<p>Lakkaraju, Himabindu, Everaldo Aguiar, Carl Shan, David Miller, Nasir Bhanpuri, Rayid Ghani, and Kecia L. Addison. 2015. “A Machine Learning Framework to Identify Students at Risk of Adverse Academic Outcomes.” In <em>Proceedings of the 21th Acm Sigkdd International Conference on Knowledge Discovery and Data Mining</em>, 1909–18. KDD ’15. ACM. <a href="https://doi.org/10.1145/2783258.2788620" class="uri">https://doi.org/10.1145/2783258.2788620</a>.</p>
</div>
<div id="ref-Potash2015">
<p>Potash, Eric, Joe Brew, Alexander Loewi, Subhabrata Majumdar, Andrew Reece, Joe Walsh, Eric Rozier, Emile Jorgenson, Raed Mansour, and Rayid Ghani. 2015. “Predictive Modeling for Public Health: Preventing Childhood Lead Poisoning.” In <em>Proceedings of the 21th Acm Sigkdd International Conference on Knowledge Discovery and Data Mining</em>, 2039–47. KDD ’15. ACM. <a href="https://doi.org/10.1145/2783258.2788629" class="uri">https://doi.org/10.1145/2783258.2788629</a>.</p>
</div>
<div id="ref-crammer2002">
<p>Crammer, Koby, and Yoram Singer. 2002. “On the Algorithmic Implementation of Multiclass Kernel-Based Vector Machines.” <em>Journal of Machine Learning Research</em> 2. JMLR.org: 265–92. <a href="http://dl.acm.org/citation.cfm?id=944790.944813" class="uri">http://dl.acm.org/citation.cfm?id=944790.944813</a>.</p>
</div>
<div id="ref-Chawla05">
<p>Chawla, Nitesh V. 2005. “Data Mining for Imbalanced Datasets: An Overview.” In <em>The Data Mining and Knowledge Discovery Handbook</em>, edited by Oded Maimon and Lior Rokach, 853–67. Springer. <a href="http://dblp.uni-trier.de/db/books/collections/datamining2005.html#Chawla05" class="uri">http://dblp.uni-trier.de/db/books/collections/datamining2005.html#Chawla05</a>.</p>
</div>
<div id="ref-KuhnJohnson2013">
<p>Kuhn, Max, and Kjell Johnson. 2013. <em>Applied Predictive Modeling</em>. Springer Science &amp; Business Media.</p>
</div>
<div id="ref-Kleinberg2015">
<p>Kleinberg, Jon, Jens Ludwig, Sendhil Mullainathan, and Ziad Obermeyer. 2015. “Prediction Policy Problems.” <em>American Economic Review</em> 105 (5): 491–95. <a href="http://EconPapers.repec.org/RePEc:aea:aecrev:v:105:y:2015:i:5:p:491-95" class="uri">http://EconPapers.repec.org/RePEc:aea:aecrev:v:105:y:2015:i:5:p:491-95</a>.</p>
</div>
<div id="ref-hainmueller2014kernel">
<p>Hainmueller, Jens, and Chad Hazlett. 2014. “Kernel Regularized Least Squares: Reducing Misspecification Bias with a Flexible and Interpretable Machine Learning Approach.” <em>Political Analysis</em> 22 (2). SPM-PMSAPSA: 143–68.</p>
</div>
<div id="ref-FeldmanSanger">
<p>Feldman, Ronen, and James Sanger. 2006. <em>Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data</em>. Cambridge University Press.</p>
</div>
<div id="ref-grimmer2013text">
<p>Grimmer, Justin, and Brandon M. Stewart. 2013. “Text as Data: The Promise and Pitfalls of Automatic Content Analysis Methods for Political Texts.” <em>Political Analysis</em> 21 (3). SPM-PMSAPSA: 267–97.</p>
</div>
<div id="ref-green2012modeling">
<p>Green, Donald P., and Holger L. Kern. 2012. “Modeling Heterogeneous Treatment Effects in Survey Experiments with Bayesian Additive Regression Trees.” <em>Public Opinion Quarterly</em> 76. AAPOR: 491–511.</p>
</div>
<div id="ref-imai2013estimating">
<p>Imai, Kosuke, Marc Ratkovic, and others. 2013. “Estimating Treatment Effect Heterogeneity in Randomized Program Evaluation.” <em>Annals of Applied Statistics</em> 7 (1). Institute of Mathematical Statistics: 443–70.</p>
</div>
<div id="ref-Varian2014">
<p>Varian, Hal R. 2014. “Big Data: New Tricks for Econometrics.” <em>Journal of Economic Perspectives</em> 28 (2): 3–28. <a href="https://doi.org/10.1257/jep.28.2.3" class="uri">https://doi.org/10.1257/jep.28.2.3</a>.</p>
</div>
<div id="ref-james2013introduction">
<p>James, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani. 2013. <em>An Introduction to Statistical Learning</em>. Springer.</p>
</div>
<div id="ref-FawcettProvost">
<p>Provost, Foster, and Tom Fawcett. 2013. <em>Data Science for Business: What You Need to Know About Data Mining and Data-Analytic Thinking</em>. O’Reilly Media.</p>
</div>
<div id="ref-wu2008top">
<p>Wu, Xindong, Vipin Kumar, J. Ross Quinlan, Joydeep Ghosh, Qiang Yang, Hiroshi Motoda, Geoffrey J. McLachlan, et al. 2008. “Top 10 Algorithms in Data Mining.” <em>Knowledge and Information Systems</em> 14 (1). Springer: 1–37.</p>
</div>
<div id="ref-cranML">
<p>Hothorn, Torsten. n.d. “CRAN Task View: Machine Learning &amp; Statistical Learning.” <a href="https://cran.r-project.org/web/views/MachineLearning.html" class="uri">https://cran.r-project.org/web/views/MachineLearning.html</a>. Accessed February 1, 2016.</p>
</div>
<div id="ref-MLcourses">
<p>Z., Zygmunt. n.d. “Machine Learning Courses Online.” <a href="http://fastml.com/machine-learning-courses-online" class="uri">http://fastml.com/machine-learning-courses-online</a>, January 7, 2013.</p>
</div>
<div id="ref-SLcourse">
<p>Hastie, Trevor, and Rob Tibshirani. n.d. “Statistical Learning Course.” <a href="https://lagunita.stanford.edu/courses/HumanitiesandScience/StatLearning/Winter2015/about" class="uri">https://lagunita.stanford.edu/courses/HumanitiesandScience/StatLearning/Winter2015/about</a>. Accessed February 1, 2016.</p>
</div>
<div id="ref-ICML">
<p>ICML. n.d. “International Conference on Machine Learning.” <a href="http://icml.cc/" class="uri">http://icml.cc/</a>. Accessed February 1, 2016.</p>
</div>
<div id="ref-nips">
<p>NIPS. n.d. “Annual Conference on Neural Information Processing Systems (NIPS).” <a href="https://nips.cc/" class="uri">https://nips.cc/</a>. Accessed February 1, 2016.</p>
</div>
<div id="ref-kdd">
<p>KDD. n.d. “ACM International Conference on Knowledge Discovery and Data Mining (KDD).” <a href="http://www.kdd.org" class="uri">http://www.kdd.org</a>. Accessed February 1, 2016.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="33">
<li id="fn33"><p>See Chapter 3.<a href="chap-ml.html#fnref33" class="footnote-back">↩</a></p></li>
<li id="fn34"><p>See Chapter 3.<a href="chap-ml.html#fnref34" class="footnote-back">↩</a></p></li>
<li id="fn35"><p>In statistical terms, regularization is an attempt to avoid overfitting the model<a href="chap-ml.html#fnref35" class="footnote-back">↩</a></p></li>
<li id="fn36"><p>Distance metrics are
mathematical formulas to
calculate the distance between two objects.
For example, <em>Manhattan distance</em> is the distance a
car would drive from one
place to another place in
a grid-based street system,
whereas <em>Euclidian distance</em>
(in two-dimensional space)
is the “straight-line” distance between two points.<a href="chap-ml.html#fnref36" class="footnote-back">↩</a></p></li>
<li id="fn37"><p>The topic of causal inference is addressed in more
detail in Chapter 10.<a href="chap-ml.html#fnref37" class="footnote-back">↩</a></p></li>
<li id="fn38"><p>Bootstrap is a general
statistical procedure that
draws random samples of
the original data with replacement.<a href="chap-ml.html#fnref38" class="footnote-back">↩</a></p></li>
</ol>
</div>
<div id="disqus_thread"></div>
<script>
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = '//big-data-and-social-science.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the
<a href="https://disqus.com/?ref_noscript">
  comments powered by Disqus.</a></noscript>
            </section>

          </div>
        </div>
      </div>
<a href="chap-parallel.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="chap-text.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/Coleridge-Initiative/big-data-and-social-science/edit/master/06-ChapterML.Rmd",
"text": "Edit"
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
